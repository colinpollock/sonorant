{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Phoneme Language Model #\n",
    "In this notebook I train a language model over English sounds (also known as [phonemes](https://en.wikipedia.org/wiki/Phoneme)). The data for English pronunciations comes from the CMU Pronouncing Dictionary. The pronunciations in the pronouncing dictionary are in [ARPABET](https://en.wikipedia.org/wiki/ARPABET), a set of symbols representing English sounds. So in ARPABET \"fish\" is pronounced as /F IH1 SH/.\n",
    "\n",
    "By training on tens of thousands of pronunciations the model will hopefully learn [English phonotactics](https://en.wikipedia.org/wiki/Phonotactics#English_phonotactics), the rules that govern what sounds like a valid English word. For example, /F AH1 N/ (\"fun\") sounds good, but /NG S ER1/ (maybe represented as \"ngsr\") does not.\n",
    "\n",
    "\n",
    "Check out the notebook `Phoneme Exploration.ipynb` if you want to see the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sonorous.languagemodel import LanguageModel, ModelParams, Vocabulary\n",
    "from sonorous.pronunciationdata import load_pronunciations\n",
    "from sonorous.utils import split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data ##\n",
    "The data for this model comes from the [CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict), which contains over one hundred thousand pronunciations. Each pronuncation is in [ARPABET](https://en.wikipedia.org/wiki/ARPABET), a set of symbols for representing English speech sounds. In ARPABET the word \"fish\" is represented by the sequence of phonemes /F IH1 SH/. You can probably guess the first and third sounds. The vowel in the middle has \"1\" at the end to indicate it has the primary stress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the `load_pronunciations` function to load the Pronouncing Dictionary into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 125,801 pronunciations.\n",
      "\n",
      "Sample of 5 pronunciations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>pronunciation_string</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>(HH, IH1, Z)</td>\n",
       "      <td>HH IH1 Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rurik</th>\n",
       "      <td>(R, UH1, R, IH0, K)</td>\n",
       "      <td>R UH1 R IH0 K</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wingerter</th>\n",
       "      <td>(W, IH1, NG, G, ER0, T, ER0)</td>\n",
       "      <td>W IH1 NG G ER0 T ER0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dellaert</th>\n",
       "      <td>(D, EH1, L, AA0, R, T)</td>\n",
       "      <td>D EH1 L AA0 R T</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azzara</th>\n",
       "      <td>(AA0, T, S, AA1, R, AH0)</td>\n",
       "      <td>AA0 T S AA1 R AH0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pronunciation  pronunciation_string  length\n",
       "word                                                                 \n",
       "his                        (HH, IH1, Z)              HH IH1 Z       3\n",
       "rurik               (R, UH1, R, IH0, K)         R UH1 R IH0 K       5\n",
       "wingerter  (W, IH1, NG, G, ER0, T, ER0)  W IH1 NG G ER0 T ER0       7\n",
       "dellaert         (D, EH1, L, AA0, R, T)       D EH1 L AA0 R T       6\n",
       "azzara         (AA0, T, S, AA1, R, AH0)     AA0 T S AA1 R AH0       6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations = load_pronunciations()\n",
    "print(f\"There are {len(pronunciations):,} pronunciations.\")\n",
    "print()\n",
    "print(\"Sample of 5 pronunciations:\")\n",
    "pronunciations.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the pronunciation for \"fish\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F IH1 SH'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['fish', 'pronunciation_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are all of the pronunciations for the word \"tomato\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation_string</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tomato</th>\n",
       "      <td>T AH0 M EY1 T OW2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomato</th>\n",
       "      <td>T AH0 M AA1 T OW2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pronunciation_string\n",
       "word                       \n",
       "tomato    T AH0 M EY1 T OW2\n",
       "tomato    T AH0 M AA1 T OW2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['tomato', ['pronunciation_string']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model ##\n",
    "The module `languagemodel.py` contains a class `LanguageModel` that implements a simple neural language model. It's a PyTorch neural network comprised of the following layers:\n",
    "1. **Embedding layer** to translate each phoneme into a dense vector. Note that in the code this is called the _encoder since it encodes input phonemes into a representation the model can work with.\n",
    "2. An recurrent neural network (**RNN**) layer that processes each input phoneme sequentially and for each step generates (a) a hidden representation to pass on to the next step and (b) an output.\n",
    "3. A **linear layer** that decodes the outputes (2b) into distributions over each phoneme. Note that in the code this is called the _docoder since it decodes the model's internal representations back into phonemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through a simple example of what happens when we pass the pronunciation /F IH1 SH/ through the model. Ultimately what I want ouf of the model is a prediction at each position of what the next phoneme should be. For example, when a well trained model is sees /F IH1/ it should know that /SH/ is likely, or at least not unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll create a `Vocabulary` instance by passing in all the pronunciations. The `vocab` is used to convert phonemes into integer indices that the neural network handle. It does a few other things too, which you can see below. The `Vocabulary` class's code is in `sonorous/languagemodel.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 distinct phonemes.\n",
      "\n",
      "Looking up the int index for 'SH': 40\n",
      "\n",
      "Checking whether 'SH' is in the vocabulary: True\n",
      "\n",
      "Looking up the phoneme for a specific int index: SH\n",
      "\n",
      "Encoding /F IH1 SH/: [ 1 54 58 40  2]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_texts(pronunciations.pronunciation.values)\n",
    "\n",
    "print(f\"There are {len(vocab)} distinct phonemes.\")\n",
    "print()\n",
    "print(\"Looking up the int index for 'SH':\", vocab['SH'])\n",
    "print()\n",
    "print(\"Checking whether 'SH' is in the vocabulary:\", 'SH' in vocab)\n",
    "print()\n",
    "print(\"Looking up the phoneme for a specific int index:\", vocab.token_from_idx(vocab['SH']))\n",
    "print()\n",
    "print(\"Encoding /F IH1 SH/:\", vocab.encode_text((\"F\", \"IH1\", \"SH\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll define the model. Note that I'm not actually fitting the model to any data so the output will be random. The hyperparameters aren't optimal, but again that doesn't matter here since I just want to show the flow of data through the network.\n",
    "\n",
    "The `ModelParams` class (from `sonorous/languagemodel.py` encapsulates hyperparameters and options for the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = ModelParams(\n",
    "    rnn_type='rnn', embedding_dimension=10, hidden_dimension=3, num_layers=1,\n",
    "    max_epochs=3, early_stopping_rounds=3\n",
    ")\n",
    "\n",
    "language_model = LanguageModel(vocab, model_params, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll walk through what happens when we pass the word \"fish\" /F IH1 SH/ through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_pronunciation = (\"F\", \"IH1\", \"SH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Vocabulary.encode_text` function we saw earlier does a few things. First, it adds dummy tokens to the pronunciation indicating its start and end. This allows the model to learn transition probabilities from the start of the word to the first phoneme, and from the last phoneme to the end of the word.\n",
    "\n",
    "It then converts every phoneme to its ingeter index.\n",
    "\n",
    "\n",
    "Before passing the pronunciation into the neural network I need to add dummy tokens to the pronunciation indicating its start and end. This allows the model to learn transition probabilities from the start of the word to the first phoneme, and from the last phoneme to the end of the word. We end up with this: `[\"START\", \"F\", \"IH1\", \"SH\", \"END\"]`.\n",
    "\n",
    "I also need to translate each phoneme into an integer index within the model. The `encode_pronunciation` function handles both of these tasks. It uses the `phoneme_to_idx` mapping I built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 54 58 40  2]\n",
      "\n",
      "1 => <START>\n",
      "54 => F\n",
      "58 => IH1\n",
      "40 => SH\n",
      "2 => <END>\n"
     ]
    }
   ],
   "source": [
    "fish_input = vocab.encode_text(fish_pronunciation)\n",
    "print(fish_input)\n",
    "print()\n",
    "for idx in input_:\n",
    "    phoneme = vocab.token_from_idx(idx)\n",
    "    print(f'{idx} => {phoneme}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to pass the input into the model's `forward` function, which takes in inputs and outputs predictions. This model's `forward` function expects a Tensor of dimension `(batch_size, NUMBER OF STEPS)`. A step here refers to a step forward in the sequence, so /<START> F IH1 SH <END>/ has 5 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input's shape: (5,)\n",
      "Batch input's shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input's shape:\", fish_input.shape)\n",
    "fish_batch_input = torch.LongTensor(fish_input).unsqueeze(0)\n",
    "print(\"Batch input's shape:\", fish_batch_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing the `forward` function does is embed each phoneme using an [nn.Embedding](https://pytorch.org/docs/stable/nn.html#embedding). Each phoneme has a dedicated embedding vector of length `embedding_dimension`, so the shape of `embedded` is `(batch size, number of steps, embedding_dimension)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 10])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6158,  0.6928,  0.9496,  1.3493,  0.5137,  0.2907,  0.6428,\n",
       "          -0.7816,  2.3113,  0.2308],\n",
       "         [-0.6769,  1.2721,  1.4072, -0.4552, -0.8251, -1.2323,  1.4046,\n",
       "          -0.1850, -0.5017, -0.7029],\n",
       "         [-1.0615,  0.1451,  1.5215,  0.0410, -0.1703, -0.1945, -1.0819,\n",
       "          -0.2996, -0.4551, -0.5323],\n",
       "         [-0.9407, -2.2037,  0.6629, -0.7016, -0.0268,  0.5728,  1.3071,\n",
       "           1.2864, -0.1486, -0.9160],\n",
       "         [ 0.7330, -1.3526,  1.1809, -0.0499,  0.3611, -1.2726,  0.9338,\n",
       "          -0.8422,  1.5843,  0.0103]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = language_model._encoder(batch_input)\n",
    "print(embedded.shape)\n",
    "print()\n",
    "embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll pass `embedded` to the [RNN layer](https://pytorch.org/docs/stable/nn.html#recurrent-layers), resulting in `rnn_output` and `hidden_state`. I won't go into detail on how RNNs work since there are many detailed posts on the web you can read, but the basic idea is a cell is applied sequentially to every token (i.e. step) in the input. At each step an output and a hidden state are produced. The hidden state can be passed on to the next step, and the output can be used to make a prediction.\n",
    "\n",
    "The `rnn` layer below operates on the full sequence, so the results are for the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9847,  0.8513, -0.9922],\n",
       "         [-0.6992,  0.4809, -0.1975],\n",
       "         [-0.7001,  0.5838,  0.0362],\n",
       "         [ 0.9454,  0.9219, -0.7351],\n",
       "         [-0.9824,  0.9435, -0.4563]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output, hidden_state = language_model._rnn(embedded)\n",
    "print(rnn_output.shape)\n",
    "print()\n",
    "rnn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our application we can ignore the `hidden_state`-- the `rnn_output` is the interesting part. The first dimension is for the batch, and we only have a single input in our batch. The second dimension is for each of the input phonemes. The third dimension corresponds to `hidden_dimension`: you can think of this as the state of the RNN at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're getting to the interesting part. As I said at the beginning of this section, I want the output of the RNN at each position to be predictions for the *next* position. So I'll apply a [linear layer](https://pytorch.org/docs/stable/nn.html#linear) to the `rnn_output`, resulting in a vector the size of the vocabularly at each position. The [softmax](https://pytorch.org/docs/stable/nn.functional.html#softmax) function normalizes the outputs into probability distributions for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('F', 'IH1', 'SH')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 72])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = language_model._decoder(rnn_output)\n",
    "probabilities = F.softmax(outputs, dim=-1).squeeze()\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of `probabilities` is (5, 72) because each of the five tokens in `/<START> F IH1 SH <END>/` gets a a probability distribution over each of the 72 phonemes in the vocabulary.\n",
    "\n",
    "The first phoneme in the input is the `<START>` token; let's see what the model thinks should come next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_for_first_phoneme = probabilities[0]\n",
    "most_likely_first_phoneme_idx = probabilities_for_first_phoneme.argmax().item()\n",
    "most_likely_first_phoneme = vocab.token_from_idx(most_likely_first_phoneme_idx)\n",
    "most_likely_first_phoneme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model predicts /F/ to be the first phoneme in the word. Since the model isn't fit yet this is just a random guess. In order to get the model to make good predictions I'll need to first train a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Model ##\n",
    "In this section I'll train a number of models on the train set and select the one that has the lowest error on the dev set. I'll split the DataFrame of pronunciations into three DataFrames, with 79% for training, 20% for dev/validation, and 1% for testing of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99382, 25160, 1259)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations, dev_pronunciations, test_pronunciations = split_data(pronunciations, dev_proportion=.2, test_proportion=.01)\n",
    "len(train_pronunciations), len(dev_pronunciations), len(test_pronunciations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I ran a larger parameter search before and saw that GRUs were consistently outperforming LSTMs and vanilla RNNs. There are 12 (4 * 3) models to train, and for each one I'm measuring train and dev error at every epoch. So if each model trains for the maximum of 2,000 epochs I would end up with 12 * 2,000 = 24,000 models to choose from. There's a good chance I'm overfitting the dev set with such a large search, but I'll inspect the learning curves to try to avoid selecting an iteration that randomly did well.\n",
    "\n",
    "While each model trains for a maximum of 2000 epochs, it stops early if the dev error does not decrease for three epochs in a row. Since I'm going to be selecting the model with the lowest dev error there's no reason to keep training a model once it's started overfitting. Alternatively I could train all models to convergence and then add regularization to reduce the complexity and identify the sweet spot, but that's far more time consuming because it requires training more models and each of them for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'embedding_dimension': [50],\n",
    "    'hidden_dimension': [2],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    model_parameters = ModelParams(rnn_type='rnn', num_layers=1, max_epochs=1000, early_stopping_rounds=1, **params)\n",
    "    model = LanguageModel(vocab, model_parameters, device_name='cpu')\n",
    "\n",
    "    print('Model Params:', model_parameters)\n",
    "    \n",
    "    train_losses, dev_losses = model.fit(\n",
    "        train_pronunciations.pronunciation.values.tolist(),\n",
    "        dev_pronunciations.pronunciation.values.tolist()\n",
    "    )\n",
    "    \n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are {meow} models with a dev error of around .76. I'll choose the simplest one, which \n",
    "\n",
    "* point out that no matter how low the train error gets, the dev error\n",
    "* which model parameters fail to ever get to the lowest dev error\n",
    "* which model parameters overfit the most\n",
    "\n",
    "* isolate the group of models with about .76 dev error. choose the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = models_df[(models_df.embedding_dimension==50) & (models_df.hidden_dimension==100) & (models_df.num_layers==3)]\n",
    "t = t.set_index('epoch')\n",
    "t.dev_loss.plot()\n",
    "t.train_loss.plot()\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('dev_loss').iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best \"model\" was at an earlier epoch I don't have access to it. So I'll train a model with that model's parameters and set the number of epochs to MEOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = PhonemeLM(\n",
    "    phoneme_to_idx, device='cuda', rnn_type='gru',\n",
    "    embedding_dimension=50, hidden_dimension=100, num_layers=3,\n",
    "    max_epochs=69, early_stopping_rounds=69, batch_size=1024,\n",
    ")\n",
    "\n",
    "train_loss, dev_loss = model.fit(train_df.pronunciation.values.tolist(), dev_df.pronunciation.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have what I hope is the best model I can test how well it does on the holdout test set, which I haven't look at at all during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_data_loader(test_df.pronunciation.values.tolist(), lm.phoneme_to_idx)\n",
    "lm.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = build_data_loader(dev_df.pronunciation.values.tolist(), lm.phoneme_to_idx)\n",
    "lm.evaluate(dev_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: compute the test error for the final model. Bar chart for the train, dev, and test errors\n",
    "\n",
    "Comment on findings, probably that test is higher and that's expected because language models are very sensitive to corpus difference (and I probably overfit the dev set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Final Model ##\n",
    "Now that I've found the best parameters for the model according to the dev set I'll train a final model using all of the data. This should increase model performance overall since more data is better, but is also necessary since I'll be using the model to predict probabilities of all English words. If some of those words weren't in the training set they would artificially get lower probabilities. (Another approach here could be to train a model on e.g. 4/5 folds of the data and make predictions about the remaining 1/5, doing that 5 times to get unbiased predictions for all data, but this would have taken much longer to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.8998loss: 0.8985\n",
      "\tGenerated: in train: 3%, assess: 0%, novel: 97%\n",
      "\t EY1 IH2 ER0 L\n",
      "\t IH2 R AA0 K AH0\n",
      "\t IH1 AY1 K S AA1\n",
      "\t AA1 R SH Z\n",
      "\t CH ER2 OY0 IY0\n",
      "Epoch 2: train loss: 0.7942loss: 0.8027\n",
      "\tGenerated: in train: 3%, assess: 0%, novel: 97%\n",
      "\t B EH1 SH S AH0 K D IH0\n",
      "\t K IY2 F EY1 AH0 K IY0\n",
      "\t T S JH AH0 B\n",
      "\t B AH0 AE1 W L IY0\n",
      "\t D HH L HH T\n",
      "Epoch 3: train loss: 0.7318loss: 0.7347\n",
      "\tGenerated: in train: 4%, assess: 0%, novel: 96%\n",
      "\t ER1 TH L\n",
      "\t P M IY1 EY1 EY0 N\n",
      "\t OY1 P UH1 K R\n",
      "\t M AE1 EY1 S OW0\n",
      "\t JH K R EH1 N CH IH0 EH1\n",
      "CPU times: user 13min 22s, sys: 56.6 s, total: 14min 18s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_params = ModelParams(\n",
    "    rnn_type='gru', embedding_dimension=50, hidden_dimension=50, num_layers=1,\n",
    "    max_epochs=3, early_stopping_rounds=3, batch_size=1024\n",
    ")\n",
    "\n",
    "language_model = LanguageModel(vocab, model_params, device_name='cpu')\n",
    "\n",
    "_ = language_model.fit(pronunciations.pronunciation.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, I'll save the model so I can use it in the next notebook, `Phoneme Exploration.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phoneme_language_model.pt', 'wb') as fh:\n",
    "    model.save(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
