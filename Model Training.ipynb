{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Phoneme Language Model #\n",
    "In this notebook I train a language model over English sounds (also known as [phonemes](https://en.wikipedia.org/wiki/Phoneme)). The data for English pronunciations comes from the CMU Pronouncing Dictionary. The pronunciations in the pronouncing dictionary are in [ARPABET](https://en.wikipedia.org/wiki/ARPABET), a set of symbols representing English sounds. So in ARPABET \"fish\" is pronounced as /F IH1 SH/.\n",
    "\n",
    "By training on tens of thousands of pronunciations the model will hopefully learn [English phonotactics](https://en.wikipedia.org/wiki/Phonotactics#English_phonotactics), the rules that govern what sounds like a valid English word. For example, /F AH1 N/ (\"fun\") sounds good, but /NG S ER1/ (maybe represented as \"ngsr\") does not.\n",
    "\n",
    "\n",
    "Check out the notebook `Phoneme Exploration.ipynb` if you want to see the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sonorous.languagemodel import LanguageModel, ModelParams, Vocabulary\n",
    "from sonorous.pronunciationdata import load_pronunciations\n",
    "from sonorous.utils import split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data ##\n",
    "The data for this model comes from the [CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict), which contains over one hundred thousand pronunciations. Each pronuncation is in [ARPABET](https://en.wikipedia.org/wiki/ARPABET), a set of symbols for representing English speech sounds. In ARPABET the word \"fish\" is represented by the sequence of phonemes /F IH1 SH/. You can probably guess the first and third sounds. The vowel in the middle has \"1\" at the end to indicate it has the primary stress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the `load_pronunciations` function to load the Pronouncing Dictionary into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 124,567 pronunciations.\n",
      "\n",
      "Sample of 5 pronunciations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pappas</th>\n",
       "      <td>(ˈ, p, æ, p, ə, s)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bastedo</th>\n",
       "      <td>(b, ɑː, ˈ, s, t, eɪ, d, oʊ)</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moakley</th>\n",
       "      <td>(ˈ, m, oʊ, k, l, i)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thur</th>\n",
       "      <td>(ˈ, ð, ɝː)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sankyo</th>\n",
       "      <td>(ˈ, s, æ, ŋ, k, j, oʊ)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                                \n",
       "pappas            (ˈ, p, æ, p, ə, s)             5              2   \n",
       "bastedo  (b, ɑː, ˈ, s, t, eɪ, d, oʊ)             7              2   \n",
       "moakley          (ˈ, m, oʊ, k, l, i)             5              2   \n",
       "thur                      (ˈ, ð, ɝː)             2              0   \n",
       "sankyo        (ˈ, s, æ, ŋ, k, j, oʊ)             6              2   \n",
       "\n",
       "         num_primary_stressed_syllables  \n",
       "word                                     \n",
       "pappas                                1  \n",
       "bastedo                               1  \n",
       "moakley                               1  \n",
       "thur                                  1  \n",
       "sankyo                                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations = load_pronunciations()\n",
    "print(f\"There are {len(pronunciations):,} pronunciations.\")\n",
    "print()\n",
    "print(\"Sample of 5 pronunciations:\")\n",
    "pronunciations.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the pronunciation for \"fish\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pronunciation                     (ˈ, f, ɪ, ʃ)\n",
       "num_phonemes                                 3\n",
       "num_syllables                                1\n",
       "num_primary_stressed_syllables               1\n",
       "Name: fish, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['fish']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are all of the pronunciations for the word \"tomato\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tomato</th>\n",
       "      <td>(t, ə, ˈ, m, eɪ, ˌ, t, oʊ)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomato</th>\n",
       "      <td>(t, ə, ˈ, m, ɑː, ˌ, t, oʊ)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                              \n",
       "tomato  (t, ə, ˈ, m, eɪ, ˌ, t, oʊ)             6              3   \n",
       "tomato  (t, ə, ˈ, m, ɑː, ˌ, t, oʊ)             6              2   \n",
       "\n",
       "        num_primary_stressed_syllables  \n",
       "word                                    \n",
       "tomato                               1  \n",
       "tomato                               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['tomato']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model ##\n",
    "The module `languagemodel.py` contains a class `LanguageModel` that implements a simple neural language model. It's a PyTorch neural network comprised of the following layers:\n",
    "1. **Embedding layer** to translate each phoneme into a dense vector. Note that in the code this is called the _encoder since it encodes input phonemes into a representation the model can work with.\n",
    "2. An recurrent neural network (**RNN**) layer that processes each input phoneme sequentially and for each step generates (a) a hidden representation to pass on to the next step and (b) an output.\n",
    "3. A **linear layer** that decodes the outputes (2b) into distributions over each phoneme. Note that in the code this is called the _docoder since it decodes the model's internal representations back into phonemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through a simple example of what happens when we pass the pronunciation /F IH1 SH/ through the model. Ultimately what I want ouf of the model is a prediction at each position of what the next phoneme should be. For example, when a well trained model is sees /F IH1/ it should know that /SH/ is likely, or at least not unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll create a `Vocabulary` instance by passing in all the pronunciations. The `vocab` is used to convert phonemes into integer indices that the neural network handle. It does a few other things too, which you can see below. The `Vocabulary` class's code is in `sonorous/languagemodel.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ˈfɪʃ\n"
     ]
    }
   ],
   "source": [
    "print(''.join(pronunciations.loc['fish'].pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 distinct phonemes.\n",
      "\n",
      "Looking up the int index for /ʃ/: 31\n",
      "\n",
      "Checking whether /ʃ/ is in the vocabulary: True\n",
      "\n",
      "Looking up the phoneme for a specific int index: ʃ\n",
      "\n",
      "Encoding /ˈfɪʃ/: [ 1  4 38  9 31  2]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_texts(pronunciations.pronunciation.values)\n",
    "\n",
    "print(f\"There are {len(vocab)} distinct phonemes.\")\n",
    "print()\n",
    "print(\"Looking up the int index for /ʃ/:\", vocab['ʃ'])\n",
    "print()\n",
    "print(\"Checking whether /ʃ/ is in the vocabulary:\", 'ʃ' in vocab)\n",
    "print()\n",
    "print(\"Looking up the phoneme for a specific int index:\", vocab.token_from_idx(vocab['ʃ']))\n",
    "print()\n",
    "print(\"Encoding /ˈfɪʃ/:\", vocab.encode_text(tuple(\"ˈfɪʃ\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll define the model. Note that I'm not actually fitting the model to any data so the output will be random. The hyperparameters aren't optimal, but again that doesn't matter here since I just want to show the flow of data through the network.\n",
    "\n",
    "The `ModelParams` class (from `sonorous/languagemodel.py` encapsulates hyperparameters and options for the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = ModelParams(\n",
    "    rnn_type='rnn', embedding_dimension=10, hidden_dimension=3, num_layers=1,\n",
    "    max_epochs=3, early_stopping_rounds=3\n",
    ")\n",
    "\n",
    "language_model = LanguageModel(vocab, model_params, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll walk through what happens when we pass the word \"fish\" /F IH1 SH/ through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_pronunciation = tuple(\"ˈfɪʃ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Vocabulary.encode_text` function we saw earlier does a few things. First, it adds dummy `<START>` and `<END>` tokens to the pronunciation indicating its start and end. This allows the model to learn transition probabilities from the start of the word to the first phoneme, and from the last phoneme to the end of the word.\n",
    "\n",
    "It then converts every phoneme to its ingeter index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4 38  9 31  2]\n",
      "\n",
      "1 => <START>\n",
      "4 => ˈ\n",
      "38 => f\n",
      "9 => ɪ\n",
      "31 => ʃ\n",
      "2 => <END>\n"
     ]
    }
   ],
   "source": [
    "fish_input = vocab.encode_text(fish_pronunciation)\n",
    "print(fish_input)\n",
    "print()\n",
    "for idx in fish_input:\n",
    "    phoneme = vocab.token_from_idx(idx)\n",
    "    print(f'{idx} => {phoneme}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to pass the input into the model's `forward` function, which takes in inputs and outputs predictions. This model's `forward` function expects a Tensor of dimension `(batch_size, NUMBER OF STEPS)`. A step here refers to a step forward in the sequence, so /<START> F IH1 SH <END>/ has 5 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input's shape: (6,)\n",
      "Batch input's shape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input's shape:\", fish_input.shape)\n",
    "fish_batch_input = torch.LongTensor(fish_input).unsqueeze(0)\n",
    "print(\"Batch input's shape:\", fish_batch_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing the `forward` function does is embed each phoneme using an [nn.Embedding](https://pytorch.org/docs/stable/nn.html#embedding). Each phoneme has a dedicated embedding vector of length `embedding_dimension`, so the shape of `embedded` is `(batch size, number of steps, embedding_dimension)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 10])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0702, -0.0878,  1.0488,  1.6095,  2.1078,  1.2971,  0.4692,\n",
       "           0.2504,  0.4908, -0.2086],\n",
       "         [-0.5052, -0.1303,  2.6945,  0.4872, -1.0471, -0.3601, -1.2850,\n",
       "          -2.1139, -1.3659, -1.0605],\n",
       "         [ 1.2538,  0.0173, -0.0690,  0.7895,  1.7514,  0.1740, -0.4033,\n",
       "          -0.7597, -0.5434,  0.4726],\n",
       "         [ 2.4930, -0.5973, -1.6396,  0.0426,  1.0717,  1.9867,  0.4249,\n",
       "          -0.5035,  0.9816,  1.4325],\n",
       "         [ 0.1882, -1.6113,  0.6758,  0.2947, -1.0157,  3.7469, -1.7828,\n",
       "          -0.6747,  0.9082,  0.2381],\n",
       "         [ 0.3316,  1.5206,  0.7191,  0.3741,  1.2754, -0.3685, -0.2283,\n",
       "           0.2486, -0.9748, -0.6877]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = language_model._encoder(fish_batch_input)\n",
    "print(embedded.shape)\n",
    "print()\n",
    "embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll pass `embedded` to the [RNN layer](https://pytorch.org/docs/stable/nn.html#recurrent-layers), resulting in `rnn_output` and `hidden_state`. I won't go into detail on how RNNs work since there are many detailed posts on the web you can read, but the basic idea is a cell is applied sequentially to every token (i.e. step) in the input. At each step an output and a hidden state are produced. The hidden state can be passed on to the next step, and the output can be used to make a prediction.\n",
    "\n",
    "The `rnn` layer below operates on the full sequence, so the results are for the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 3])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9590, -0.2611, -0.3243],\n",
       "         [-0.4472,  0.9664, -0.9934],\n",
       "         [ 0.8957, -0.6811, -0.6081],\n",
       "         [ 0.9948, -0.7902,  0.5413],\n",
       "         [ 0.8693,  0.9834, -0.6951],\n",
       "         [ 0.7104, -0.4971, -0.3664]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output, hidden_state = language_model._rnn(embedded)\n",
    "print(rnn_output.shape)\n",
    "print()\n",
    "rnn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our application we can ignore the `hidden_state`-- the `rnn_output` is the interesting part. The first dimension is for the batch, and we only have a single input in our batch. The second dimension is for each of the input phonemes. The third dimension corresponds to `hidden_dimension`: you can think of this as the state of the RNN at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said at the beginning of this section, I want the output of the RNN at each position to be predictions for the *next* position. So I'll apply a [linear layer](https://pytorch.org/docs/stable/nn.html#linear) to the `rnn_output`, resulting in a vector the size of the vocabularly at each position. The [softmax](https://pytorch.org/docs/stable/nn.functional.html#softmax) function normalizes the outputs into probability distributions for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 47])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = language_model._decoder(rnn_output)\n",
    "probabilities = F.softmax(outputs, dim=-1).squeeze()\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of `probabilities` is (5, 42) because each of the five tokens in /ˈfɪʃ/ gets a a probability distribution over each of the 42 phonemes in the vocabulary.\n",
    "\n",
    "The first phoneme in the input is the `<START>` token; let's see what the model thinks should come next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_for_first_phoneme = probabilities[0]\n",
    "most_likely_first_phoneme_idx = probabilities_for_first_phoneme.argmax().item()\n",
    "most_likely_first_phoneme = vocab.token_from_idx(most_likely_first_phoneme_idx)\n",
    "most_likely_first_phoneme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model predicts /ŋ/ to be the first phoneme in the word. Since the model isn't fit yet this is just a random guess. In order to get the model to make good predictions I'll need to first train a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Model ##\n",
    "In this section I'll train a number of models on the train set and select the one that has the lowest error on the dev set. I'll split the DataFrame of pronunciations into three DataFrames, with 79% for training, 20% for dev/validation, and 1% for testing of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98407, 24914, 1246)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations, dev_pronunciations, test_pronunciations = split_data(pronunciations, dev_proportion=.2, test_proportion=.01)\n",
    "len(train_pronunciations), len(dev_pronunciations), len(test_pronunciations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I ran a larger parameter search before and saw that GRUs were consistently outperforming LSTMs and vanilla RNNs. There are 12 (4 * 3) models to train, and for each one I'm measuring train and dev error at every epoch. So if each model trains for the maximum of 2,000 epochs I would end up with 12 * 2,000 = 24,000 models to choose from. There's a good chance I'm overfitting the dev set with such a large search, but I'll inspect the learning curves to try to avoid selecting an iteration that randomly did well.\n",
    "\n",
    "While each model trains for a maximum of 2000 epochs, it stops early if the dev error does not decrease for three epochs in a row. Since I'm going to be selecting the model with the lowest dev error there's no reason to keep training a model once it's started overfitting. Alternatively I could train all models to convergence and then add regularization to reduce the complexity and identify the sweet spot, but that's far more time consuming because it requires training more models and each of them for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check errors before fitting\n",
    "* overfit a small set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 1.1036\tdev loss: 0.9862                                                                                             \n",
      "\tGenerated: in train: 1%, assess: 0%, novel: 99%\n",
      "\t ʒ v ə i\n",
      "\t eɪ j f j i aʊ n ə ˌ aɪ ˈ\n",
      "\t ˈ ʒ i p l\n",
      "\t ˈ ɪ z uː j θ ʌ d ɛ uː t\n",
      "\t r ʃ dʒ uː ʌ ɔɪ ɝ ɝ p aʊ h ʌ h eɪ\n",
      "Epoch 2: train loss: 0.8437\tdev loss: 0.7338                                                                                             \n",
      "\tGenerated: in train: 4%, assess: 0%, novel: 96%\n",
      "\t \n",
      "\t ˈ p aɪ p p z\n",
      "\t b ʌ ɑː ŋ i\n",
      "\t ˈ ŋ l ʒ tʃ ɔɪ ɪ\n",
      "\t ˈ θ oʊ iː\n",
      "Epoch 3: train loss: 0.7594\tdev loss: 0.6554                                                                                             \n",
      "\tGenerated: in train: 4%, assess: 0%, novel: 96%\n",
      "\t ˈ r eɪ n d\n",
      "\t \n",
      "\t ˈ ʌ eɪ n θ k ɝ\n",
      "\t ˈ ɔɪ t l\n",
      "\t ˈ ɑː k ɪ ʊ t eɪ uː t i\n",
      "Epoch 4: train loss: 0.7143\tdev loss: 0.6142                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t ˈ b t h oʊ\n",
      "\t ˈ k oʊ n s\n",
      "\t ˈ s aɪ m d r\n",
      "\t ˈ t uː r\n",
      "\t ˈ k l t eɪ aʊ\n",
      "Epoch 5: train loss: 0.6828\tdev loss: 0.5859                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t ˈ s n iː t\n",
      "\t ˈ h ɪ ə d ɑː aʊ\n",
      "\t ˈ ŋ iː\n",
      "\t ˈ z t t ə ʒ k r ə l s ɝː i\n",
      "\t ˈ ɛ n b iː\n",
      "Epoch 6: train loss: 0.6585\tdev loss: 0.5646                                                                                             \n",
      "\tGenerated: in train: 4%, assess: 1%, novel: 95%\n",
      "\t ˈ b ɑː uː d t ə n ɪ n ɝ t\n",
      "\t ˈ k ɑː s ɪ ŋ k ŋ\n",
      "\t ˈ d ɑː l ɔ g\n",
      "\t ˈ k eɪ z s z\n",
      "\t θ ˈ ŋ r ɛ g ə\n",
      "Epoch 7: train loss: 0.6398\tdev loss: 0.5481                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 0%, novel: 97%\n",
      "\t ˈ l ɑː ɛ l ɪ n r\n",
      "\t ˈ w ɛ b ə t ə ɪ\n",
      "\t ˈ ə k ɪ s ʌ n z f\n",
      "\t ˈ ɝː d z ə aɪ\n",
      "\t f æ ˈ w ɑː l ɪ s w\n",
      "Epoch 8: train loss: 0.6264\tdev loss: 0.5363                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ r ɛ n t ə s\n",
      "\t ˈ m\n",
      "\t ˈ s l iː ə t ə n ə z\n",
      "\t z ʌ n ɪ ˈ k ɪ n ɝ ɪ s ŋ\n",
      "\t ˈ l ɑː v uː g\n",
      "Epoch 9: train loss: 0.6151\tdev loss: 0.5265                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t ˈ r æ l k ə n\n",
      "\t θ ʊ ˈ k h ɛ tʃ ɝ d\n",
      "\t m ɪ ˈ ŋ r æ d\n",
      "\t ˈ n v ʌ l t æ ə m l\n",
      "\t ˈ s w ɛ l ə l ə n\n",
      "Epoch 10: train loss: 0.6061\tdev loss: 0.5186                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ k r iː ɝ\n",
      "\t ˈ m uː w ɪ p z\n",
      "\t m iː ˈ p eɪ d\n",
      "\t ɪ tʃ ɪ ˈ s ɛ r ɝ\n",
      "\t ˈ f h f r ɪ ɛ k s\n",
      "Epoch 11: train loss: 0.5990\tdev loss: 0.5123                                                                                             \n",
      "\tGenerated: in train: 2%, assess: 2%, novel: 96%\n",
      "\t ʃ ɪ ˈ h æ n d ə k z\n",
      "\t ˈ n ʌ\n",
      "\t ˈ n iː t l ɝ z\n",
      "\t ˈ n r b ɑː d ɪ s\n",
      "\t ˈ iː l ə v ə\n",
      "Epoch 12: train loss: 0.5930\tdev loss: 0.5071                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 2%, novel: 92%\n",
      "\t p ə v ɪ ˈ n ɑː d l d ə n\n",
      "\t ˈ h r aɪ s ə k z\n",
      "\t ˈ g oʊ n d t oʊ\n",
      "\t ˈ ˈ n d iː k n\n",
      "\t k oʊ ˈ m oʊ n\n",
      "Epoch 13: train loss: 0.5880\tdev loss: 0.5027                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t ˈ p ʊ l i\n",
      "\t ˈ k ɝː l\n",
      "\t r s ɝ ˈ h ɛ ˌ s ɛ t s ə l d\n",
      "\t ʒ k oʊ ˈ h iː d\n",
      "\t ɪ ˈ p ɑː g n i\n",
      "Epoch 14: train loss: 0.5838\tdev loss: 0.4990                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ʒ r iː ˈ s ɑː k n\n",
      "\t ˈ b ɔ r ɪ s m\n",
      "\t ˈ k ɪ h iː g ə n\n",
      "\t ˌ m ɑː r ə ɝː k s ə ˌ h iː n ɪ h ɪ ˈ n ɑː l ɪ k\n",
      "\t k ˈ eɪ m\n",
      "Epoch 15: train loss: 0.5803\tdev loss: 0.4960                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˌ v ʊ ˈ f iː z\n",
      "\t ˈ s p ɔ n z\n",
      "\t ˈ m ɛ n z ʊ ŋ\n",
      "\t ˈ n ɑː r s\n",
      "\t n ɪ ˈ m ɛ r\n",
      "Epoch 16: train loss: 0.5773\tdev loss: 0.4934                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t r aɪ ˈ p ɑː r d l\n",
      "\t ə\n",
      "\t ˈ r iː aɪ\n",
      "\t ˈ p ɝː p t i\n",
      "\t ˈ b ɑː ˈ w ɛ n\n",
      "Epoch 17: train loss: 0.5747\tdev loss: 0.4911                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ɪ ˈ m r aɪ z ə t\n",
      "\t ˈ d ɑː l ɪ ŋ\n",
      "\t ˈ b ˌ s ɛ k t d\n",
      "\t m ə ˈ s iː k ə k ˌ k oʊ g\n",
      "\t ˈ n iː iː\n",
      "Epoch 18: train loss: 0.5723\tdev loss: 0.4890                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ n uː ˌ ɪ s t\n",
      "\t ˈ r ʌ s t ə m\n",
      "\t ˈ s aɪ oʊ\n",
      "\t ˈ oʊ f i\n",
      "\t ˌ n eɪ ˈ t l æ l m ə l\n",
      "Epoch 19: train loss: 0.5702\tdev loss: 0.4872                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t ˈ k oʊ l\n",
      "\t ˈ f r æ k r ə ŋ z\n",
      "\t ˌ w eɪ ˈ p r æ t ˌ k eɪ\n",
      "\t ə m\n",
      "\t ˈ h eɪ t\n",
      "Epoch 20: train loss: 0.5682\tdev loss: 0.4855                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 2%, novel: 93%\n",
      "\t ˈ t s r m uː\n",
      "\t ˈ eɪ s\n",
      "\t r ɪ ˈ iː ə l i\n",
      "\t ð ɝ ˈ dʒ ɪ n d ɛ ə d\n",
      "\t ˈ h ɔ r ɪ ŋ\n",
      "Epoch 21: train loss: 0.5665\tdev loss: 0.4839                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ d æ l\n",
      "\t ˈ f ɝː tʃ ə k ə l\n",
      "\t m ə ˈ l ʌ f l ɝ\n",
      "\t ˈ m ʌ ˌ r ɛ s s\n",
      "\t ˈ t ɛ g r ɪ n\n",
      "Epoch 22: train loss: 0.5648\tdev loss: 0.4825                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t s ə ˈ tʃ ɪ tʃ uː\n",
      "\t ˈ k l ʊ s ə\n",
      "\t ˌ ɪ ˈ k ʌ l\n",
      "\t ˈ d r iː iː ˌ b ɪ l\n",
      "\t k ə ə d f ɪ ˈ k r æ t l ɝ ð i\n",
      "Epoch 23: train loss: 0.5632\tdev loss: 0.4811                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ ə l uː n\n",
      "\t ˈ v ɛ ɔ l\n",
      "\t ˈ b ʌ s t oʊ d\n",
      "\t ˈ ɝː ˌ l ɔ r t\n",
      "\t ˈ g r ɛ z ə d l\n",
      "Epoch 24: train loss: 0.5617\tdev loss: 0.4798                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ b r iː k\n",
      "\t ˈ k æ f iː ˌ ɪ n z\n",
      "\t ˈ r aɪ t ə l\n",
      "\t ˈ r ɔ f\n",
      "\t ˈ h ɑː r ˈ ʃ uː n t\n",
      "Epoch 25: train loss: 0.5603\tdev loss: 0.4786                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 4%, novel: 88%\n",
      "\t iː ˈ l ɪ t n\n",
      "\t ˈ m aɪ n z\n",
      "\t ˈ g oʊ l\n",
      "\t ˈ l ʌ l\n",
      "\t ˈ m w æ s\n",
      "Epoch 26: train loss: 0.5589\tdev loss: 0.4775                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t ˈ ɑː r d ɑː k ɪ s\n",
      "\t ˈ l ɛ l ʊ t ɝ\n",
      "\t ˈ k ɛ\n",
      "\t ˈ w oʊ s iː ɪ ʃ t\n",
      "\t ˈ w aɪ l ə n\n",
      "Epoch 27: train loss: 0.5577\tdev loss: 0.4764                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ r aɪ l ɝ\n",
      "\t ˈ v j uː ə t\n",
      "\t ˈ ʃ oʊ n ɪ b\n",
      "\t ˈ v ɔ r ə m\n",
      "\t s ɪ k ˈ n iː r ɪ t eɪ\n",
      "Epoch 28: train loss: 0.5565\tdev loss: 0.4754                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t ˈ ɑː l k ˌ t ɛ f ə n\n",
      "\t ˈ ˌ r ɛ d oʊ\n",
      "\t ˈ ʌ g ˌ r aʊ s\n",
      "\t k ə ˈ g ɛ n d ɝ\n",
      "\t r ɛ ˈ z ɛ k ə n\n",
      "Epoch 29: train loss: 0.5554\tdev loss: 0.4745                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ t r ɔ r ə\n",
      "\t ə ˈ g r aɪ d ɪ d\n",
      "\t ˈ r æ z\n",
      "\t ˈ s t ɛ n z\n",
      "\t b r ə ˈ n ɪ p ɛ p ɝ ˌ d oʊ\n",
      "Epoch 30: train loss: 0.5545\tdev loss: 0.4738                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 5%, novel: 85%\n",
      "\t ˈ f r ɑː ˌ p ɝː\n",
      "\t ˈ m ɛ d r æ k ɪ f ɪ ŋ\n",
      "\t ˈ l eɪ l\n",
      "\t ˈ tʃ ɛ p s ə\n",
      "\t ˈ p iː l ə\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train loss: 0.5535\tdev loss: 0.4730                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ b ʌ l z ɝ\n",
      "\t ˈ t ɪ f t ɝ ə l\n",
      "\t ˈ d ɛ k ə v ɝ\n",
      "\t ˈ tʃ æ l s ɝ\n",
      "\t ˈ m ɪ k ɝː d\n",
      "Epoch 32: train loss: 0.5528\tdev loss: 0.4723                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ˈ b r ɛ l ə ŋ\n",
      "\t ˌ s n ɑː ʒ iː ˈ æ l s k\n",
      "\t ˈ oʊ ˌ æ n b\n",
      "\t ˈ n ɛ tʃ ɪ k\n",
      "\t ˈ f r aɪ d ə d\n",
      "Epoch 33: train loss: 0.5520\tdev loss: 0.4716                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 4%, novel: 81%\n",
      "\t ˈ h ɑː r p t i\n",
      "\t ˈ g ɛ l ɪ v ɪ t\n",
      "\t ˈ b j r uː d\n",
      "\t ˈ g ɛ r ɪ d\n",
      "\t m ə ˈ s p k eɪ n\n",
      "Epoch 34: train loss: 0.5511\tdev loss: 0.4709                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ʒ ɪ ˈ m ɝː ə\n",
      "\t ˈ s ɪ r ɪ ŋ\n",
      "\t d ɪ ˈ t r ɔɪ ˌ f iː n\n",
      "\t ˈ m ɪ n ɪ ŋ\n",
      "\t ˈ ɪ n s ə ˌ z aɪ t\n",
      "Epoch 35: train loss: 0.5504\tdev loss: 0.4703                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 5%, novel: 84%\n",
      "\t ˌ iː r ɪ ʒ ə ˈ g l eɪ s v ə n\n",
      "\t ˈ oʊ z ɪ d\n",
      "\t ˈ b ɑː n d ə ˌ l ɪ d i\n",
      "\t ˈ s aɪ ˈ k l ɛ n\n",
      "\t ˈ s r ɛ p\n",
      "Epoch 36: train loss: 0.5496\tdev loss: 0.4696                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 3%, novel: 92%\n",
      "\t ˈ iː d r ɪ ˌ v ɪ l iː t ɪ ŋ\n",
      "\t ˈ m uː k ɪ k\n",
      "\t ˈ t uː m ɪ n ə\n",
      "\t ˌ m ɑː l ˈ m æ l t ə\n",
      "\t ˈ d ɪ b θ iː ˌ tʃ oʊ d z\n",
      "Epoch 37: train loss: 0.5489\tdev loss: 0.4691                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 4%, novel: 91%\n",
      "\t r ɛ ˈ dʒ ɑː ŋ b d\n",
      "\t ˈ h eɪ l ɪ z z\n",
      "\t ˈ s r uː k\n",
      "\t ˈ t w ɪ k oʊ l i\n",
      "\t ˌ aʊ t s ə ˈ t r ɪ k ʃ ə n\n",
      "Epoch 38: train loss: 0.5483\tdev loss: 0.4685                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t z ˈ s æ p s\n",
      "\t ˈ m ɑː s t r ə n\n",
      "\t ˈ b uː n dʒ ə s\n",
      "\t ˈ h ɔ r p ɪ k s\n",
      "\t ˈ b r eɪ f\n",
      "Epoch 39: train loss: 0.5477\tdev loss: 0.4680                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ s ə ˌ b r ɑː r g ə z\n",
      "\t ˈ j uː s ə\n",
      "\t ˈ s t oʊ b ɝ z\n",
      "\t ˈ p ɝː k r ɪ f\n",
      "\t ˈ l ɛ aʊ n ɪ z\n",
      "Epoch 40: train loss: 0.5471\tdev loss: 0.4675                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ g ɝː k i\n",
      "\t ˈ w ɪ l k ˌ l aʊ t\n",
      "\t ˈ l ɔ d r ə b ə ˌ l iː\n",
      "\t ˈ t ʌ f z\n",
      "\t ˈ m ɪ r ɪ k s\n",
      "Epoch 41: train loss: 0.5466\tdev loss: 0.4671                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t j uː ˈ g l æ g ɑː g\n",
      "\t ˈ æ n d i\n",
      "\t ˈ h ɝː k s\n",
      "\t s t æ r ə n ˈ d uː d iː ə ˌ g ə d ə v l z\n",
      "\t ˌ m ɑː n ə ˈ aʊ z ɪ ŋ\n",
      "Epoch 42: train loss: 0.5460\tdev loss: 0.4666                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ w ɔ l m ə n\n",
      "\t r ɪ ˈ n ɑː k\n",
      "\t ˈ k r ɑː n oʊ\n",
      "\t ˌ ɛ l ɝː ˈ p iː r ɪ ŋ\n",
      "\t ˈ b r uː s t\n",
      "Epoch 43: train loss: 0.5455\tdev loss: 0.4662                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t r ɪ ˈ h eɪ d ɝ\n",
      "\t ˈ b r ʌ s ɪ z\n",
      "\t ˈ w ɛ n d b ə l b ɝ d\n",
      "\t ˈ ʃ ɛ ʃ n ɝ ˌ k r iː s\n",
      "\t k ɝ ˌ aɪ ˈ f eɪ dʒ i\n",
      "Epoch 44: train loss: 0.5449\tdev loss: 0.4657                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ l ɪ l ˌ v ɛ t\n",
      "\t ˈ f aɪ ɝ\n",
      "\t m oʊ ˈ s ɔ r t r uː s ə n t i\n",
      "\t ˌ ɛ l oʊ ˈ oʊ t\n",
      "\t h uː p ɝ ˈ iː ə d\n",
      "Epoch 45: train loss: 0.5444\tdev loss: 0.4653                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ h ɔ r m ə n\n",
      "\t ˈ d ʌ ˌ k ɑː ˌ g iː z\n",
      "\t ˈ s m ɪ s t ɝ\n",
      "\t ˈ b r ɔ r b ə\n",
      "\t ˈ g aɪ l ɝ\n",
      "Epoch 46: train loss: 0.5439\tdev loss: 0.4649                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ t r ɝː d\n",
      "\t z iː ˈ k ɛ r i\n",
      "\t ˈ f ɔ r g r oʊ ˌ t uː n d\n",
      "\t ˈ b ɔ s ə n\n",
      "\t ɝ ˈ b ɛ r iː ə n\n",
      "Epoch 47: train loss: 0.5435\tdev loss: 0.4646                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ t iː ˌ s t oʊ\n",
      "\t ˈ ʃ ɔ r i\n",
      "\t ˈ m aɪ ˈ t ɪ k k i\n",
      "\t ˈ m ɑː k ˌ w b r uː\n",
      "\t ˈ m ɑː n d w iː ə k\n",
      "Epoch 48: train loss: 0.5430\tdev loss: 0.4642                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t r d uː ˈ t ɪ t ə\n",
      "\t s ə ˈ l ɑː d ə\n",
      "\t r uː ˈ m ɑː r s ɪ s t\n",
      "\t ˌ b ɪ r ˈ ð eɪ m\n",
      "\t ˈ d ʌ s ɪ s k ɪ ŋ\n",
      "Epoch 49: train loss: 0.5426\tdev loss: 0.4639                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ s m æ l ɝ\n",
      "\t ˈ m ɔ r t\n",
      "\t ˈ k ɪ s p ɝ l ɪ ŋ\n",
      "\t ˈ s ɪ m p ˌ v iː d\n",
      "\t ˈ p ɝː t ə n\n",
      "Epoch 50: train loss: 0.5422\tdev loss: 0.4635                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ θ æ n t ə ˌ l ɛ l\n",
      "\t oʊ ˈ z iː n eɪ t s\n",
      "\t ˈ k ɝː v ɪ ŋ v ɝ ˈ z m ɑː g\n",
      "\t k ɔ r ˈ k ə n ə t ɪ ŋ\n",
      "\t ˈ f ɪ t s\n",
      "Epoch 51: train loss: 0.5418\tdev loss: 0.4631                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ æ n ˌ v ɛ s\n",
      "\t ˈ d iː z ˌ p ɛ s t\n",
      "\t ˈ t ɛ m h oʊ\n",
      "\t ˈ f r iː iː ə n\n",
      "\t ˈ m æ v ɝ d ɝ\n",
      "Epoch 52: train loss: 0.5414\tdev loss: 0.4629                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ s l aɪ k ˌ t r aɪ v\n",
      "\t ˈ l ɔɪ d ɪ k\n",
      "\t ˈ k ɑː k ɑː n\n",
      "\t ˈ t r ɔ n ɝ\n",
      "\t ˈ s ʌ k ɪ k\n",
      "Epoch 53: train loss: 0.5409\tdev loss: 0.4625                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ˈ k r oʊ ˌ h ɔ\n",
      "\t ˈ f r aɪ n ˌ t r æ k s\n",
      "\t d ə ˈ l ɪ f ə m\n",
      "\t ˈ b ɛ s t iː ə n\n",
      "\t ˈ b l æ g n ə\n",
      "Epoch 54: train loss: 0.5407\tdev loss: 0.4623                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t b ɛ n ˈ z eɪ z\n",
      "\t ˈ m ɔ r t s\n",
      "\t ˈ θ ɛ m t ɝ\n",
      "\t ˈ h eɪ l ˌ w ɝː dʒ\n",
      "\t ˈ t ɑː ŋ v ɝ l\n",
      "Epoch 55: train loss: 0.5404\tdev loss: 0.4620                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ v ɑː s i\n",
      "\t ˈ s t ɪ k ə l z i\n",
      "\t ˈ l oʊ s ə l t ɝ\n",
      "\t ˈ b ɑː ʃ ə n\n",
      "\t ˈ b ɔ r t ə m\n",
      "Epoch 56: train loss: 0.5399\tdev loss: 0.4616                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t ˈ g iː k iː ə n t i\n",
      "\t ˈ k æ k ɪ ʃ n\n",
      "\t ˈ ʃ ɪ ˌ b ɑː n z ɪ ŋ\n",
      "\t ˈ h ɔ m ˈ t iː l\n",
      "\t ɛ n t ɑː ˈ v aɪ ˌ b æ k\n",
      "Epoch 57: train loss: 0.5397\tdev loss: 0.4615                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ t æ m\n",
      "\t ˈ l ɪ m\n",
      "\t ˈ g uː d ə k\n",
      "\t ˈ s ɪ n oʊ ˌ s ɪ d\n",
      "\t iː ˈ ˌ l ʌ k\n",
      "Epoch 58: train loss: 0.5394\tdev loss: 0.4612                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t b ə ˈ aɪ d\n",
      "\t ˈ d j uː n\n",
      "\t ˈ g ɑː k i\n",
      "\t ˈ ð aʊ g ə n\n",
      "\t j uː ˈ g r eɪ ʃ ə l z\n",
      "Epoch 59: train loss: 0.5388\tdev loss: 0.4607                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ˈ f ɑː k dʒ ɪ z\n",
      "\t ˈ g r ɔ ə s\n",
      "\t ˈ ʌ f t m ə n\n",
      "\t ˈ n ɔ r ɪ ˌ d ɛ t\n",
      "\t ˈ w ɝː tʃ n aɪ f ˌ t ɝː\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: train loss: 0.5387\tdev loss: 0.4606                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ɪ ˈ h ɑː r t ə n t ɪ ŋ\n",
      "\t ˈ t ɑː r ɔ n\n",
      "\t k ɑː b ɔ ˈ k ɑː t ə l\n",
      "\t ˈ r ɔɪ s\n",
      "\t ˈ g æ s t r ə n\n",
      "Epoch 61: train loss: 0.5384\tdev loss: 0.4604                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ h aʊ s t\n",
      "\t r iː ˈ d ɝː t w i\n",
      "\t ˈ æ n ɪ t s\n",
      "\t ˈ k aɪ oʊ s n ɝ oʊ m\n",
      "\t ˈ f w eɪ z ɛ d\n",
      "Epoch 62: train loss: 0.5381\tdev loss: 0.4601                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ l ɛ g n ə n\n",
      "\t ˈ s æ n d oʊ\n",
      "\t ˈ k æ s\n",
      "\t ˌ s ɪ n ʃ ə n ˈ p ɑː r t s\n",
      "\t ˈ æ n d ˌ h eɪ m\n",
      "Epoch 63: train loss: 0.5380\tdev loss: 0.4600                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ h ɔ f t s\n",
      "\t ˈ b ɔ f ɝ t\n",
      "\t ˈ dʒ ɔɪ iː ə ˌ s p ɔ t\n",
      "\t ˌ p ɛ r ə ˈ dʒ ɪ n ə\n",
      "\t k ɑː ˈ r uː ʒ ə n z\n",
      "Epoch 64: train loss: 0.5375\tdev loss: 0.4597                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ b aɪ r dʒ ə n ə n\n",
      "\t s ə ˈ p l ʊ r\n",
      "\t ˈ ʃ ɪ k ɝ z\n",
      "\t r ɪ ˈ s iː t s\n",
      "\t ˈ g r uː m ə ɪ ŋ\n",
      "Epoch 65: train loss: 0.5374\tdev loss: 0.4595                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t b aɪ ˈ ɛ l ə ˌ f ɛ r\n",
      "\t ˈ m ɛ m ɪ d\n",
      "\t r ɪ ˈ v ɑː r f\n",
      "\t ˈ h æ l ə b ə s\n",
      "\t ˈ w ɪ r l\n",
      "Epoch 66: train loss: 0.5371\tdev loss: 0.4593                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ h ɔ r t ɪ ˌ n ɛ r\n",
      "\t d ə ˈ k r iː v\n",
      "\t ˈ b l æ f ˌ b æ m ə t s\n",
      "\t ˈ k l ɛ s d ˌ s t r oʊ p t\n",
      "\t m ɑː p m ɑː ˈ n eɪ t iː ə\n",
      "Epoch 67: train loss: 0.5369\tdev loss: 0.4591                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t k ə ˈ v oʊ n ɝ\n",
      "\t ˈ m æ v ɝ l iː n\n",
      "\t ˈ eɪ dʒ ə n\n",
      "\t ˈ æ tʃ iː ɪ ŋ\n",
      "\t ˈ b r eɪ tʃ\n",
      "Epoch 68: train loss: 0.5368\tdev loss: 0.4591                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t ɝ ˈ iː n\n",
      "\t ˈ p iː n ɪ k\n",
      "\t ˈ m ɛ ˌ d r ɛ k s\n",
      "\t b oʊ ˈ s ɛ s\n",
      "\t ˈ k æ m ə n ˌ h eɪ g z\n",
      "Epoch 69: train loss: 0.5366\tdev loss: 0.4590                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t m ɑː ˈ n ɑː r\n",
      "\t ˈ k ʌ k ɝ ə z\n",
      "\t ə ˈ dʒ ɪ m ə t\n",
      "\t ˈ p ɑː f ə s\n",
      "\t ˈ b ɪ v ə n\n",
      "Epoch 70: train loss: 0.5363\tdev loss: 0.4586                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ˈ b r ɪ n m ɝ\n",
      "\t ə ˈ p ɑː l ɝ\n",
      "\t ˈ m ɛ p ˌ d ɪ h\n",
      "\t ˈ k ɝː h ə ˌ m ɔ r ə\n",
      "\t ˈ m ɪ k\n",
      "Epoch 71: train loss: 0.5362\tdev loss: 0.4586                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˌ ɛ v ə ˈ n eɪ n r ə s\n",
      "\t k ə ˈ l iː θ\n",
      "\t ˈ t r ɔ r ə b ə n t\n",
      "\t ˈ f oʊ l d ɝ z\n",
      "\t ˈ b æ m p l i\n",
      "Epoch 72: train loss: 0.5359\tdev loss: 0.4584                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t r ɪ ˈ k l iː\n",
      "\t ˈ p oʊ l ˈ t ʌ v ɝ ˌ s æ k ˌ l aʊ l z\n",
      "\t h oʊ k l ə ˈ k w ɑː r\n",
      "\t ˈ r ʌ ˌ s k ɝː k ə d\n",
      "\t ˈ d w oʊ l k ɪ k\n",
      "Epoch 73: train loss: 0.5356\tdev loss: 0.4581                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t ˈ l ɛ m t ə l\n",
      "\t ˈ s n r ɔ\n",
      "\t ˈ h ɔ r ˌ k eɪ d\n",
      "\t ˈ r ɑː k i\n",
      "\t ˈ b ʌ n ɪ ŋ\n",
      "Epoch 74: train loss: 0.5355\tdev loss: 0.4580                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t ˈ h iː r ə n\n",
      "\t ˈ uː ˌ b aɪ\n",
      "\t ˈ k oʊ b ɝ\n",
      "\t ˈ aɪ d ə\n",
      "\t ˈ æ b r iː z\n",
      "Epoch 75: train loss: 0.5355\tdev loss: 0.4580                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ə ˈ l ɔ t l i\n",
      "\t ˈ l ɪ ŋ l ə ˌ n ɛ t i\n",
      "\t ˈ s t ɔ r ˌ b l ɪ d\n",
      "\t ˌ ɔ r ˈ d eɪ z\n",
      "\t ˈ s ɝː ˌ k æ t\n",
      "Epoch 76: train loss: 0.5353\tdev loss: 0.4579                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ æ l ə n z\n",
      "\t ˈ ɔ l g ˌ d w oʊ t\n",
      "\t ˈ t ɪ ˈ t ɑː m ɝ ˌ b eɪ ˌ t r ɪ n dʒ ə ˌ k ɔ l t s\n",
      "\t z ɪ ˈ d ɪ s t ɪ ŋ\n",
      "\t æ t ɝ z ˈ f ɑː r z\n",
      "Epoch 77: train loss: 0.5349\tdev loss: 0.4575                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ k ɛ n tʃ ɝ z\n",
      "\t ˈ t ɑː m p ə s t ɛ f\n",
      "\t ˈ l ɑː v\n",
      "\t ˈ m ɑː g r ə m ɝ\n",
      "\t ˈ g r oʊ b ə l z\n",
      "Epoch 78: train loss: 0.5349\tdev loss: 0.4575                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ m ɑː b\n",
      "\t ˈ ʌ t ˌ p j uː\n",
      "\t ˌ ə m ˈ b æ f iː ˌ l aɪ d d\n",
      "\t ˈ f ɑː b ˌ t r ɛ n\n",
      "\t ˈ æ n ɪ n ˌ s ɛ r\n",
      "Epoch 79: train loss: 0.5347\tdev loss: 0.4574                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ˈ g ɪ n tʃ i\n",
      "\t z iː ˈ ɑː t t\n",
      "\t æ ŋ t ˈ d ɝː ʃ ə k ə l\n",
      "\t ˈ w iː\n",
      "\t ˈ s k ɑː m ɪ k\n",
      "Epoch 80: train loss: 0.5346\tdev loss: 0.4573                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ k eɪ s t ɝ ɝ\n",
      "\t d ɪ ˈ s t ɛ n t ɪ t ɪ ŋ\n",
      "\t d ɪ ˈ s t ɛ r iː ɝ\n",
      "\t ˈ v æ d ɪ k\n",
      "\t ˈ t r ɛ k s ə n\n",
      "Epoch 81: train loss: 0.5344\tdev loss: 0.4572                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˌ g r uː ˈ t oʊ n t r ə ŋ\n",
      "\t k ə k s ɝ ˈ æ k t ɑː k\n",
      "\t ˈ k w aɪ n d ɪ ŋ\n",
      "\t ɪ n ˈ b ɪ n ɝ\n",
      "\t ˈ f ɔ l d\n",
      "Epoch 82: train loss: 0.5343\tdev loss: 0.4570                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ æ ð ˌ w ɛ t s\n",
      "\t ˌ eɪ θ oʊ ˈ s æ k n uː ə l\n",
      "\t ˌ g ɝː d ə ˈ d r ɛ t ɝ ˌ eɪ t ɪ g ə n\n",
      "\t ˈ g æ d l ɪ ˌ n iː g ɝ\n",
      "\t ˈ w ɪ ŋ k iː l ɝ\n",
      "Epoch 83: train loss: 0.5341\tdev loss: 0.4569                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ oʊ b ɝ z\n",
      "\t ˈ p ɛ d k i\n",
      "\t ˈ p uː θ ə n\n",
      "\t v iː ˈ m ɛ t s\n",
      "\t ˈ k ɝː t r ə n\n",
      "Epoch 84: train loss: 0.5341\tdev loss: 0.4568                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ˈ t eɪ b ɝ t\n",
      "\t ˈ r aʊ n ə t ɝ\n",
      "\t ˈ h oʊ n ˌ k ɛ s\n",
      "\t ˈ æ g oʊ\n",
      "\t ˈ ə d iː k\n",
      "Epoch 85: train loss: 0.5340\tdev loss: 0.4568                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t r ɑː ˈ s eɪ n d\n",
      "\t ˈ h ɔɪ d ɝ\n",
      "\t ˈ b eɪ n k j uː l i\n",
      "\t ˈ ʃ ɛ k ɝ ˌ f ɛ r\n",
      "\t ˈ θ iː l ɪ ŋ\n",
      "Epoch 86: train loss: 0.5338\tdev loss: 0.4566                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ b æ k j uː l ɪ t\n",
      "\t ˈ n ɛ l ə n\n",
      "\t ˈ w ʊ m ˌ h ɑː r t z i\n",
      "\t ˈ p ɔ r t ə l\n",
      "\t ˈ g æ g ə n z\n",
      "Epoch 87: train loss: 0.5337\tdev loss: 0.4566                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ f l æ s ə z\n",
      "\t r ə ˈ t ɑː l z\n",
      "\t w ɪ ˈ f r oʊ l t ə n\n",
      "\t ˈ m ɪ d s k iː ˈ ɛ s\n",
      "\t ˈ n oʊ ˈ z ɛ s t\n",
      "Epoch 88: train loss: 0.5335\tdev loss: 0.4564                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ b ɛ r\n",
      "\t ˈ k ɑː m ə n z\n",
      "\t ˈ s iː ˈ f ɑː l ə n\n",
      "\t k ə n iː ˈ ɑː f ə\n",
      "\t ˈ b l eɪ d ɪ ŋ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: train loss: 0.5333\tdev loss: 0.4562                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ h ɔ r f\n",
      "\t ɛ ˈ r ɛ s l i\n",
      "\t ˈ m ʌ m ˌ p l oʊ l\n",
      "\t ˈ æ n d iː n ə t s\n",
      "\t ˈ s iː d\n",
      "Epoch 90: train loss: 0.5333\tdev loss: 0.4561                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ oʊ b oʊ\n",
      "\t ˌ k æ dʒ ə ˌ s ɪ n d ɝ ˈ t oʊ s t\n",
      "\t ˈ g æ s t r ə s\n",
      "\t ˈ h æ n d ɝ l oʊ\n",
      "\t ˈ dʒ ɛ t s i\n",
      "Epoch 91: train loss: 0.5331\tdev loss: 0.4561                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ p ɛ g p k ə n\n",
      "\t ˈ ʃ ʌ b iː ə n\n",
      "\t ˈ h æ s ə ˌ r eɪ t\n",
      "\t ˈ s aʊ n t s\n",
      "\t ˌ r uː ˈ ɛ s r i\n",
      "Epoch 92: train loss: 0.5331\tdev loss: 0.4560                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 6%, novel: 82%\n",
      "\t ˌ dʒ aɪ r ə ˈ t oʊ v ɝ ɪ k\n",
      "\t ˈ w aɪ tʃ ɪ ŋ\n",
      "\t r iː ˈ g ʌ l k ə s\n",
      "\t ˈ aɪ ˌ s b iː l v ə l\n",
      "\t ˈ s æ b ɝ ˌ t æ k t i\n",
      "Epoch 93: train loss: 0.5330\tdev loss: 0.4560                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ˈ h ɔ r t s\n",
      "\t ˈ b eɪ s ə n\n",
      "\t g ə ˈ d æ g\n",
      "\t b ɑː ˈ l oʊ l ə s ˌ v ɔ l\n",
      "\t ɪ n ˈ t ɔ r ə ˌ k ɪ k ə l\n",
      "Epoch 94: train loss: 0.5329\tdev loss: 0.4558                                                                                             \n",
      "\tGenerated: in train: 4%, assess: 6%, novel: 90%\n",
      "\t ˈ b r ɪ n z\n",
      "\t w ɪ ˈ tʃ æ n z\n",
      "\t d ɪ g ˈ p r iː v ə m i\n",
      "\t ˈ æ n s t r oʊ ˌ k eɪ s\n",
      "\t ˌ r iː n ɝ ˈ eɪ ʃ ə n d\n",
      "Epoch 95: train loss: 0.5328\tdev loss: 0.4559                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ɛ p ɝ ˈ s aɪ f z i\n",
      "\t ˌ ɑː r ɑː ˈ l iː d\n",
      "\t ˈ h eɪ ʃ ə n\n",
      "\t d uː ˌ ɝː oʊ ˈ k r uː z\n",
      "\t p r oʊ ˈ dʒ æ l i\n",
      "Epoch 96: train loss: 0.5328\tdev loss: 0.4558                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ b ɔɪ r oʊ ˌ t ɛ l\n",
      "\t ˈ v oʊ g ə\n",
      "\t ˈ s t j uː l ɝ\n",
      "\t ˈ p ɑː s t l i\n",
      "\t z ɪ d oʊ ˈ v l ɔ n oʊ\n",
      "Epoch 97: train loss: 0.5327\tdev loss: 0.4557                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ˌ r eɪ ʃ ə ˈ l ɛ n d ə\n",
      "\t ˈ f ɑː p t\n",
      "\t ˈ f r iː n ə s\n",
      "\t ˈ w eɪ k ʃ ɝ ɑː\n",
      "\t ˈ b r iː n\n",
      "Epoch 98: train loss: 0.5325\tdev loss: 0.4556                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t r iː ˈ b iː f ɛ\n",
      "\t m ə g ˈ k ɑː l ə\n",
      "\t ˈ f iː r z\n",
      "\t b ɔ r ˈ r æ n s n ɝ\n",
      "\t ˈ m ɑː n t ɪ n\n",
      "Epoch 99: train loss: 0.5323\tdev loss: 0.4554                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ d r æ dʒ i\n",
      "\t p r ə ˈ s p ɑː r d\n",
      "\t d ɝ ˈ l ɪ s oʊ\n",
      "\t ˈ j uː f ə l t l i\n",
      "\t ˈ s w ɔ s t ɪ v l i\n",
      "Epoch 100: train loss: 0.5322\tdev loss: 0.4553                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ r ʌ ŋ k ə t ɪ g ɝ\n",
      "\t k ə l ˈ k ɑː l k i\n",
      "\t ˈ l ɪ ŋ ə ˌ g r iː n\n",
      "\t s t ə ˈ f uː ˌ f iː oʊ\n",
      "\t d ɪ ˈ f ɔ r t ə l\n",
      "Epoch 101: train loss: 0.5322\tdev loss: 0.4554                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t ˈ m ɪ d ɝ ˈ aɪ s ɪ ŋ\n",
      "\t b iː m ə ˈ s k eɪ t oʊ\n",
      "\t d iː ˈ f ɛ t s\n",
      "\t ˈ v ʊ v ɝ ˌ æ s ɪ z\n",
      "\t ˈ m ɪ l t i\n",
      "Epoch 102: train loss: 0.5321\tdev loss: 0.4552                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ n ɪ s ɪ l d\n",
      "\t ˈ s t r aɪ oʊ\n",
      "\t ˈ l ʌ k r ɪ k\n",
      "\t ˈ j ɪ s n ɝ\n",
      "\t ˈ h ɔ r b iː ɝ\n",
      "Epoch 103: train loss: 0.5322\tdev loss: 0.4554                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ l iː t s i\n",
      "\t ˈ p aɪ z b æ k\n",
      "\t ˈ f ɑː r t s\n",
      "\t ˈ k r iː t ɪ θ\n",
      "\t ˈ m ɛ f\n",
      "Epoch 104: train loss: 0.5319\tdev loss: 0.4550                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ s k oʊ g l i\n",
      "\t ˈ s ɝː d ɪ ŋ\n",
      "\t s iː ˈ g ɛ s\n",
      "\t b ɑː ˈ ʃ eɪ\n",
      "\t s ə ˈ n æ n t ɝ\n",
      "Epoch 105: train loss: 0.5318\tdev loss: 0.4550                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ s t r ɛ n ɪ v\n",
      "\t r ɪ ˈ s aɪ d ə\n",
      "\t ˈ tʃ ɪ l ɪ t\n",
      "\t ˈ s p iː m ɝ g ɝ\n",
      "\t ˈ g ɔ r ɝ ə l\n",
      "Epoch 106: train loss: 0.5317\tdev loss: 0.4549                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ p r ɛ n t\n",
      "\t ˈ f aʊ l v i\n",
      "\t ˈ t r ɪ d ˌ k ɛ l d ɝ\n",
      "\t ˈ p r oʊ s t ɪ z\n",
      "\t ˈ s t ʌ ʃ ə n ə l\n",
      "Epoch 107: train loss: 0.5317\tdev loss: 0.4550                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ s ɝː\n",
      "\t ˈ ʃ ɑː r k\n",
      "\t ˈ m ɛ r ə n s ə ˌ n eɪ d\n",
      "\t ˈ k ʌ n r i\n",
      "\t ˈ s t r aɪ n z\n",
      "Epoch 108: train loss: 0.5315\tdev loss: 0.4547                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ ʃ ɛ l m ə s t\n",
      "\t ˈ s p ɔ l g ɝ\n",
      "\t ˈ ɪ l b l ɝ\n",
      "\t ˈ ɝː m\n",
      "\t ˈ r iː d ɪ k w ə t ɝ\n",
      "Epoch 109: train loss: 0.5315\tdev loss: 0.4548                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t ˈ l iː ə ˌ n aɪ d\n",
      "\t ˈ f ɪ r s ə k\n",
      "\t ˈ ɔ l w ə s ə n\n",
      "\t ˈ k r iː p t m ə n\n",
      "\t ˈ h eɪ ˌ n ɛ g\n",
      "Epoch 110: train loss: 0.5317\tdev loss: 0.4549                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ k æ t ɝ ˌ b æ s\n",
      "\t ˌ p æ n t ɝ ˈ ɪ t s ə n\n",
      "\t ˈ uː l eɪ m i\n",
      "\t ˈ v ɑː r ə b ɝ ə z\n",
      "\t ˈ m ɑː n d iː ə b ə l\n",
      "Epoch 111: train loss: 0.5314\tdev loss: 0.4547                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ dʒ æ s\n",
      "\t ˈ ʃ ə n l ɝ g æ k\n",
      "\t ˈ h ɑː l\n",
      "\t p r ɝ ˈ ɛ p t\n",
      "\t ˈ oʊ l ɪ ŋ k ʃ ɪ s t\n",
      "Epoch 112: train loss: 0.5313\tdev loss: 0.4547                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ n oʊ f k ə\n",
      "\t ˈ h ɪ s ə\n",
      "\t ˈ n ɪ d ˌ s t aɪ\n",
      "\t ˈ m ɝː m z\n",
      "\t ˈ p ɝː w ə n ˈ l ɪ v ə ˌ l i\n",
      "Epoch 113: train loss: 0.5313\tdev loss: 0.4546                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ k r ɪ n ɪ k s\n",
      "\t ˈ v oʊ p ɝ ə n t\n",
      "\t v ɪ ˈ θ ɑː l m i\n",
      "\t ˈ h ɑː k l ɝ\n",
      "\t ˈ s w ɔ r t ə n\n",
      "Epoch 114: train loss: 0.5312\tdev loss: 0.4545                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t m ə g ˈ n ɪ s ɪ s\n",
      "\t ˈ j ɑː r ˌ s t r ɔ n\n",
      "\t ə n ˈ h ɑː l d\n",
      "\t ˈ h uː t n ɝ z\n",
      "\t k ə n ˈ l ʊ r n\n",
      "Epoch 115: train loss: 0.5312\tdev loss: 0.4546                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ m æ l oʊ ˌ l iː z i\n",
      "\t ˈ n ɑː n s ə\n",
      "\t ˈ b ʊ n d ɝ t\n",
      "\t ˈ w ʊ ˌ k ɑː r d\n",
      "\t ˈ ɑː r s oʊ\n",
      "Epoch 116: train loss: 0.5310\tdev loss: 0.4545                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t p ə ˈ n ɛ d i\n",
      "\t ˈ eɪ k r i\n",
      "\t ˈ æ d ɪ r ɪ ŋ\n",
      "\t ˈ n oʊ dʒ ə n\n",
      "\t ˌ v j uː ˈ s ɛ k s t ɪ v\n",
      "Epoch 117: train loss: 0.5309\tdev loss: 0.4544                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ s æ l dʒ ɪ z\n",
      "\t ˈ g ɪ k l ɝ t\n",
      "\t ˈ r ɛ s d z\n",
      "\t ˈ p r aɪ z ɪ ŋ\n",
      "\t ˈ s t ɪ n v oʊ ˌ b æ n z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: train loss: 0.5309\tdev loss: 0.4543                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t ˈ aʊ m ɝ\n",
      "\t ɪ ˈ ɝː t\n",
      "\t d ɪ f ə ˈ s t ɑː l i\n",
      "\t ˈ r æ ŋ k s ɝ z\n",
      "\t ˈ d æ n z ə n\n",
      "Epoch 119: train loss: 0.5308\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t k æ ˈ s ɛ n t iː r ə\n",
      "\t \n",
      "\t p r ə ˈ v uː ʃ ə m ə k\n",
      "\t ˈ h ɛ r\n",
      "\t ˈ dʒ ɪ s t z\n",
      "Epoch 120: train loss: 0.5308\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˌ m ɪ ˈ l ɪ l ə m\n",
      "\t ˈ r æ v d\n",
      "\t ˈ l iː v\n",
      "\t ˈ h æ r ɪ m ə\n",
      "\t p r æ ˈ t ɑː f d\n",
      "Epoch 121: train loss: 0.5307\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ s p aɪ n\n",
      "\t ˈ d ʌ k l ɪ ŋ\n",
      "\t ˈ v æ n b ɝ d\n",
      "\t b ə ˈ t aʊ m ɝ\n",
      "\t ˈ t ɑː n ˈ b uː ɪ ŋ\n",
      "Epoch 122: train loss: 0.5306\tdev loss: 0.4541                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ˈ b r æ k ɪ ŋ\n",
      "\t ˌ ɪ n ˈ z ɝː ŋ v\n",
      "\t t ɑː ˈ r æ r oʊ d\n",
      "\t ɪ ˈ t ɛ l h oʊ t\n",
      "\t ˈ l oʊ m\n",
      "Epoch 123: train loss: 0.5306\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t s ə n ˈ d aɪ l i\n",
      "\t k ˈ p ɔ r k ɪ k\n",
      "\t ˈ h aɪ ˌ b l ɔ ŋ\n",
      "\t ˈ f ʌ k t s\n",
      "\t b ɪ k ˈ s k eɪ v ɪ v\n",
      "Epoch 124: train loss: 0.5304\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t ˈ r eɪ iː z\n",
      "\t ˈ s t r aʊ s m ə n z\n",
      "\t ˈ g ɛ t ˌ d eɪ p\n",
      "\t ˈ r aɪ ə n\n",
      "\t ˈ s t eɪ l ˌ s p ɪ r s ɝ\n",
      "Epoch 125: train loss: 0.5306\tdev loss: 0.4541                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ j uː s t ɪ ŋ\n",
      "\t ˌ aʊ f ˈ f aɪ l ʃ ə\n",
      "\t ˈ d ɝː l i\n",
      "\t ˈ h ɪ n ɝ\n",
      "\t ˈ t r ɑː k s t\n",
      "Epoch 126: train loss: 0.5304\tdev loss: 0.4540                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ k r uː p s\n",
      "\t ˈ s æ tʃ b ɪ r l i\n",
      "\t ˈ k ɪ f k ə n\n",
      "\t ˈ d ʌ g b oʊ\n",
      "\t ˈ m eɪ b ɝ\n",
      "Epoch 127: train loss: 0.5305\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t t r ɪ ˈ s t aɪ n\n",
      "\t ˈ w ɔ r d ɪ ŋ\n",
      "\t d ɑː ʃ ˈ s aɪ g ə l\n",
      "\t ˈ p ɛ l m z\n",
      "\t ɔ ˈ f l ɑː p ə s\n",
      "Epoch 128: train loss: 0.5304\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ m ɑː g r oʊ ɝ z\n",
      "\t ə ˈ l oʊ d ɝ z\n",
      "\t ˈ l æ k ɑː ˌ z ɪ v z\n",
      "\t ˈ æ d n ə\n",
      "\t g ə ˈ b ɑː l\n",
      "Epoch 129: train loss: 0.5302\tdev loss: 0.4538                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ g ʊ r ɝ\n",
      "\t ˈ p ɑː k d ə n ɪ ŋ\n",
      "\t ˈ s ɑː s p ə l\n",
      "\t ˈ d æ p iː ɪ t s\n",
      "\t ˈ tʃ ɛ k ə\n",
      "Epoch 130: train loss: 0.5302\tdev loss: 0.4537                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t ˈ k ʌ l ˌ n ɑː s\n",
      "\t ˈ w æ l f\n",
      "\t r ɪ ˈ s p ɛ s\n",
      "\t ɪ ˈ k l uː z ɝ\n",
      "\t ˈ t oʊ v ɝ\n",
      "Epoch 131: train loss: 0.5301\tdev loss: 0.4537                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 0%, novel: 94%\n",
      "\t ˈ s l ɪ k l i\n",
      "\t ˈ r ɛ l ɪ ŋ ˌ s aɪ z\n",
      "\t ˈ θ iː l iː ə n\n",
      "\t ˈ l ʌ z ə m\n",
      "\t r ɝ aɪ ˈ eɪ ʃ ə n ɝ\n",
      "Epoch 132: train loss: 0.5301\tdev loss: 0.4537                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t ˌ ɪ b ˈ t aɪ ɪ ŋ\n",
      "\t r ə b ˈ p ɝː s ə t ɪ ŋ\n",
      "\t ˈ oʊ l iː ə n\n",
      "\t ˈ k r aɪ ə l\n",
      "\t ə ˈ v ɪ tʃ t ˌ s iː d z\n",
      "Epoch 133: train loss: 0.5301\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ d r ɑː n ˌ t r æ m\n",
      "\t ˈ t r oʊ t ˌ d aɪ z ɪ f\n",
      "\t ˈ p ɝː h ə ˌ tʃ ɪ z ə ˌ b j uː\n",
      "\t k ə n ˈ k æ s t ə b ə n\n",
      "\t ˈ l æ n ə z\n",
      "Epoch 134: train loss: 0.5299\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˌ b ɑː ˈ r ɑː θ ə\n",
      "\t ˈ k æ n t ɪ n\n",
      "\t ˈ tʃ ɝː k oʊ\n",
      "\t ˈ b l ɔ ˈ p æ l\n",
      "\t ˈ b ɛ ˌ k w aɪ ɪ ŋ\n",
      "Epoch 135: train loss: 0.5299\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ˌ k ɑː r ˈ z ɪ n j ə ˌ l eɪ ʃ ə l\n",
      "\t k ə t ɪ ˈ dʒ ɑː n ɑː t\n",
      "\t ˈ s ɑː d ə n\n",
      "\t ˈ tʃ ɛ r ɝ\n",
      "\t ˈ f r ɛ n d\n",
      "Epoch 136: train loss: 0.5300\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ k l æ f ɪ k\n",
      "\t ˈ r ʌ b ə l ɝ z\n",
      "\t ˈ b ɔ r g ɝ\n",
      "\t ˈ æ k ə ˌ k w oʊ n\n",
      "\t ˈ p iː b ɝ z\n",
      "Epoch 137: train loss: 0.5297\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ oʊ t ə l\n",
      "\t ˈ p l ɑː d\n",
      "\t r ɪ ˈ d ɑː r\n",
      "\t d ɪ tʃ ɝ ˈ aɪ z\n",
      "\t ˌ f ɛ f t ə ˈ l uː\n",
      "Epoch 138: train loss: 0.5297\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ k ɔ r l i\n",
      "\t ˈ b l ʌ s t s\n",
      "\t ˈ k r ɪ s l i\n",
      "\t ˈ m ɪ r ɪ ŋ\n",
      "\t ˈ k l æ k ˌ t r ʊ s ɪ ŋ\n",
      "Epoch 139: train loss: 0.5297\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t ˌ æ n tʃ ɪ v ˈ tʃ ɑː r b oʊ\n",
      "\t l ɛ ˈ k ɑː k iː ɝ\n",
      "\t ˈ ʃ ʌ p ɝ z\n",
      "\t ˈ oʊ b ə n\n",
      "\t ˌ k uː ˈ d oʊ p t ɪ m\n",
      "Epoch 140: train loss: 0.5296\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t p ə ˈ t ɛ v\n",
      "\t ˈ b r ʌ d iː ˌ eɪ t ɝ\n",
      "\t ˈ b l ɛ p s t\n",
      "\t ˌ n ɔ ˈ r oʊ t ɛ\n",
      "\t ˈ d ʌ b t r i\n",
      "Epoch 141: train loss: 0.5296\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ə ˈ n ʌ f l i\n",
      "\t ˈ k r ʌ f ɪ s t\n",
      "\t ˈ b eɪ s\n",
      "\t ˌ oʊ ˈ k æ k r ə d\n",
      "\t ˈ w ɪ t ɪ ŋ\n",
      "Epoch 142: train loss: 0.5296\tdev loss: 0.4533                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t ˈ h ɑː l f ə\n",
      "\t ˈ m eɪ m z\n",
      "\t ə ˈ p r ɑː n d ɪ ŋ\n",
      "\t ˈ p r uː m ˈ p ɛ ˌ k ɪ t\n",
      "\t ˈ l æ b ɝ i\n",
      "Epoch 143: train loss: 0.5296\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 4%, novel: 82%\n",
      "\t ˌ h ɛ d ɛ ˈ l ɪ n t iː g\n",
      "\t ˈ b iː g\n",
      "\t ˈ n ɛ s ɝ ə m\n",
      "\t ˈ m æ m ɝ t ɪ z\n",
      "\t ˈ d ɪ s t ə l\n",
      "Epoch 144: train loss: 0.5296\tdev loss: 0.4533                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ v æ r iː ɝ\n",
      "\t ˈ k æ l dʒ ə n\n",
      "\t k oʊ ˈ m oʊ m ə\n",
      "\t ˈ æ k t ə m z\n",
      "\t k ə n ˈ tʃ oʊ l k ə\n",
      "Epoch 145: train loss: 0.5294\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ d ɛ d\n",
      "\t ˈ g r eɪ m\n",
      "\t b ə ˈ s ɛ l ə t i\n",
      "\t ˈ t ɝː ð ɝ d\n",
      "\t ˈ k r ɪ dʒ ɪ ŋ\n",
      "Epoch 146: train loss: 0.5294\tdev loss: 0.4531                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ə ˈ f uː n ə\n",
      "\t ˈ dʒ eɪ s ɝ\n",
      "\t ˈ j ɑː r ə\n",
      "\t k ɝ ˈ m ɛ l t s\n",
      "\t ˈ p oʊ n d s\n",
      "Epoch 147: train loss: 0.5293\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t r iː ˈ f ɪ m z s ɛ t\n",
      "\t m oʊ ˈ s t ɑː r d ə m\n",
      "\t ˈ s t æ n ɝ\n",
      "\t ˈ p oʊ t ɪ ŋ\n",
      "\t ˈ h aʊ ɝ ˌ f aɪ d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: train loss: 0.5293\tdev loss: 0.4531                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ p l aʊ z\n",
      "\t ˈ p ɑː r f oʊ\n",
      "\t ˈ n ɪ ˌ g r ɪ k ɝ d\n",
      "\t ˈ s ɛ t\n",
      "\t ˈ k r aɪ r ə n\n",
      "Epoch 149: train loss: 0.5293\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ k ʌ l d z\n",
      "\t ˈ b ɛ t ɪ l\n",
      "\t b ɔ r ˈ ʃ ɔ n z\n",
      "\t ˈ s iː z ə l ɝ\n",
      "\t ˈ d ɔ l z\n",
      "Epoch 150: train loss: 0.5294\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ t aʊ n ˌ tʃ ɪ n s ə n\n",
      "\t ˈ ʃ ɛ p ˌ l æ p ə l ɪ s t\n",
      "\t ˈ t ɑː d iː ə l\n",
      "\t ˈ h ɑː n d ɝ ˌ l ɛ t s\n",
      "\t ˈ k w iː n i\n",
      "CPU times: user 20min 12s, sys: 1min 6s, total: 21min 18s\n",
      "Wall time: 20min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping because of no decrease in 3 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.1036094570775852,\n",
       "  0.8436986849933503,\n",
       "  0.7593890346064368,\n",
       "  0.7142919638836622,\n",
       "  0.6827820520739124,\n",
       "  0.6585459344478072,\n",
       "  0.6397948564493996,\n",
       "  0.6263673148779023,\n",
       "  0.6151490808569349,\n",
       "  0.6061084125504329,\n",
       "  0.5990127835470382,\n",
       "  0.5930243306423786,\n",
       "  0.5879646833771807,\n",
       "  0.5837700006839988,\n",
       "  0.5802721241679054,\n",
       "  0.5773340510623292,\n",
       "  0.5746628072301132,\n",
       "  0.5722927667713189,\n",
       "  0.5701736787136268,\n",
       "  0.5682149583007987,\n",
       "  0.5664557019719216,\n",
       "  0.5647777990809897,\n",
       "  0.5631747640938567,\n",
       "  0.5616779143599051,\n",
       "  0.5602522044755545,\n",
       "  0.5589182815339883,\n",
       "  0.5576782485464997,\n",
       "  0.556496865144055,\n",
       "  0.5554179067594209,\n",
       "  0.5544824393690825,\n",
       "  0.5535344802965141,\n",
       "  0.5527828994594833,\n",
       "  0.5519750950300111,\n",
       "  0.5511186626509402,\n",
       "  0.5503950765280766,\n",
       "  0.549635472584408,\n",
       "  0.5489427600438943,\n",
       "  0.5483249656282391,\n",
       "  0.5476590450837193,\n",
       "  0.5471173402514103,\n",
       "  0.546583084297366,\n",
       "  0.5459890213701928,\n",
       "  0.5455426814033151,\n",
       "  0.5448852699436737,\n",
       "  0.5444035458911805,\n",
       "  0.5439455149436778,\n",
       "  0.5434862972268211,\n",
       "  0.5430092636511571,\n",
       "  0.542618904783786,\n",
       "  0.5422132475255486,\n",
       "  0.541766661911414,\n",
       "  0.5414067655721605,\n",
       "  0.5409463057612681,\n",
       "  0.5406938033475951,\n",
       "  0.5403563633355696,\n",
       "  0.5398752983237255,\n",
       "  0.5397293763040889,\n",
       "  0.5393565340956776,\n",
       "  0.5388489533213874,\n",
       "  0.5386591515991486,\n",
       "  0.5383591029556755,\n",
       "  0.5380787915784155,\n",
       "  0.5379658029842852,\n",
       "  0.5375185000631488,\n",
       "  0.5373809764081438,\n",
       "  0.5371067775398709,\n",
       "  0.5368894701297019,\n",
       "  0.5367788996600897,\n",
       "  0.5366356188003467,\n",
       "  0.5362963487499278,\n",
       "  0.5361596466717602,\n",
       "  0.5359121829508013,\n",
       "  0.5356369303972097,\n",
       "  0.5355335460756481,\n",
       "  0.5354909035052267,\n",
       "  0.535311059268738,\n",
       "  0.534931504414996,\n",
       "  0.5348630937627704,\n",
       "  0.5347279732758354,\n",
       "  0.5346249563796251,\n",
       "  0.534414703273935,\n",
       "  0.5342568941740815,\n",
       "  0.5341337368609517,\n",
       "  0.5340530781181271,\n",
       "  0.5340157130119636,\n",
       "  0.5337962502783742,\n",
       "  0.5336728852407353,\n",
       "  0.5335004254492821,\n",
       "  0.5333376106884908,\n",
       "  0.5332588800161348,\n",
       "  0.5331004047518261,\n",
       "  0.5331353704821943,\n",
       "  0.5330011980639534,\n",
       "  0.5328583875526082,\n",
       "  0.5328278468752767,\n",
       "  0.532814076806587,\n",
       "  0.5326580138897798,\n",
       "  0.5325380982273056,\n",
       "  0.5322804154954043,\n",
       "  0.5321856303163864,\n",
       "  0.5322200606626166,\n",
       "  0.5320533376968546,\n",
       "  0.5322105816059992,\n",
       "  0.5318603343377754,\n",
       "  0.531801476532037,\n",
       "  0.5317028556620128,\n",
       "  0.5317031464267069,\n",
       "  0.5315369926920214,\n",
       "  0.5314598874878715,\n",
       "  0.5316595014552808,\n",
       "  0.5313698033119038,\n",
       "  0.5313235183147222,\n",
       "  0.5312910854694866,\n",
       "  0.53121336488901,\n",
       "  0.531209759144534,\n",
       "  0.5310426580499908,\n",
       "  0.5309382696616589,\n",
       "  0.5309104789151677,\n",
       "  0.5307503927846827,\n",
       "  0.5308225403161198,\n",
       "  0.5307300415598157,\n",
       "  0.5306151638457776,\n",
       "  0.5306217242684899,\n",
       "  0.5304214438885327,\n",
       "  0.5306375839514651,\n",
       "  0.5304164776034574,\n",
       "  0.5304503261722068,\n",
       "  0.5303720443705052,\n",
       "  0.5302363047504106,\n",
       "  0.5301745929566476,\n",
       "  0.5301115191691707,\n",
       "  0.5301121583978423,\n",
       "  0.5300688930437539,\n",
       "  0.5299377636602075,\n",
       "  0.5299134884587596,\n",
       "  0.5299547086426053,\n",
       "  0.5297234018551689,\n",
       "  0.5296558362777074,\n",
       "  0.5297023621729418,\n",
       "  0.5296080619089099,\n",
       "  0.5295831762575484,\n",
       "  0.5295718064152576,\n",
       "  0.5296296842192215,\n",
       "  0.5295610132113837,\n",
       "  0.5294472825718608,\n",
       "  0.5293620980503461,\n",
       "  0.5292782366428682,\n",
       "  0.5293206221892085,\n",
       "  0.5293351968581036,\n",
       "  0.5294013025161016],\n",
       " [0.9862473134717574,\n",
       "  0.733764826498582,\n",
       "  0.6553836422522135,\n",
       "  0.6141708068361872,\n",
       "  0.5859495536597114,\n",
       "  0.564553892275862,\n",
       "  0.5480846967990619,\n",
       "  0.5362681618670666,\n",
       "  0.5264919445032681,\n",
       "  0.5185536917919901,\n",
       "  0.5123455541674641,\n",
       "  0.5070750288385338,\n",
       "  0.5026725682536951,\n",
       "  0.4989921943528421,\n",
       "  0.49595083745860147,\n",
       "  0.4933659063282876,\n",
       "  0.4911166358729823,\n",
       "  0.4890260773547283,\n",
       "  0.48716240163800667,\n",
       "  0.4854833458652643,\n",
       "  0.4839441629280946,\n",
       "  0.4825120107147245,\n",
       "  0.48110640083594886,\n",
       "  0.47984277088871696,\n",
       "  0.47864143411720467,\n",
       "  0.47750857987681894,\n",
       "  0.47641919691926204,\n",
       "  0.4754286419253268,\n",
       "  0.4745365004548574,\n",
       "  0.47375992564574576,\n",
       "  0.4729574872852246,\n",
       "  0.47232105443487793,\n",
       "  0.4716370532237605,\n",
       "  0.47094093334271114,\n",
       "  0.4702827756063174,\n",
       "  0.46963470162434995,\n",
       "  0.46911957927955095,\n",
       "  0.46851424091328436,\n",
       "  0.4680309539778729,\n",
       "  0.4675336434774649,\n",
       "  0.4671094121131877,\n",
       "  0.4666195118218868,\n",
       "  0.4662209398960473,\n",
       "  0.46566933677919115,\n",
       "  0.4653021016917097,\n",
       "  0.46490717416235017,\n",
       "  0.4645715134873416,\n",
       "  0.46416372014853047,\n",
       "  0.46388366759090294,\n",
       "  0.4634936707999604,\n",
       "  0.46313017762428976,\n",
       "  0.4629292076098486,\n",
       "  0.4624916869136537,\n",
       "  0.46227728177231503,\n",
       "  0.46197575911134303,\n",
       "  0.4615982533650514,\n",
       "  0.46145953302684406,\n",
       "  0.4611772930665024,\n",
       "  0.4607026128150655,\n",
       "  0.4606336776024769,\n",
       "  0.46035498356725185,\n",
       "  0.46011846778069,\n",
       "  0.4599889420865399,\n",
       "  0.45965815096385837,\n",
       "  0.45954064785835835,\n",
       "  0.45932983309765474,\n",
       "  0.45908936889622864,\n",
       "  0.4591198529534587,\n",
       "  0.4589977346003178,\n",
       "  0.458615335878899,\n",
       "  0.45858386328390394,\n",
       "  0.45838682304169026,\n",
       "  0.4580825360122969,\n",
       "  0.45802940497552436,\n",
       "  0.4579994319177483,\n",
       "  0.45789085146501524,\n",
       "  0.45750213384576477,\n",
       "  0.4574842813699859,\n",
       "  0.4574330351515922,\n",
       "  0.4573136128105378,\n",
       "  0.45715313555918946,\n",
       "  0.45699436721621156,\n",
       "  0.45692843299012625,\n",
       "  0.4568068672238598,\n",
       "  0.4568031253120491,\n",
       "  0.4566132983362156,\n",
       "  0.45656997380439934,\n",
       "  0.45638789690728176,\n",
       "  0.4562386119302229,\n",
       "  0.4561193827077647,\n",
       "  0.4560512151893979,\n",
       "  0.45603263421673607,\n",
       "  0.45596897200225484,\n",
       "  0.4558228610536098,\n",
       "  0.4558513164095464,\n",
       "  0.4557965300022321,\n",
       "  0.4557372359009505,\n",
       "  0.45557443644628376,\n",
       "  0.45539951497557085,\n",
       "  0.45530213874753545,\n",
       "  0.45535830375393793,\n",
       "  0.45520391356250256,\n",
       "  0.4553544581125841,\n",
       "  0.45504845739465716,\n",
       "  0.4549897995331073,\n",
       "  0.45493843285459906,\n",
       "  0.4549695770523772,\n",
       "  0.4547419576276844,\n",
       "  0.4547561633169016,\n",
       "  0.45489387647470714,\n",
       "  0.45470331191968055,\n",
       "  0.4546552559822558,\n",
       "  0.45464371093191674,\n",
       "  0.4544835314847404,\n",
       "  0.4545909814288592,\n",
       "  0.45446966709918096,\n",
       "  0.4544156005844556,\n",
       "  0.45433266475165424,\n",
       "  0.4542034239552353,\n",
       "  0.45424781541949427,\n",
       "  0.4541520783094455,\n",
       "  0.4541033273362807,\n",
       "  0.4541625841522888,\n",
       "  0.45391330628581833,\n",
       "  0.4541436900789325,\n",
       "  0.4539667179181751,\n",
       "  0.453937017807722,\n",
       "  0.4538890722920689,\n",
       "  0.4537701944116113,\n",
       "  0.4537460034393313,\n",
       "  0.45370095996080173,\n",
       "  0.4536904010581461,\n",
       "  0.4536443112018759,\n",
       "  0.45356497770011767,\n",
       "  0.4535651301873261,\n",
       "  0.45361426978776503,\n",
       "  0.4534055516066733,\n",
       "  0.45341140491660215,\n",
       "  0.4533967197770085,\n",
       "  0.4533561242404053,\n",
       "  0.4534100922837671,\n",
       "  0.4532538507350958,\n",
       "  0.45335432928909597,\n",
       "  0.4533195077117112,\n",
       "  0.45319072772303187,\n",
       "  0.4531135682395306,\n",
       "  0.4531531685461402,\n",
       "  0.4531114200341553,\n",
       "  0.4532093971287142,\n",
       "  0.4531775464228042])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_parameters = ModelParams(rnn_type='gru', num_layers=1, max_epochs=1000, early_stopping_rounds=3,\n",
    "                              embedding_dimension=100, hidden_dimension=20)\n",
    "model = LanguageModel(vocab, model_parameters, device_name='cuda')\n",
    "\n",
    "train_losses, dev_losses = model.fit(\n",
    "    train_pronunciations.pronunciation.values.tolist(),\n",
    "    dev_pronunciations.pronunciation.values.tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 1.2172\tdev loss: 1.0880                                                                                             \n",
      "\tGenerated: in train: 0%, assess: 0%, novel: 100%\n",
      "\t ˌ v ʊ ə h uː\n",
      "\t f ɝː i ɛ uː ŋ dʒ\n",
      "\t oʊ θ f\n",
      "\t k ʊ\n",
      "\t ʊ iː tʃ aʊ t aʊ t g tʃ z\n",
      "Epoch 2: train loss: 0.9410\tdev loss: 0.8146                                                                                             \n",
      "\tGenerated: in train: 0%, assess: 0%, novel: 100%\n",
      "\t v aʊ ɝ i g ɔ ɝ i ə w\n",
      "\t ɑː k\n",
      "\t b n\n",
      "\t aʊ t uː ə ɛ ˈ ə ə j æ ɛ aɪ\n",
      "\t tʃ ð s\n",
      "Epoch 3: train loss: 0.8466\tdev loss: 0.7287                                                                                             \n",
      "\tGenerated: in train: 0%, assess: 0%, novel: 100%\n",
      "\t s ɛ h z z\n",
      "\t iː æ m ŋ\n",
      "\t tʃ ˈ ə b h f\n",
      "\t l tʃ ɪ ʒ ɔɪ\n",
      "\t ɑː ˈ tʃ s ə f ə\n",
      "Epoch 4: train loss: 0.7842\tdev loss: 0.6733                                                                                             \n",
      "\tGenerated: in train: 0%, assess: 0%, novel: 100%\n",
      "\t θ iː ʊ j ɛ ɔɪ v v ð n\n",
      "\t l dʒ t\n",
      "\t ˈ ˈ aɪ ɝ ʒ ʊ t aʊ s\n",
      "\t ɝ ɝ tʃ ˌ ʃ ɑː\n",
      "\t iː p k b w dʒ t\n",
      "Epoch 5: train loss: 0.7369\tdev loss: 0.6318                                                                                             \n",
      "\tGenerated: in train: 2%, assess: 0%, novel: 98%\n",
      "\t ˈ d ˈ θ k\n",
      "\t ʊ ˈ aʊ ɔɪ tʃ aɪ k ə w\n",
      "\t ˈ ʌ ɪ m ɪ r ʃ oʊ\n",
      "\t f s t eɪ ɪ ˌ l ɪ ɝ oʊ ə iː ˈ\n",
      "\t ˈ t v uː l\n",
      "Epoch 6: train loss: 0.7010\tdev loss: 0.6005                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 0%, novel: 97%\n",
      "\t g t ð æ ˈ r ɛ k dʒ\n",
      "\t ˈ s tʃ ɪ ʃ ɑː l p\n",
      "\t ˈ p ð r ɑː ʊ b ɪ s iː s m\n",
      "\t ˈ ɔ l z\n",
      "\t ˈ k ˌ l l uː n ˌ d ɝː\n",
      "Epoch 7: train loss: 0.6754\tdev loss: 0.5781                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 0%, novel: 95%\n",
      "\t ˈ l oʊ d ɪ\n",
      "\t ˈ k r j dʒ ə l\n",
      "\t \n",
      "\t ˈ p uː l s\n",
      "\t ə ˈ aʊ r l\n",
      "Epoch 8: train loss: 0.6561\tdev loss: 0.5613                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ g ɔ ʃ ɝ w\n",
      "\t ˈ eɪ oʊ ˈ ɝː k s\n",
      "\t ˈ k r oʊ m ɪ\n",
      "\t ˈ ʃ aɪ k w ʃ\n",
      "\t ˈ g eɪ ˌ iː ɑː ɪ d\n",
      "Epoch 9: train loss: 0.6409\tdev loss: 0.5482                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 0%, novel: 95%\n",
      "\t ˈ ɛ t ɛ s\n",
      "\t ˌ ə n θ ɪ ˈ dʒ ɪ h\n",
      "\t ˈ p l iː n\n",
      "\t ˈ s aɪ n æ k s\n",
      "\t ˈ p æ t ɪ n\n",
      "Epoch 10: train loss: 0.6283\tdev loss: 0.5373                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ b r ɔ l r ə n ə ə d\n",
      "\t n d ˈ j ʃ ɪ æ ʃ ə ˌ d i\n",
      "\t ˈ k θ r ɝ ˈ f uː ŋ θ\n",
      "\t ˈ f ɪ w ɛ ɪ n\n",
      "\t ˈ k ɑː l b\n",
      "Epoch 11: train loss: 0.6178\tdev loss: 0.5282                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t ˈ ɔ f aɪ\n",
      "\t ɪ v ˌ ˌ ˈ s m iː m\n",
      "\t d ə ˈ w iː m\n",
      "\t ˈ ɑː k ɑː aɪ iː l ə d oʊ\n",
      "\t ˈ f r ɪ n\n",
      "Epoch 12: train loss: 0.6086\tdev loss: 0.5202                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ s t ɔ r s\n",
      "\t n ˈ k r ɛ b m ə n\n",
      "\t ˈ f eɪ t ə n ˌ f r ə n\n",
      "\t ŋ z\n",
      "\t ˈ ɑː l ɪ l i\n",
      "Epoch 13: train loss: 0.6007\tdev loss: 0.5134                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 2%, novel: 93%\n",
      "\t ˈ l ɑː f ɛ m ə n\n",
      "\t ˈ h aɪ n k\n",
      "\t ˈ w ɛ r t l ɝ d\n",
      "\t ˈ s æ ŋ dʒ\n",
      "\t ˌ l d aɪ g l æ n ˈ s j aɪ\n",
      "Epoch 14: train loss: 0.5945\tdev loss: 0.5080                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˌ h ɑː r æ ˈ h dʒ ɝ d\n",
      "\t ˈ n iː m ɪ m\n",
      "\t ˈ s w ʌ k i\n",
      "\t ˈ r d æ s\n",
      "\t ə ˈ l eɪ s ˌ g ɛ n\n",
      "Epoch 15: train loss: 0.5895\tdev loss: 0.5037                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ f ɪ l ɪ ˌ k r æ ʃ\n",
      "\t ə ˈ l aʊ ŋ z z\n",
      "\t ˈ d ʌ k ə n t\n",
      "\t ˈ m ɔ l ɪ z\n",
      "\t ˈ ɛ l ɝ i\n",
      "Epoch 16: train loss: 0.5855\tdev loss: 0.5002                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ r ɑː k t l ɝ\n",
      "\t ˈ dʒ ɪ l ɪ n\n",
      "\t m uː ˈ d ɑː s t i\n",
      "\t ˈ ɑː iː ɪ n\n",
      "\t ɪ aʊ n ˌ k ɔ r iː ˌ t ɑː n ɪ g t ɝ\n",
      "Epoch 17: train loss: 0.5821\tdev loss: 0.4973                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ h ʌ s\n",
      "\t ˈ æ t z oʊ s k w ə k\n",
      "\t ˈ ɪ k\n",
      "\t ˈ d uː t ə v ə z\n",
      "\t ˈ k ɛ l aʊ i\n",
      "Epoch 18: train loss: 0.5792\tdev loss: 0.4947                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t ˈ m iː f eɪ n\n",
      "\t ˈ f ɪ ə m ə s ə\n",
      "\t ˌ s m dʒ ɑː m ˈ b aɪ d t\n",
      "\t m ɝ ˈ t ʌ k s\n",
      "\t ˈ r oʊ b r iː ɝ\n",
      "Epoch 19: train loss: 0.5766\tdev loss: 0.4926                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 4%, novel: 89%\n",
      "\t ˈ j ɪ p ə n\n",
      "\t ˈ s ɛ k ə t l ə ˈ l t ɑː l z\n",
      "\t ˈ b uː m ə n iː ˌ t aɪ n\n",
      "\t ˈ eɪ n ə n\n",
      "\t s m ə ˌ aɪ r ɪ ʃ ə ˈ l æ t z\n",
      "Epoch 20: train loss: 0.5744\tdev loss: 0.4906                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t m iː ˈ p aʊ s\n",
      "\t ˈ b ɔ g n dʒ ə s\n",
      "\t ˈ aɪ z\n",
      "\t ɑː tʃ ˈ uː m uː m\n",
      "\t ˈ f l eɪ t ɝ\n",
      "Epoch 21: train loss: 0.5724\tdev loss: 0.4889                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˈ d eɪ z ə dʒ ɝ z\n",
      "\t ˈ m aɪ n ə ˌ t l eɪ t\n",
      "\t ˈ r ɑː d ɝ s t l z\n",
      "\t ɝ t ɛ ˈ f l ɛ v\n",
      "\t ˈ k r iː ˌ n ɔ t\n",
      "Epoch 22: train loss: 0.5706\tdev loss: 0.4873                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t m ə ˈ t ɪ s k ə n s\n",
      "\t ˈ p eɪ ˌ l eɪ d\n",
      "\t ˈ s l ə s d\n",
      "\t ˈ t d æ l ˌ r oʊ l ɝ θ\n",
      "\t p r ˈ r aʊ n ˌ s ɛ k d\n",
      "Epoch 23: train loss: 0.5690\tdev loss: 0.4860                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˈ f ɑː t ɝ ɔ\n",
      "\t ˈ g ɛ l k i\n",
      "\t ˈ r uː ˌ w iː k\n",
      "\t ˈ h æ d ə n\n",
      "\t ˈ uː t ɪ ŋ k\n",
      "Epoch 24: train loss: 0.5674\tdev loss: 0.4846                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ ʃ iː ˌ k j ʊ ə\n",
      "\t ˈ f r ʌ ʃ ə n\n",
      "\t n ə ˈ m ɛ s t oʊ\n",
      "\t m ə ˈ s t iː ə n t m\n",
      "\t ə ˈ f ɛ m ɪ m\n",
      "Epoch 25: train loss: 0.5660\tdev loss: 0.4834                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ t ɝː ɑː d\n",
      "\t ˈ l uː m\n",
      "\t ˈ m ʌ k t ə n d\n",
      "\t ˈ ɛ d ɪ ŋ\n",
      "\t ˈ r eɪ s ɪ k\n",
      "Epoch 26: train loss: 0.5646\tdev loss: 0.4822                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ ʃ iː n d\n",
      "\t \n",
      "\t ˈ p r oʊ z ɪ z\n",
      "\t ˈ p eɪ s ə n ˌ ɔ l\n",
      "\t ˈ f ɛ m r oʊ\n",
      "Epoch 27: train loss: 0.5634\tdev loss: 0.4812                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ ʃ ɛ p ə g ə l\n",
      "\t ˌ p æ w ə ˈ f ɪ l s tʃ\n",
      "\t ˈ b r uː s ə t ə z\n",
      "\t ˈ l ɛ g ə s ɝ\n",
      "\t ɝ ˈ oʊ n ʃ ə n\n",
      "Epoch 28: train loss: 0.5622\tdev loss: 0.4802                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t d ə ˈ s ɪ l ə d z\n",
      "\t ˈ l iː n\n",
      "\t ˈ b oʊ s ə n t\n",
      "\t r iː ˈ t ɛ d ə n g ɪ ŋ\n",
      "\t ɑː ˈ k ɛ s s s\n",
      "Epoch 29: train loss: 0.5612\tdev loss: 0.4793                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˈ dʒ aɪ z ə d\n",
      "\t ˈ m j uː d ə n\n",
      "\t ˌ s iː ˌ r uː ˈ w ə n z\n",
      "\t ˈ r eɪ t\n",
      "\t ˈ b ʊ r ə\n",
      "Epoch 30: train loss: 0.5601\tdev loss: 0.4783                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ l ɪ dʒ ɪ dʒ m ɝ p\n",
      "\t ˈ g ɔ k\n",
      "\t ˈ t ɑː r ˌ f ʌ l\n",
      "\t ˈ v ɝː g ɪ g z\n",
      "\t ˈ m ɛ l p oʊ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train loss: 0.5591\tdev loss: 0.4775                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ θ ɑː r t ɝ\n",
      "\t ˈ p f ɛ r d ɝ s\n",
      "\t ˈ b ɔ l i\n",
      "\t ˈ s ɑː m ɪ z\n",
      "\t k r iː ˈ iː t ə l θ\n",
      "Epoch 32: train loss: 0.5581\tdev loss: 0.4767                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ eɪ t ɪ k s k i\n",
      "\t ˈ h ɪ k t s\n",
      "\t ˈ dʒ ɪ k ə b ɝ\n",
      "\t ˈ θ iː z ɪ k\n",
      "\t ˈ p æ n d ɪ s n i\n",
      "Epoch 33: train loss: 0.5572\tdev loss: 0.4759                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 2%, novel: 93%\n",
      "\t m ə k ˈ ɑː n d ɪ ʃ\n",
      "\t b ɑː n r ə ˈ k ʌ r ˌ k oʊ ˌ f eɪ l z\n",
      "\t r iː ˈ æ n d ɝ oʊ\n",
      "\t ˈ b iː ˌ b ɔ z ə t\n",
      "\t s ə ˈ w ɪ n ə t ɝ\n",
      "Epoch 34: train loss: 0.5562\tdev loss: 0.4751                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ s ʌ z z\n",
      "\t ˈ l ɪ r k\n",
      "\t s ə ˈ l ɪ m ə n d s\n",
      "\t ˈ w ɪ s s t i\n",
      "\t ˈ b l eɪ v ˌ d aɪ g ɝ\n",
      "Epoch 35: train loss: 0.5553\tdev loss: 0.4743                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t ɑː n ˈ w oʊ n z\n",
      "\t ˌ k ɝː n uː ˈ t oʊ l p j ə l s i\n",
      "\t oʊ\n",
      "\t ˈ d r aɪ d\n",
      "\t ˈ b uː k ɪ r ɪ dʒ z\n",
      "Epoch 36: train loss: 0.5545\tdev loss: 0.4736                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ k æ tʃ i\n",
      "\t dʒ ɪ ˈ b w æ p ɪ v z\n",
      "\t ˈ g æ m ˌ f ɪ ŋ k ə b ə l\n",
      "\t ˈ s ɑː l t r ə\n",
      "\t l ɛ ˈ n iː ə n d\n",
      "Epoch 37: train loss: 0.5537\tdev loss: 0.4729                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t k ɪ k ˈ oʊ t ə l\n",
      "\t ˈ p r ɔ r ˌ n iː z\n",
      "\t ˈ t ɪ n d ə l ɔɪ\n",
      "\t ˈ k æ l ə l\n",
      "\t ˈ z ɝː t\n",
      "Epoch 38: train loss: 0.5529\tdev loss: 0.4722                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t d ɪ dʒ ˈ l p r aɪ ə n\n",
      "\t ˈ f æ s ə t ɪ ˈ g eɪ ʃ\n",
      "\t ˈ g ɑː r m iː ə\n",
      "\t d ə ˈ l iː k\n",
      "\t ˈ s æ n t ɪ n ˌ ɝː g\n",
      "Epoch 39: train loss: 0.5521\tdev loss: 0.4716                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ b r æ ŋ g l j uː z z\n",
      "\t ˈ n ɑː n i\n",
      "\t p r iː ˈ n eɪ ʃ ə n\n",
      "\t ˈ l ɑː l k ɝ\n",
      "\t d oʊ ˈ l ɪ n ɪ k i\n",
      "Epoch 40: train loss: 0.5514\tdev loss: 0.4710                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 0%, novel: 95%\n",
      "\t ˈ d ɪ r ˌ iː z\n",
      "\t ˈ h æ l s\n",
      "\t ˈ w ɛ f l ə n\n",
      "\t ˈ t æ g r ə n ɝ\n",
      "\t ˌ ɪ n ˌ m oʊ dʒ ə ˈ s k aʊ t ɝ\n",
      "Epoch 41: train loss: 0.5508\tdev loss: 0.4704                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ b ɛ m h ə\n",
      "\t ˈ s aɪ n ə n\n",
      "\t ˈ f eɪ k ə n\n",
      "\t ˈ k iː m ˌ g ɝː t\n",
      "\t k ɑː s t ɛ ˈ m oʊ n ɪ l\n",
      "Epoch 42: train loss: 0.5501\tdev loss: 0.4699                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ t oʊ k\n",
      "\t ˈ r æ p t ɪ d\n",
      "\t ˈ m ɛ n dʒ ə ˌ r ə l\n",
      "\t ˈ k l uː d\n",
      "\t ˈ s ɪ p ə n ˌ v aɪ ɝ\n",
      "Epoch 43: train loss: 0.5495\tdev loss: 0.4693                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ l oʊ k\n",
      "\t ˈ p ɛ m ə l\n",
      "\t ˈ aʊ ɝ ɝ\n",
      "\t ˈ m aɪ l ˌ f l iː ˌ r aɪ dʒ i\n",
      "\t ˈ m aʊ m\n",
      "Epoch 44: train loss: 0.5489\tdev loss: 0.4689                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ɪ ˈ r æ v ə m\n",
      "\t ˈ h ɑː r d ə d z\n",
      "\t dʒ ɑː r ˈ ɪ t ɝ\n",
      "\t ˈ b ʊ g l ɪ k i\n",
      "\t ˈ n uː θ ˌ g oʊ b w eɪ ˌ ɪ n d p\n",
      "Epoch 45: train loss: 0.5484\tdev loss: 0.4685                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ r ɛ b r ə n\n",
      "\t ˈ p ɛ t ə ˌ d aɪ z\n",
      "\t ˈ w ɑː n ə\n",
      "\t ɝ ˈ v eɪ ʃ\n",
      "\t ˈ b ɑː ˌ l ɪ k\n",
      "Epoch 46: train loss: 0.5478\tdev loss: 0.4680                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ˈ ɛ r ɪ d\n",
      "\t b ɝ ˈ eɪ p\n",
      "\t ˈ b ɔ n ˌ g aɪ t\n",
      "\t ˈ j ɛ z ə m\n",
      "\t ˈ n oʊ\n",
      "Epoch 47: train loss: 0.5473\tdev loss: 0.4676                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ b eɪ t ɪ ŋ\n",
      "\t uː ˈ k iː\n",
      "\t k r ɪ ˈ m æ ŋ t ɝ ə m\n",
      "\t aɪ ˈ w oʊ m\n",
      "\t ˈ ʃ eɪ b ɝ s k i\n",
      "Epoch 48: train loss: 0.5468\tdev loss: 0.4672                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t ˈ l uː\n",
      "\t k ə ˈ k l oʊ ˌ v j uː s t ə l d\n",
      "\t ˈ k l ɑː s\n",
      "\t ˈ k eɪ d i\n",
      "\t ˈ l uː ə k\n",
      "Epoch 49: train loss: 0.5464\tdev loss: 0.4668                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ s t r w oʊ t\n",
      "\t ˈ g ɑː l ɪ z\n",
      "\t ˈ s t ɪ s t ə m\n",
      "\t t ɛ ˈ n ɛ k ɛ t\n",
      "\t r iː ˈ l ɛ m t ɪ ŋ\n",
      "Epoch 50: train loss: 0.5459\tdev loss: 0.4664                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t ˈ k ɔ r k ɪ d\n",
      "\t ˈ ɔ r ˌ r ɪ ŋ l ʊ ŋ\n",
      "\t s ɪ ˈ v ɛ l d ə n\n",
      "\t ˈ d ɝː p t\n",
      "\t ˈ d iː ˌ f l iː\n",
      "Epoch 51: train loss: 0.5455\tdev loss: 0.4660                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ l ʊ s ɪ m\n",
      "\t ˈ d ɪ n d ɪ l\n",
      "\t r oʊ ˈ d eɪ ʃ ə n ɝ\n",
      "\t ˈ r eɪ ɝ\n",
      "\t ˈ θ m æ p ɪ g k\n",
      "Epoch 52: train loss: 0.5450\tdev loss: 0.4657                                                                                             \n",
      "\tGenerated: in train: 2%, assess: 3%, novel: 95%\n",
      "\t ˈ k r ɛ k ʃ\n",
      "\t ˈ l ɛ r ə n t\n",
      "\t ˈ p ɛ n t\n",
      "\t ˈ w ɪ n ˌ b ɪ t\n",
      "\t ˈ d ɪ n\n",
      "Epoch 53: train loss: 0.5446\tdev loss: 0.4654                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ g æ m dʒ ə n d\n",
      "\t ˈ f iː d\n",
      "\t ˈ θ ɑː r ŋ\n",
      "\t ˈ ɪ s ə n ɝ\n",
      "\t w ɝː ˈ h ɪ s k i\n",
      "Epoch 54: train loss: 0.5442\tdev loss: 0.4650                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ g ʊ r b ə l\n",
      "\t ˈ l ɪ t r ə s ə\n",
      "\t ˈ p ɪ n z ɪ ˌ t r ɛ s t\n",
      "\t ˈ t æ s i\n",
      "\t ˈ m æ ŋ k\n",
      "Epoch 55: train loss: 0.5439\tdev loss: 0.4648                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ɝ eɪ ˈ k ɑː r\n",
      "\t k ɑː r ˈ b ɑː n\n",
      "\t ˈ m æ b ɝ t\n",
      "\t ˈ s m aɪ t i\n",
      "\t dʒ ə ˈ k æ l i\n",
      "Epoch 56: train loss: 0.5435\tdev loss: 0.4644                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t tʃ ɪ ˈ m ɪ k t ɪ ŋ\n",
      "\t ˈ g oʊ j ə\n",
      "\t ˈ h ɛ l d ɪ\n",
      "\t ˈ h ɑː l ə ˌ d ɛ r\n",
      "\t ˈ z uː l g ə\n",
      "Epoch 57: train loss: 0.5431\tdev loss: 0.4641                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t ˌ k ɛ r aɪ ˈ t eɪ ˌ s t aɪ d\n",
      "\t ə ˈ l ɑː t t ɝ ʃ ɔ l ə s\n",
      "\t ˈ b w ɑː l i\n",
      "\t k r ə ˈ v ɔɪ ɑː n oʊ\n",
      "\t ˈ f ɑː k\n",
      "Epoch 58: train loss: 0.5428\tdev loss: 0.4638                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ g æ t ə k r ɝ\n",
      "\t ˈ r oʊ z l i\n",
      "\t ˈ ɛ m ɝ ˈ v ɪ s\n",
      "\t ˈ k r eɪ s ɔ r k\n",
      "\t ə ˈ l ɛ n t\n",
      "Epoch 59: train loss: 0.5425\tdev loss: 0.4636                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ s t aɪ n ə b\n",
      "\t ˈ iː t ə\n",
      "\t ˈ d iː k\n",
      "\t ˈ p aɪ z f ɪ d\n",
      "\t ˈ ʃ ɛ n ɪ n ɪ d\n",
      "Epoch 60: train loss: 0.5422\tdev loss: 0.4633                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t z ɝ ˈ ɪ n d ə b ɪ ʃ t\n",
      "\t ˈ b ʌ b iː t\n",
      "\t ˈ l aɪ ˌ w eɪ\n",
      "\t ˈ s aɪ r i\n",
      "\t ˌ t ɛ n ˈ s ɛ n t ˌ d ɔ r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: train loss: 0.5420\tdev loss: 0.4631                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ k r æ t ʃ ə n\n",
      "\t ˈ s t r æ k t ɝ\n",
      "\t ˈ ɑː s n ɝ\n",
      "\t s iː ˈ v iː n ɪ d\n",
      "\t ˈ f ɝː l aɪ z\n",
      "Epoch 62: train loss: 0.5416\tdev loss: 0.4628                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˌ ɛ t ɝ ˈ t r iː s ə n\n",
      "\t ˈ ɔ r s k i\n",
      "\t ˈ k ɑː g ə p l ɪ ŋ z\n",
      "\t ˈ f ɛ v l ə m b ɛ k\n",
      "\t ˈ r iː z s\n",
      "Epoch 63: train loss: 0.5415\tdev loss: 0.4627                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ˈ h eɪ z d\n",
      "\t d ˈ l æ ʃ z\n",
      "\t ˈ æ d h uː\n",
      "\t ˈ p ʌ s t r iː v ɝ z\n",
      "\t ˈ ɑː d l ɪ k\n",
      "Epoch 64: train loss: 0.5411\tdev loss: 0.4625                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ r oʊ z ɪ n\n",
      "\t t ɛ s t ɝ oʊ ˈ l ɑː n\n",
      "\t ˈ s uː ˌ h ɑː r\n",
      "\t ˈ r ɝː f\n",
      "\t ˈ n ɛ k\n",
      "Epoch 65: train loss: 0.5409\tdev loss: 0.4623                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t b ɪ ˈ b ɑː r ə\n",
      "\t s p r oʊ ˈ v ɑː n ɝ\n",
      "\t d ɪ k ˈ s t ɛ r ɪ k ə n\n",
      "\t ˈ k ɝː k l i\n",
      "\t k oʊ ˈ r uː dʒ\n",
      "Epoch 66: train loss: 0.5406\tdev loss: 0.4620                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ oʊ l ɝ\n",
      "\t ˈ p ɑː r m p r ɑː r z\n",
      "\t ˈ b w ɛ n t i\n",
      "\t ɪ ˈ r eɪ ʃ ə n\n",
      "\t ˈ t ɑː n s t h ɝ\n",
      "Epoch 67: train loss: 0.5404\tdev loss: 0.4619                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 3%, novel: 81%\n",
      "\t ˈ p r ɛ m ˌ f ɛ n ə l\n",
      "\t ˈ k ɑː k l ɪ ŋ\n",
      "\t l ɑː ˈ ɔɪ s t\n",
      "\t ˈ d l æ dʒ ə n d\n",
      "\t ˈ f l oʊ t ə n\n",
      "Epoch 68: train loss: 0.5402\tdev loss: 0.4617                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t ˈ r oʊ n ˌ t l aɪ z\n",
      "\t r ɪ ˈ p eɪ z\n",
      "\t ˌ b ɪ ˌ f ɪ s ɛ n f iː r ɛ m t s\n",
      "\t ˌ d ɑː n ə ˈ v ɛ tʃ k i\n",
      "\t ˈ s ɝː tʃ ə l z\n",
      "Epoch 69: train loss: 0.5401\tdev loss: 0.4616                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ d ɝː t\n",
      "\t ˈ m ɔ r ˌ h oʊ l\n",
      "\t ˈ h ɔ l z s\n",
      "\t ˈ d ɛ b ɪ n\n",
      "\t d ɪ ˈ l iː dʒ d\n",
      "Epoch 70: train loss: 0.5398\tdev loss: 0.4614                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t d ɪ ˈ d ɑː n ə s p\n",
      "\t ˈ b iː m\n",
      "\t ˈ t ɔ s ə b r ə k\n",
      "\t ˈ f iː θ\n",
      "\t ˈ s æ n tʃ\n",
      "Epoch 71: train loss: 0.5396\tdev loss: 0.4612                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t d ɪ ˈ n uː n\n",
      "\t ˈ t ɝː s t ə s\n",
      "\t ˈ b r aɪ l\n",
      "\t ˈ b ɔ r d ɪ p\n",
      "\t s ɑː ˈ z ɛ ʃ m ə n ˌ s t aɪ n\n",
      "Epoch 72: train loss: 0.5395\tdev loss: 0.4611                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ ɝː b ɪ ŋ\n",
      "\t ˈ b æ d z ə l\n",
      "\t ˈ b oʊ v\n",
      "\t ˈ ʃ aɪ b\n",
      "\t d ɪ ˈ s ɛ t ə z\n",
      "Epoch 73: train loss: 0.5392\tdev loss: 0.4609                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ l æ l ɪ t\n",
      "\t ˈ m ɛ n m ə n\n",
      "\t ˈ l eɪ b ə z\n",
      "\t ˈ p ɛ l b i\n",
      "\t ˌ w æ n oʊ ˈ v ɛ t ə n\n",
      "Epoch 74: train loss: 0.5390\tdev loss: 0.4607                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ m ɛ r i\n",
      "\t ˈ n æ f ɝ z\n",
      "\t ˈ f ʌ m m ə n z\n",
      "\t ˈ h ɑː g d\n",
      "\t m ə n ˈ t ɔ r b ə s\n",
      "Epoch 75: train loss: 0.5389\tdev loss: 0.4606                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t k ə n ˈ ɪ n d ɪ d\n",
      "\t ˌ g oʊ ˈ s n ɔ r ɪ dʒ\n",
      "\t ˈ h ɛ l t r ə\n",
      "\t ˈ æ b ɪ g\n",
      "\t ˈ m iː n ə s\n",
      "Epoch 76: train loss: 0.5388\tdev loss: 0.4604                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ k l ɑː p ɝ ə\n",
      "\t ˈ f r oʊ l z\n",
      "\t ˈ k ɔ k t ə l\n",
      "\t ˈ b æ r\n",
      "\t ˈ f ɪ r w ɪ k\n",
      "Epoch 77: train loss: 0.5385\tdev loss: 0.4603                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ t ɑː m b ə b ɝ l\n",
      "\t ˈ z w ɛ s t ɝ\n",
      "\t ˈ θ eɪ n\n",
      "\t ˈ w ɪ t ɝ ˌ ɛ s t\n",
      "\t ˈ k ɔ r z d ɪ ŋ\n",
      "Epoch 78: train loss: 0.5384\tdev loss: 0.4602                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ s ɪ r d\n",
      "\t ˈ v aʊ ɝ\n",
      "\t d ɛ ˈ b ɑː m p ə n\n",
      "\t ˈ θ ɝː l ə dʒ ˌ d eɪ ˌ w eɪ\n",
      "\t b ɝ ˈ eɪ t ɪ s\n",
      "Epoch 79: train loss: 0.5382\tdev loss: 0.4600                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 2%, novel: 92%\n",
      "\t ˈ w ɛ ˌ t r uː\n",
      "\t ˈ ɪ n d ɝ\n",
      "\t ˌ ɛ n t r iː s uː ˈ k ɑː d ɪ\n",
      "\t ˈ tʃ ʊ g ə l\n",
      "\t m ə n ˈ s iː ˌ ʃ ɝ\n",
      "Epoch 80: train loss: 0.5380\tdev loss: 0.4599                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ b ɑː r m ə n ɪ ŋ\n",
      "\t ˈ m ʌ s m ə k\n",
      "\t ˈ s t ɝː g ɛ k\n",
      "\t ˌ ɛ l ˌ ɪ n s ɪ g ˈ r oʊ ˌ t ɑː d\n",
      "\t ˈ b ɔ r\n",
      "Epoch 81: train loss: 0.5379\tdev loss: 0.4597                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 1%, novel: 93%\n",
      "\t ˈ p ɛ l m ə l\n",
      "\t ˈ p iː m l ə s\n",
      "\t ˈ f uː k s ə n\n",
      "\t ˈ m ɪ r eɪ\n",
      "\t tʃ ɝː m ɑː n ˈ t r ɛ ŋ tʃ ɪ n\n",
      "Epoch 82: train loss: 0.5378\tdev loss: 0.4597                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ tʃ oʊ l ə m ɝ\n",
      "\t ˈ s ɑː n t d\n",
      "\t ˌ ɪ v ˈ n uː s ɪ ŋ oʊ\n",
      "\t ˌ ɛ θ ə ˈ n iː n i\n",
      "\t ˌ f ʊ r ə ˈ z ɝː d ə t i\n",
      "Epoch 83: train loss: 0.5376\tdev loss: 0.4595                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ b z ɪ t s k ə\n",
      "\t ˈ g l ʌ θ ˌ θ ɛ n\n",
      "\t ˈ p ɝː g ə l d\n",
      "\t ˈ v ʌ ˌ k ə n\n",
      "\t ˈ g r ɑː v ɪ ʒ ə\n",
      "Epoch 84: train loss: 0.5375\tdev loss: 0.4594                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t ˈ b ɔɪ ə ˌ l eɪ s t ɪ ŋ\n",
      "\t ˈ s ʌ k ə ˌ n oʊ\n",
      "\t ˈ oʊ n ə n\n",
      "\t ˈ m ɛ l t ə s\n",
      "\t ˈ æ n m ə n\n",
      "Epoch 85: train loss: 0.5372\tdev loss: 0.4592                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 3%, novel: 92%\n",
      "\t r iː ˈ t ɔ r ə\n",
      "\t ˈ s k ɑː j ə n d\n",
      "\t ˈ k ɑː l ɝ t z\n",
      "\t ˈ b r æ s t\n",
      "\t ˈ t æ m k ə l\n",
      "Epoch 86: train loss: 0.5371\tdev loss: 0.4591                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ˈ g l uː s ɪ dʒ ɔ z\n",
      "\t ˈ b ɑː n ə ˌ n oʊ t ɝ\n",
      "\t ˈ b w ɑː w ə n\n",
      "\t ˈ h ɔ s l aɪ ɝ\n",
      "\t ˈ m ɑː r ɪ θ\n",
      "Epoch 87: train loss: 0.5369\tdev loss: 0.4590                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 0%, novel: 82%\n",
      "\t p j ə ˈ k l iː d\n",
      "\t ˈ m ʌ g r ɪ dʒ\n",
      "\t ˈ d æ t ə n\n",
      "\t ˈ d aɪ tʃ\n",
      "\t ˈ k ɪ g s\n",
      "Epoch 88: train loss: 0.5368\tdev loss: 0.4588                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ v ɑː r k ɝ\n",
      "\t ˌ g ɔ r p ə ˈ b ɛ l ə s\n",
      "\t ˈ r ɛ n t ɝ j ə n s t\n",
      "\t ˈ d ɛ ʃ ɛ k s\n",
      "\t k ə b ˈ v æ z ə n\n",
      "Epoch 89: train loss: 0.5366\tdev loss: 0.4587                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t ˈ h ɛ k ɝ\n",
      "\t ˈ g w oʊ ˌ b ɪ l dʒ ɝ\n",
      "\t ˈ p ʊ tʃ ə h j oʊ\n",
      "\t ˈ d r oʊ l i\n",
      "\t ˈ h uː l iː ə n\n",
      "Epoch 90: train loss: 0.5366\tdev loss: 0.4587                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t ˈ t ʌ p t ˌ s t ɔ l z\n",
      "\t r ə ˈ n æ n s ɛ n d\n",
      "\t ˈ p ɑː r ʒ ə n s\n",
      "\t ˈ s ɔ s t w ɪ ŋ t\n",
      "\t ˈ d ɛ n ə l z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: train loss: 0.5363\tdev loss: 0.4585                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ ɑː r n ɪ ŋ\n",
      "\t ˈ t ɛ v ɝ z\n",
      "\t ˌ ɪ n iː ˈ v ɛ iː ə b ə l t\n",
      "\t dʒ ə ˈ g ɑː d d i\n",
      "\t d iː ˈ ɛ l t\n",
      "Epoch 92: train loss: 0.5362\tdev loss: 0.4584                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t r ə ˌ k ɑː r ˈ p r iː\n",
      "\t ˈ r ɪ ˈ t oʊ t s\n",
      "\t ˈ w ʌ l b ə l\n",
      "\t ˈ s ɛ r ɪ t ə s\n",
      "\t ˈ l aɪ v ɪ ŋ\n",
      "Epoch 93: train loss: 0.5360\tdev loss: 0.4582                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˌ r ɪ ð ɝ ˈ ɪ k s k ə ˈ b ɑː r t ə\n",
      "\t d ɝ ˈ ɪ t ˌ s t ɔ m ə n d n ɝ i\n",
      "\t ˈ k æ f uː ˌ k w ʊ d\n",
      "\t ˈ z oʊ\n",
      "\t ɛ ˈ m iː d ə n\n",
      "Epoch 94: train loss: 0.5359\tdev loss: 0.4581                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ l ʊ t ɝ ˌ eɪ t ɪ ŋ\n",
      "\t ˈ dʒ ɑː m p ɪ l\n",
      "\t ˈ d r æ l m ə n z\n",
      "\t ˈ s t æ f t\n",
      "\t ˈ h ɑː r i\n",
      "Epoch 95: train loss: 0.5358\tdev loss: 0.4580                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ m ɔ ˌ r ɔɪ n\n",
      "\t ˈ d ɛ ˌ l eɪ t s\n",
      "\t ˈ ɔ θ ə l ɝ\n",
      "\t ˌ ɛ s ɪ l m ə ˈ w ɛ t s ə n\n",
      "\t ɑː\n",
      "Epoch 96: train loss: 0.5357\tdev loss: 0.4579                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t ˈ m æ l k ɪ ŋ m ə s\n",
      "\t v ə ˈ v oʊ r d r ɪ ŋ\n",
      "\t ˈ m oʊ g r ə\n",
      "\t ˈ k r iː l\n",
      "\t ˌ g r ɪ r ə ˈ t ɛ r oʊ\n",
      "Epoch 97: train loss: 0.5355\tdev loss: 0.4578                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ˈ h iː t i\n",
      "\t ˈ ɔ r d m ə\n",
      "\t ˈ b aɪ l\n",
      "\t ˈ b r uː t\n",
      "\t ˈ n aɪ oʊ ˌ b aɪ z\n",
      "Epoch 98: train loss: 0.5354\tdev loss: 0.4577                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ m æ l ə l z\n",
      "\t ˈ h ɔ l z ɑː r b ə g\n",
      "\t ˈ f r iː tʃ\n",
      "\t p r ə ˈ k oʊ s d i\n",
      "\t ˈ p l ɛ f ˌ ɪ ŋ g ə p\n",
      "Epoch 99: train loss: 0.5353\tdev loss: 0.4576                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ tʃ ʌ n z\n",
      "\t p r iː ˈ eɪ t i\n",
      "\t d ɛ ˈ l iː ˌ θ r eɪ\n",
      "\t ˌ s ɑː d ɪ ˈ k j uː oʊ f ɝ ɛ ŋ\n",
      "\t ˈ p aɪ n d\n",
      "Epoch 100: train loss: 0.5352\tdev loss: 0.4575                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 0%, novel: 93%\n",
      "\t ˈ ɪ n ɝ ˌ b ɛ s t\n",
      "\t r ɪ ˈ s ɪ l l oʊ\n",
      "\t ˈ b ʌ k eɪ ˌ b aʊ d\n",
      "\t ˈ b j ʌ m ɑː n ə d\n",
      "\t ˈ w iː l i\n",
      "Epoch 101: train loss: 0.5350\tdev loss: 0.4574                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t l ə ˈ k ɪ g j uː ˌ oʊ m\n",
      "\t ˈ b uː p s\n",
      "\t ˈ ɛ k ɪ t\n",
      "\t r aʊ ˈ eɪ n ɪ ŋ\n",
      "\t ˈ p iː t s\n",
      "Epoch 102: train loss: 0.5349\tdev loss: 0.4573                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t m ə ˈ t r iː b ɪ s\n",
      "\t ˈ t r ɑː k ə t ə\n",
      "\t ˈ oʊ ˌ s t r iː\n",
      "\t ˈ s æ d ɪ t ə l d\n",
      "\t ˌ s uː tʃ ə ˈ tʃ aɪ n ɪ ŋ\n",
      "Epoch 103: train loss: 0.5348\tdev loss: 0.4572                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˌ t j uː m ə ˈ t oʊ r oʊ\n",
      "\t ˈ ʃ ɛ l tʃ\n",
      "\t ˌ p r iː r iː ˈ oʊ l\n",
      "\t ˈ s uː p r ə\n",
      "\t ˈ oʊ ŋ g ə l ə s ə b\n",
      "Epoch 104: train loss: 0.5347\tdev loss: 0.4571                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t g ˈ s ɝː ʃ ə n\n",
      "\t ˈ ɪ n s t l i\n",
      "\t g oʊ ˈ t ɔ r d ə\n",
      "\t ˈ j eɪ d eɪ z\n",
      "\t ˈ g ɔ r t ɪ l\n",
      "Epoch 105: train loss: 0.5346\tdev loss: 0.4571                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t v ɑː ˈ r æ r i\n",
      "\t ˈ m ɛ r ɪ n d\n",
      "\t ˈ s aɪ oʊ\n",
      "\t d ɪ ˈ h ɪ ʃ ə n t\n",
      "\t ˈ d ɛ ɝ ˌ t aɪ\n",
      "Epoch 106: train loss: 0.5344\tdev loss: 0.4568                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ oʊ t ə l\n",
      "\t ˌ r ɪ d ɪ ˈ v eɪ ʃ ə n ɝ z\n",
      "\t ˈ s ɪ m ɪ g i\n",
      "\t ˌ ɛ n oʊ ˈ h æ m p ə n\n",
      "\t ɪ f ˈ m ɑː r k i\n",
      "Epoch 107: train loss: 0.5344\tdev loss: 0.4568                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 0%, novel: 81%\n",
      "\t ˈ b j ʊ r iː ə n\n",
      "\t l ɪ ˈ s t oʊ n\n",
      "\t ˈ k eɪ m ɝ ə n\n",
      "\t ˈ w ɪ l ə b i\n",
      "\t ˈ θ eɪ l ə\n",
      "Epoch 108: train loss: 0.5342\tdev loss: 0.4567                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ s ɝː z h ʊ d\n",
      "\t d ɪ ˈ f eɪ p r ə\n",
      "\t ˈ r aɪ eɪ t ə\n",
      "\t ˈ r ɛ g r ɪ ʃ\n",
      "\t ˌ t r ɪ k ˈ s t eɪ ʃ ə n z\n",
      "Epoch 109: train loss: 0.5341\tdev loss: 0.4566                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 2%, novel: 79%\n",
      "\t s ə ˈ r oʊ l i\n",
      "\t m ə ˈ v eɪ v\n",
      "\t ˈ b w iː z\n",
      "\t ˈ d ɪ ŋ k ə\n",
      "\t ˌ d æ k ə ɝ ˈ m ɪ s p\n",
      "Epoch 110: train loss: 0.5340\tdev loss: 0.4566                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ oʊ l z ˌ s t j uː\n",
      "\t ˈ s ɪ m z ə l\n",
      "\t ˈ w ɛ l ɝ\n",
      "\t ˈ s k ɑː n g oʊ\n",
      "\t ˈ k ɪ s t\n",
      "Epoch 111: train loss: 0.5339\tdev loss: 0.4565                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t l uː k ə ˈ t oʊ t ɑː n\n",
      "\t ˈ d ɛ k s ɪ z\n",
      "\t ˈ p r iː d\n",
      "\t p iː ɑː ˈ s h ɔ r ˌ b uː\n",
      "\t ˈ s uː l ɪ z\n",
      "Epoch 112: train loss: 0.5338\tdev loss: 0.4564                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ə ˈ dʒ ɪ ʃ ɪ k\n",
      "\t ˈ d ɪ ŋ oʊ\n",
      "\t ˈ p oʊ s ə z\n",
      "\t ˈ b uː\n",
      "\t ˈ h w ɔ r k ə b ə l\n",
      "Epoch 113: train loss: 0.5337\tdev loss: 0.4563                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 3%, novel: 89%\n",
      "\t ˈ l æ n d ɪ l s\n",
      "\t s ə m ˈ m æ p ɪ g ˌ b eɪ z\n",
      "\t ˈ ɔ r k ə ˌ n iː\n",
      "\t ˈ ɛ n d l i\n",
      "\t ɪ p ə ˈ t ɪ k s k i\n",
      "Epoch 114: train loss: 0.5336\tdev loss: 0.4562                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t b ɝ ˈ æ p t ɪ d\n",
      "\t ˈ k æ d ɪ k\n",
      "\t ˌ v ɛ r ə ˈ p ɝː dʒ ə t ə t s\n",
      "\t ˌ aɪ ˈ g ɪ s t ə n\n",
      "\t ˈ v ɑː n ʃ ɝ z\n",
      "Epoch 115: train loss: 0.5335\tdev loss: 0.4562                                                                                             \n",
      "\tGenerated: in train: 20%, assess: 0%, novel: 80%\n",
      "\t ˈ f l oʊ dʒ ɝ\n",
      "\t ə ˈ k ɛ m\n",
      "\t ˈ r ɪ g ə m ə n z\n",
      "\t ˈ t r iː z\n",
      "\t ˈ r iː ɝ t\n",
      "Epoch 116: train loss: 0.5334\tdev loss: 0.4561                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t ˈ k æ s t ə l\n",
      "\t ˈ ɑː n t\n",
      "\t d ɪ ˈ tʃ ʌ n t ɪ k\n",
      "\t ˈ w oʊ g ə\n",
      "\t ˈ s iː θ\n",
      "Epoch 117: train loss: 0.5333\tdev loss: 0.4560                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ s t ɪ n t l aɪ ˌ w aɪ p z\n",
      "\t ˈ g r ɛ r ˌ m aɪ z d\n",
      "\t b ə ˈ z ɔ r iː ə z\n",
      "\t ˈ r eɪ n t l i\n",
      "\t ˈ k ɝː m iː d ə l\n",
      "Epoch 118: train loss: 0.5333\tdev loss: 0.4560                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˈ dʒ uː t ɪ s\n",
      "\t ˈ d aɪ k s\n",
      "\t ˈ w ɔ r ˌ t aɪ z ɪ s\n",
      "\t ˈ w ɔ r z ə n\n",
      "\t ˈ d uː n ə l\n",
      "Epoch 119: train loss: 0.5332\tdev loss: 0.4559                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ v ɛ k s\n",
      "\t d æ m ˈ p r eɪ ˌ t r iː\n",
      "\t ˈ f ʌ l t ɪ t s i\n",
      "\t ˈ h ɝː z j oʊ\n",
      "\t ˈ m ɑː r m ə n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: train loss: 0.5333\tdev loss: 0.4560                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 1%, novel: 82%\n",
      "\t ˈ b w eɪ n l i\n",
      "\t ˈ k j uː ˈ æ ŋ k ɝ\n",
      "\t ˈ l ɛ θ ɑː dʒ\n",
      "\t ˈ f ɑː r t d\n",
      "\t ˈ ɪ r ɪ ˌ l eɪ b iː d n ɝ\n",
      "Epoch 121: train loss: 0.5330\tdev loss: 0.4557                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ g r aɪ dʒ\n",
      "\t ˈ b l ʌ n d d\n",
      "\t ˈ f r aʊ ɝ\n",
      "\t ˈ s aʊ n d ɝ\n",
      "\t ˈ t r ɛ θ ɝ\n",
      "Epoch 122: train loss: 0.5329\tdev loss: 0.4557                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 5%, novel: 85%\n",
      "\t ˈ s eɪ h aɪ ˌ h ɔ r\n",
      "\t ˈ m ɪ n t r ə s\n",
      "\t ˈ t w ɔ k s k i\n",
      "\t ˈ d ɔ ˌ f ɝː n\n",
      "\t ˈ b eɪ dʒ ə\n",
      "Epoch 123: train loss: 0.5328\tdev loss: 0.4556                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t ˌ æ s ˈ g uː s ə ˌ l æ s ɪ n\n",
      "\t d ɪ ˈ m eɪ t ɪ ŋ\n",
      "\t ˌ v ɝː l ə m ˈ w ɪ ʃ t n i\n",
      "\t ˈ k l aɪ f r ɪ t\n",
      "\t ˈ v ɑː l oʊ z\n",
      "Epoch 124: train loss: 0.5328\tdev loss: 0.4556                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ g r ɪ m ɝ z\n",
      "\t h ə ˈ m ɑː v r ɪ k\n",
      "\t ˈ d ɪ k t r oʊ z\n",
      "\t ˌ ɪ ˈ m ɑː n j ə n\n",
      "\t ɪ m ˈ j uː f ɝ\n",
      "Epoch 125: train loss: 0.5327\tdev loss: 0.4555                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ v æ t ɪ ˌ p ɛ r ə z\n",
      "\t ˈ k r iː p ɝ ˌ d ɝː\n",
      "\t b ɪ l t r oʊ ˈ f ʊ tʃ\n",
      "\t ˈ ʃ aɪ n dʒ ɪ ŋ\n",
      "\t ˈ g ɔ n s t iː ə\n",
      "Epoch 126: train loss: 0.5326\tdev loss: 0.4554                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ f iː ˌ l ɔ r\n",
      "\t ˈ h eɪ t ɝ\n",
      "\t ˈ s k ɪ v ə f\n",
      "\t ˈ w aɪ l\n",
      "\t ˌ n æ p ə s ˈ k ɔ r\n",
      "Epoch 127: train loss: 0.5325\tdev loss: 0.4554                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 0%, novel: 95%\n",
      "\t dʒ ə b ˈ s p l iː s ɪ ŋ\n",
      "\t ˈ v ɝː t s\n",
      "\t ə z ˈ l ɔ r ɪ ŋ\n",
      "\t ˈ k j ɔ r oʊ\n",
      "\t ˈ b l oʊ n ˈ m eɪ θ ɪ ŋ\n",
      "Epoch 128: train loss: 0.5324\tdev loss: 0.4553                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t m ɪ ˈ s l ɛ dʒ ɪ s t\n",
      "\t ˈ f r ɑː f p ə\n",
      "\t ˈ ð æ s i\n",
      "\t b iː ˈ oʊ k ə n\n",
      "\t ˈ v æ t\n",
      "Epoch 129: train loss: 0.5323\tdev loss: 0.4553                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ˈ s m iː ˌ w eɪ n\n",
      "\t ˈ s j aɪ n ə l ə\n",
      "\t ˈ d oʊ t ˌ s t aʊ s\n",
      "\t ˈ k ɑː s ə b ʊ r i\n",
      "\t ˌ dʒ ɪ k ˈ t iː r d\n",
      "Epoch 130: train loss: 0.5323\tdev loss: 0.4552                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t ˈ s p ɑː l t ə l i\n",
      "\t ˈ m iː m ɑː l d\n",
      "\t ˈ b r uː b ˌ m aɪ z\n",
      "\t ˈ p iː z\n",
      "\t ˈ t ɪ g b ɝ d\n",
      "Epoch 131: train loss: 0.5322\tdev loss: 0.4551                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ s ɑː oʊ n d l oʊ\n",
      "\t f ɪ ˈ s t r ɑː n t i\n",
      "\t m ə ˈ p ɑː f ˌ t æ s\n",
      "\t ə ˌ s ɛ l ə ˌ m uː l eɪ ˌ t eɪ v ɪ ŋ\n",
      "\t ˌ b iː k r ə ˈ k r ʌ n v i\n",
      "Epoch 132: train loss: 0.5322\tdev loss: 0.4551                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ g ɛ n tʃ ɝ ɝ ɪ ŋ\n",
      "\t ˈ h æ n ɝ ˈ j uː n\n",
      "\t ˈ m ɪ p l i\n",
      "\t v ə ˌ d ɛ r t ˌ ɑː l eɪ ˈ t ɛ k s ɪ ŋ\n",
      "\t ˈ θ ɝː m ɝ z ɝ d\n",
      "Epoch 133: train loss: 0.5321\tdev loss: 0.4550                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t ˈ t ɪ f s æ t\n",
      "\t p ə l ˈ v æ d iː ə l\n",
      "\t ˈ d ɛ ð ɝ ɔɪ n\n",
      "\t ˈ s t ɛ ʃ ə g ɛ n d\n",
      "\t ˈ s l oʊ z ɪ ŋ z\n",
      "Epoch 134: train loss: 0.5321\tdev loss: 0.4550                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ aɪ ɝ\n",
      "\t ˈ l eɪ z ə dʒ n i\n",
      "\t ˈ p r oʊ\n",
      "\t ˈ d oʊ n ə l\n",
      "\t b j ɝ ˈ ɛ k s l i\n",
      "Epoch 135: train loss: 0.5320\tdev loss: 0.4549                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ f aɪ d\n",
      "\t ˈ h ɑː r l d\n",
      "\t ˈ h æ n s ə ˌ l ɛ ŋ\n",
      "\t ˈ w iː v ˌ s t aɪ t s\n",
      "\t ˌ ɪ tʃ oʊ ˈ b oʊ l d ə\n",
      "Epoch 136: train loss: 0.5319\tdev loss: 0.4549                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ b ɝː ə ˌ p iː m\n",
      "\t ˌ s ɪ l ˌ w ɛ r iː ˈ oʊ\n",
      "\t ə n ˈ v ɪ m ə l\n",
      "\t ˈ t iː ˌ p oʊ\n",
      "\t ˌ d iː ə ˈ s t ɑː n\n",
      "Epoch 137: train loss: 0.5318\tdev loss: 0.4548                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ r æ k s\n",
      "\t ˈ b ɛ n ə n tʃ ɝ z\n",
      "\t ˈ t ɑː n k ə n\n",
      "\t ˈ r oʊ d ə n ˌ k r æ f\n",
      "\t ˈ l ɛ k k ə ˌ l ɛ z\n",
      "Epoch 138: train loss: 0.5318\tdev loss: 0.4548                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 1%, novel: 80%\n",
      "\t ˈ b r ɪ s aʊ ə n\n",
      "\t ˈ b ɑː l t\n",
      "\t d iː m ə ˈ m ɛ l l z\n",
      "\t ˌ ə n t r ɑː ˈ n oʊ p ɝ\n",
      "\t ˈ k r ɑː k ə l z\n",
      "Epoch 139: train loss: 0.5317\tdev loss: 0.4547                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˌ n ɛ v ə ˈ dʒ ɔ n ə s ɪ n\n",
      "\t ˈ d ɪ g ə n s iː n\n",
      "\t ˈ b ɪ g ə l\n",
      "\t ˈ v æ m ə k ɝ\n",
      "\t ɪ ˈ t ɪ g ə n ə s\n",
      "Epoch 140: train loss: 0.5316\tdev loss: 0.4547                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ə ˌ k aʊ z ˈ eɪ t s\n",
      "\t n ə k ˈ t iː n i\n",
      "\t ə n ˌ s ɪ k s uː ˈ l eɪ ʃ ə n\n",
      "\t ə ˈ m ɑː d ə n z\n",
      "\t ˈ d aʊ l d\n",
      "Epoch 141: train loss: 0.5316\tdev loss: 0.4546                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t s ə ˈ l eɪ b ə l d\n",
      "\t aʊ k ˈ s ɪ l ɝ d ə ˈ m ɛ l ə\n",
      "\t ˈ h ɔɪ l d\n",
      "\t ˈ m eɪ l z\n",
      "\t ˈ dʒ iː ˌ l iː z\n",
      "Epoch 142: train loss: 0.5316\tdev loss: 0.4546                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ h ɪ ŋ g ɪ ŋ\n",
      "\t k ɑː n ˈ w ɑː n ə\n",
      "\t ˈ m ɛ g ə n d\n",
      "\t ˈ f ɪ k ə ˌ n aɪ d l ɪ ŋ\n",
      "\t ˈ b r æ n b ɝ l b ə l\n",
      "Epoch 143: train loss: 0.5314\tdev loss: 0.4545                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t b æ g ˈ s p r ɛ t ə n\n",
      "\t ˈ w ɪ p ɝ s n ə\n",
      "\t ˈ r iː l d\n",
      "\t ˈ j uː m ˌ k ɑː l d\n",
      "\t ˈ p r ɪ v ɪ ˌ b ɔ r i\n",
      "Epoch 144: train loss: 0.5313\tdev loss: 0.4544                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ oʊ l ə s\n",
      "\t ˈ r ɑː l s ə n d ɝ\n",
      "\t ˈ t ɛ r ɪ n\n",
      "\t k ɑː l ˌ k oʊ ˈ m eɪ ʃ ə n\n",
      "\t ˈ ʃ ɛ ŋ k ɝ d\n",
      "Epoch 145: train loss: 0.5314\tdev loss: 0.4544                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ d r ɪ k ɝ dʒ eɪ ˌ k iː t\n",
      "\t ˌ h ə z iː ˈ d ɛ l ə ˌ t j uː\n",
      "\t ˈ ɛ m ə n\n",
      "\t ˈ k ɑː f w eɪ ð ɝ z\n",
      "\t ˈ b ɑː k l iː\n",
      "Epoch 146: train loss: 0.5312\tdev loss: 0.4543                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t ˈ k r ɪ s ˌ s k aɪ r\n",
      "\t ˈ h æ k ɪ k i\n",
      "\t ˈ l oʊ s t ə l\n",
      "\t ˈ k aʊ n ɪ ŋ\n",
      "\t ˈ b r æ p t\n",
      "Epoch 147: train loss: 0.5312\tdev loss: 0.4543                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ p iː k ə\n",
      "\t b aɪ l ə ˈ b ɝː t ə\n",
      "\t d ˈ f ɝː t oʊ\n",
      "\t ˈ r ɛ t ɝ z\n",
      "\t ˈ m ɛ l oʊ\n",
      "Epoch 148: train loss: 0.5312\tdev loss: 0.4543                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˌ l ɔ r ɪ ˈ v uː ʃ ə n\n",
      "\t ˈ r ɪ n\n",
      "\t ˈ r ʌ g ɪ ŋ\n",
      "\t ˈ f ə l\n",
      "\t ˈ oʊ tʃ ɝ ˌ m iː d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: train loss: 0.5311\tdev loss: 0.4543                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ n ʌ ŋ g ɝ z\n",
      "\t ˈ n iː d ˌ v ɪ l\n",
      "\t ˈ n oʊ\n",
      "\t ˈ ɛ s t ə ˌ l aɪ t\n",
      "\t ˌ t r ɪ dʒ ə ˈ l ɛ n i\n",
      "Epoch 150: train loss: 0.5311\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ b uː d\n",
      "\t ˈ f r aɪ k ə m\n",
      "\t ˈ k r ɑː r z\n",
      "\t ˌ d ɑː r ˈ t aɪ oʊ ˌ n eɪ t\n",
      "\t ˈ k iː s t ə n\n",
      "Epoch 151: train loss: 0.5310\tdev loss: 0.4542                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t ˈ eɪ p ɪ n s ə n\n",
      "\t ˈ ɛ tʃ ɝ θ\n",
      "\t ˈ ɛ f p ɝ ˌ h iː t l i\n",
      "\t d ɪ ˈ p uː z\n",
      "\t ə ˈ m aɪ d z\n",
      "Epoch 152: train loss: 0.5309\tdev loss: 0.4541                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t m ə ˈ k ɑː r ɪ n\n",
      "\t ˈ m ɛ l ɪ k\n",
      "\t ˈ s ɪ n ɪ n\n",
      "\t ɛ ˈ h g r ɑː\n",
      "\t ˌ æ ð aɪ ˈ k ɑː n s k oʊ\n",
      "Epoch 153: train loss: 0.5309\tdev loss: 0.4541                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ə ˈ n ɑː t r oʊ\n",
      "\t ə ˈ m ɛ r ɪ k\n",
      "\t ˈ r ʌ m p l ə d\n",
      "\t ˈ k ɑː b ɪ z ə dʒ ɪ ŋ\n",
      "\t ˈ g w ɪ n ɪ ŋ g r ɪ g\n",
      "Epoch 154: train loss: 0.5309\tdev loss: 0.4540                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˈ d ɛ s t ɪ n z\n",
      "\t ˈ b l uː p ə s i\n",
      "\t ˈ b uː θ ˌ r ɪ ŋ z\n",
      "\t ˈ v iː d z\n",
      "\t ˈ k ɑː d k iː ə n ɝ\n",
      "Epoch 155: train loss: 0.5308\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t ɑː t ə ˈ l ɪ n\n",
      "\t ˈ t ʌ n d ə n ˌ s eɪ z\n",
      "\t ˈ m æ s ɪ n t ə n z\n",
      "\t ˈ ɪ n ˌ b r ɪ n ɪ z\n",
      "\t ɛ m ˈ b æ ŋ k\n",
      "Epoch 156: train loss: 0.5308\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˌ iː ˈ t eɪ v i\n",
      "\t ˈ k l ɑː l d\n",
      "\t ˈ s k ɛ r ɪ n s\n",
      "\t ˈ s p ɛ dʒ ɪ ˌ k ɔ k s\n",
      "\t ˌ k ɑː n ə n ˈ s aɪ p ə\n",
      "Epoch 157: train loss: 0.5307\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 4%, novel: 87%\n",
      "\t ˌ ɪ n ˈ m ɛ k t ɪ d\n",
      "\t ɪ ˈ g oʊ l s\n",
      "\t ˈ j ɔ k s ə n\n",
      "\t ˈ p ɔ\n",
      "\t ˈ ɑː r n ɪ ŋ\n",
      "Epoch 158: train loss: 0.5306\tdev loss: 0.4539                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ə ˈ g r ɔ k ə m\n",
      "\t ɛ m ə ˈ k r iː s i\n",
      "\t ˈ h aʊ t\n",
      "\t ˈ b r ɑː b ɪ l\n",
      "\t ˈ w ɛ l n\n",
      "Epoch 159: train loss: 0.5306\tdev loss: 0.4538                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ b aɪ l\n",
      "\t ˈ m ɑː r ɪ k\n",
      "\t ˈ r ɛ s t\n",
      "\t ˈ ʃ ɝː m ɝ\n",
      "\t ˈ dʒ iː k ə n\n",
      "Epoch 160: train loss: 0.5306\tdev loss: 0.4538                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t ˈ l æ g s k i\n",
      "\t r ɪ ˈ p ɪ g ɔ s\n",
      "\t ɛ n ə ˈ k w ɛ r ə\n",
      "\t ˈ eɪ k ɪ n\n",
      "\t ˈ m oʊ l\n",
      "Epoch 161: train loss: 0.5305\tdev loss: 0.4538                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ ʌ m p ˌ g r ʊ n d\n",
      "\t ˈ s ɛ l\n",
      "\t ˈ n ɝː s j uː ˌ l æ k t ɝ\n",
      "\t ˈ f oʊ l d\n",
      "\t tʃ ɪ ˈ n ɑː tʃ ɝ\n",
      "Epoch 162: train loss: 0.5304\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ θ ʌ k ə t\n",
      "\t ˈ ɑː n t i\n",
      "\t z ɪ ˈ g oʊ m i\n",
      "\t ˈ h æ m p l ɛ ˌ m eɪ t i\n",
      "\t ˈ θ ɪ ʃ\n",
      "Epoch 163: train loss: 0.5303\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ f w ɛ l ɪ s\n",
      "\t ˈ t r iː m oʊ\n",
      "\t p ɝ ˈ eɪ ʃ ə n\n",
      "\t ˈ r ɔ r m ə n t\n",
      "\t ˈ k r aɪ ɝ t\n",
      "Epoch 164: train loss: 0.5304\tdev loss: 0.4537                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t n ɑː ˈ n uː l oʊ\n",
      "\t ˈ h æ n t ɝ ˌ w aɪ ɝ z\n",
      "\t ˈ k w ɔ r t ɝ\n",
      "\t ˈ dʒ aɪ n s t ɪ ŋ z\n",
      "\t ˈ k ɑː r ə l i\n",
      "Epoch 165: train loss: 0.5304\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ w ɛ l m\n",
      "\t ˈ ɪ s t ɝ ˌ h ɪ k\n",
      "\t ˈ dʒ eɪ t z\n",
      "\t ˈ w aɪ z d\n",
      "\t f ˈ w ɔ j ɝ\n",
      "Epoch 166: train loss: 0.5303\tdev loss: 0.4536                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 0%, novel: 94%\n",
      "\t ɛ ˈ t r ɑː ˌ dʒ ɪ t l i\n",
      "\t ˌ n iː ɔ ˈ f r aɪ oʊ m\n",
      "\t ˈ ɪ l s t ɝ\n",
      "\t ˈ t aɪ d i\n",
      "\t ˈ g ɪ n oʊ\n",
      "Epoch 167: train loss: 0.5302\tdev loss: 0.4535                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ t æ l ɪ ŋ\n",
      "\t ˌ v ə n ˈ f ɑː ʃ ə ˌ t oʊ\n",
      "\t ˈ ɑː r g ə l\n",
      "\t ˈ t aɪ t ɪ b ə n z\n",
      "\t ˈ ɪ h ɝ d\n",
      "Epoch 168: train loss: 0.5302\tdev loss: 0.4535                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˈ ɪ p r ə l\n",
      "\t ˈ m æ l t ə l\n",
      "\t ˌ f ɛ l ə ˈ w ɪ t ɪ ŋ\n",
      "\t ˈ b l ɪ t ˌ f ɑː k s\n",
      "\t ˈ w aɪ n z ˌ s t aɪ m\n",
      "Epoch 169: train loss: 0.5301\tdev loss: 0.4535                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˌ z iː iː ˌ oʊ l iː iː ˈ t ɑː l\n",
      "\t ˈ l oʊ t ɪ d\n",
      "\t d ə ˈ m ɑː r d iː ə n d\n",
      "\t ˈ s p r ɪ v i\n",
      "\t ˈ k r ɑː k\n",
      "Epoch 170: train loss: 0.5301\tdev loss: 0.4535                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t m ə k ˈ s l ɪ n oʊ m\n",
      "\t ˈ j uː ˌ s k ɑː r i\n",
      "\t ˈ t r æ t ɪ ŋ i\n",
      "\t ˈ b iː k ə\n",
      "\t ˈ k oʊ\n",
      "Epoch 171: train loss: 0.5300\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t ˈ æ n dʒ n ɝ\n",
      "\t n ɑː ˈ ʒ ɑː n ə\n",
      "\t ˌ ə s iː s ɑː r t ɪ ˈ h æ s iː ə n\n",
      "\t ˈ h aɪ ɝ z\n",
      "\t ˈ t ɔ s k ɪ l\n",
      "Epoch 172: train loss: 0.5300\tdev loss: 0.4534                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t k ə n ˈ k iː\n",
      "\t ˈ b ʌ v ɝ ˌ w ɑː s t\n",
      "\t ˈ k ɔ n z\n",
      "\t ˈ ʃ l ɪ b ɪ l\n",
      "\t ˈ g æ n d ɪ d\n",
      "Epoch 173: train loss: 0.5300\tdev loss: 0.4533                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ t ɔ r b ɪ l\n",
      "\t ˌ v oʊ ˈ k w ɪ k ə ˌ k eɪ t z\n",
      "\t ə ˈ s oʊ p j uː m\n",
      "\t ˈ s p ɛ n t ɪ ŋ ɝ\n",
      "\t ˈ θ ɑː l m ə\n",
      "Epoch 174: train loss: 0.5300\tdev loss: 0.4533                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t d ɪ k ˈ p iː b iː ə l\n",
      "\t ˈ s ɛ l ɝ ˌ p eɪ\n",
      "\t ˈ b ʊ dʒ ɪ s t s\n",
      "\t p ɪ ˈ t ɑː n ɪ t\n",
      "\t ˈ ɛ k f\n",
      "Epoch 175: train loss: 0.5300\tdev loss: 0.4533                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ k oʊ l ə n t l i\n",
      "\t ˈ t eɪ\n",
      "\t ˈ z ɑː ˌ k ɛ n z\n",
      "\t ə ˈ p oʊ v\n",
      "\t ˈ dʒ uː v ə\n",
      "Epoch 176: train loss: 0.5299\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 1%, novel: 80%\n",
      "\t ˈ r ʌ s t w ə tʃ i\n",
      "\t ˈ g ɑː g i\n",
      "\t ˈ h ɔ r m ɪ n\n",
      "\t p ɪ ˈ b ɑː r k ɝ\n",
      "\t ˈ f l ʌ n ˌ g oʊ t\n",
      "Epoch 177: train loss: 0.5298\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 2%, novel: 93%\n",
      "\t d ə ˈ v ɛ d r oʊ z\n",
      "\t ˈ s iː b ɝ d\n",
      "\t ə ˈ k ɔ r t\n",
      "\t ˈ s iː k l ɪ s t\n",
      "\t ˈ l eɪ dʒ ɪ n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178: train loss: 0.5298\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ k s ʌ t ə tʃ ɪ k\n",
      "\t ˈ k r oʊ d ə n\n",
      "\t ɪ n ˈ f ɪ dʒ ɝ\n",
      "\t p ɪ ˌ m ə n t ɑː l oʊ ˈ t ɑː n d ɪ ŋ\n",
      "\t ˈ k l æ n n\n",
      "Epoch 179: train loss: 0.5298\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ˈ dʒ oʊ v ɪ n z\n",
      "\t ˈ ɑː r v iː i\n",
      "\t ˈ f ɝː t ɪ ŋ\n",
      "\t ˈ p ɛ m w ə ʃ n ə\n",
      "\t ˈ d ɑː s ə f ɝ n s t\n",
      "Epoch 180: train loss: 0.5297\tdev loss: 0.4532                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ s p aɪ z\n",
      "\t ˈ m ɪ k\n",
      "\t ˈ s l æ d ʃ ə n\n",
      "\t ˈ h j uː r\n",
      "\t ˈ dʒ ɛ n tʃ f r ə n z\n",
      "Epoch 181: train loss: 0.5296\tdev loss: 0.4531                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ p l ɛ l b ə n z\n",
      "\t ˈ h ɝː t ə n\n",
      "\t b ɝ ˈ æ n d ə m\n",
      "\t ˈ l ʌ d ɪ ŋ\n",
      "\t ˈ ɔ r n ɝ\n",
      "Epoch 182: train loss: 0.5297\tdev loss: 0.4530                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t d ə n ˈ k ɛ r dʒ\n",
      "\t ˈ s eɪ v ɝ\n",
      "\t ˈ n eɪ t ɝ\n",
      "\t ˌ k ɛ ˈ ʃ æ dʒ m ə s t\n",
      "\t ˈ p ɑː s ə k\n",
      "Epoch 183: train loss: 0.5296\tdev loss: 0.4530                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t p ɪ ˈ t æ t ɪ s t\n",
      "\t b ɝ ˈ k j uː t ə l i\n",
      "\t ˈ s t æ n d ɝ\n",
      "\t ˈ s t ʌ s t ə ˌ l ɔ k\n",
      "\t ˌ d ɪ s ə ˈ s ɪ l ə\n",
      "Epoch 184: train loss: 0.5296\tdev loss: 0.4529                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t ˈ k oʊ d ɝ\n",
      "\t ə ˈ n ɑː n ɪ g ə t ɝ\n",
      "\t ˈ iː ˌ s aɪ\n",
      "\t k ɪ n ˈ n ɪ ŋ k\n",
      "\t ˈ f ɪ k m ə n\n",
      "Epoch 185: train loss: 0.5296\tdev loss: 0.4530                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ θ aɪ ŋ ɝ z\n",
      "\t ˈ s g ɑː t\n",
      "\t ˈ r ʌ b ɪ s t\n",
      "\t ˈ k eɪ n t ə t\n",
      "\t ˈ m æ f ɑː k s ɪ ŋ\n",
      "Epoch 186: train loss: 0.5295\tdev loss: 0.4530                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t ˈ oʊ m ə n\n",
      "\t ˈ h aɪ t ɪ ŋ\n",
      "\t g ˈ m eɪ b ə\n",
      "\t ˈ tʃ iː z\n",
      "\t ˈ tʃ ɝː z i\n",
      "Epoch 187: train loss: 0.5295\tdev loss: 0.4529                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ t ɑː g w ɪ d\n",
      "\t ˈ s m æ g r ɪ n\n",
      "\t ˈ m ɔ r l ə\n",
      "\t ˈ ʃ eɪ l ɝ\n",
      "\t ˈ l ɪ n s n ə l d\n",
      "Epoch 188: train loss: 0.5295\tdev loss: 0.4529                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ p uː n ə ˌ l æ d ɪ ŋ\n",
      "\t r ə ˈ m aɪ p\n",
      "\t ˈ d ɛ ŋ g ɝ t s\n",
      "\t ˈ w ɑː f ə l ɝ\n",
      "\t ˈ d ɪ v ə b ə l\n",
      "Epoch 189: train loss: 0.5294\tdev loss: 0.4528                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t ˈ k j uː ɪ t iː ˌ iː s\n",
      "\t ˈ w eɪ\n",
      "\t ˈ s t r ʌ k t r ə\n",
      "\t w ə ˈ t ɛ r ɪ ŋ\n",
      "\t l ə ˈ v ɑː tʃ m ə n z\n",
      "Epoch 190: train loss: 0.5294\tdev loss: 0.4529                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 4%, novel: 86%\n",
      "\t ˈ d iː m ɛ n ɪ ŋ\n",
      "\t ˈ h ɔ r k s\n",
      "\t ˈ oʊ l i\n",
      "\t m ɝː ˈ g uː p ə t ɝ\n",
      "\t ˈ s t iː p ɪ l z\n",
      "Epoch 191: train loss: 0.5293\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t ˈ t r oʊ t ɪ g\n",
      "\t ˈ t j uː z\n",
      "\t ˈ g eɪ s t ə d s\n",
      "\t ˈ g ɑː d\n",
      "\t ˈ k r iː z ə d ɪ ŋ\n",
      "Epoch 192: train loss: 0.5293\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t s ɑː ˈ z eɪ k i\n",
      "\t ˈ f iː n d ə n\n",
      "\t ˈ ʃ ɛ g m ə n z\n",
      "\t p ɪ ˈ l ɪ f ʃ ə n\n",
      "\t ˈ s l æ ŋ k ɪ\n",
      "Epoch 193: train loss: 0.5293\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 0%, novel: 93%\n",
      "\t ˈ h eɪ dʒ ɪ ŋ\n",
      "\t ˈ b ɑː k ɪ ŋ\n",
      "\t ˈ l ɛ n f ɝ z\n",
      "\t ˈ d r ɔ d\n",
      "\t ə m ˈ p ɛ r ɪ v\n",
      "Epoch 194: train loss: 0.5292\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t m ɪ w ə n ˈ d ɑː p t\n",
      "\t ɪ k ˈ f uː\n",
      "\t ˈ s p ɪ r ə l i\n",
      "\t ˈ k w ɪ z i\n",
      "\t ˈ s t r eɪ z ˌ b ɪ k\n",
      "Epoch 195: train loss: 0.5292\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t ˈ g oʊ l tʃ ɝ t ə t\n",
      "\t ˈ d ɔ r k s ɪ ŋ\n",
      "\t ˈ ɑː n d\n",
      "\t r ə ˈ p iː l d\n",
      "\t ˌ ɪ m d ɝ f ɔ r p ˈ s aɪ l f r ə\n",
      "Epoch 196: train loss: 0.5292\tdev loss: 0.4526                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ g r ɪ m ɪ ŋ\n",
      "\t ə ˈ s n ɪ ʃ t ə ˌ m eɪ p ə l\n",
      "\t ˈ w ɔ r t r ə z\n",
      "\t ˈ v ɝː g i\n",
      "\t ˈ m ɑː r k ə ˌ n eɪ t s\n",
      "Epoch 197: train loss: 0.5291\tdev loss: 0.4527                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t m ə l ˈ b aɪ r iː ə n\n",
      "\t ˈ l uː g ɝ d\n",
      "\t ˈ t r uː ə n dʒ ə l\n",
      "\t ˈ k uː z ˌ b ɔ r\n",
      "\t ˈ b aɪ r z\n",
      "Epoch 198: train loss: 0.5291\tdev loss: 0.4526                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t ˈ s p l ɑː n\n",
      "\t ˈ t æ n oʊ z\n",
      "\t ə ˈ dʒ uː t ɪ m\n",
      "\t ˈ tʃ ɛ r ˌ b ɛ r d\n",
      "\t ˈ w uː z\n",
      "Epoch 199: train loss: 0.5291\tdev loss: 0.4525                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ b ɑː r t ɪ k\n",
      "\t k ɑː r ˈ n ɑː r ɪ m\n",
      "\t r ɪ ˈ s ɑː l dʒ ə n ə t z\n",
      "\t ˈ t ɛ l b i\n",
      "\t ˈ d ɑː n dʒ\n",
      "Epoch 200: train loss: 0.5291\tdev loss: 0.4526                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t d ɪ ˈ r iː v ɪ s t\n",
      "\t ˌ k æ p ˈ s t ɛ k ʃ ə n t\n",
      "\t ˈ dʒ iː n ɪ f\n",
      "\t ˈ g æ f t r iː ˌ iː d\n",
      "\t r iː ˈ ɪ n θ\n",
      "Epoch 201: train loss: 0.5291\tdev loss: 0.4526                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ b uː s ə k\n",
      "\t ˈ w ɪ b l ɪ ŋ\n",
      "\t ˈ s ɛ s ˌ h ɪ s l i\n",
      "\t ˈ v æ d f ɝ ˌ ɑː t\n",
      "\t ˌ ʃ ɑː r ˈ k oʊ n oʊ\n",
      "Epoch 202: train loss: 0.5290\tdev loss: 0.4525                                                                                             \n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t eɪ ˈ t eɪ s ɪ z\n",
      "\t ˈ k ɑː m ˌ f l æ b\n",
      "\t ˌ h ɑː v iː ˈ b uː m ə t iː z ɝ\n",
      "\t ˌ r uː d iː ˈ v ɛ s\n",
      "\t ˈ b ɝː r oʊ\n",
      "Epoch 203: train loss: 0.5289\tdev loss: 0.4525                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t s ɛ z ˈ m oʊ n ɪ ŋ\n",
      "\t ˌ ɪ n ˈ k iː v\n",
      "\t ˌ f ʊ d ɝ ˈ eɪ ʃ ə n\n",
      "\t ˈ s p æ t iː z\n",
      "\t ˈ d ɪ n oʊ ˌ w ɔ l θ\n",
      "Epoch 204: train loss: 0.5288\tdev loss: 0.4524                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ s k ɑː n k ɝ\n",
      "\t ˈ oʊ t ə g ɝ\n",
      "\t ˈ m ɑː r iː ə n z\n",
      "\t ˈ b æ θ ɪ ˌ t l eɪ\n",
      "\t ˈ r iː m ˌ s t ɪ θ s\n",
      "Epoch 205: train loss: 0.5289\tdev loss: 0.4525                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 0%, novel: 81%\n",
      "\t ˈ k ɔ ŋ k ɑː r m ə\n",
      "\t ˌ æ ˈ g r ɑː n d iː ə\n",
      "\t ˈ ɔɪ f\n",
      "\t r ə ˈ p uː t ɪ k\n",
      "\t ˈ t ɛ n s n ɝ\n",
      "Epoch 206: train loss: 0.5288\tdev loss: 0.4524                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t k ə ˈ k iː l ə\n",
      "\t ˈ l ɪ ˌ n iː t\n",
      "\t r ə ˈ t ɛ k t ɪ d z\n",
      "\t ˈ s k iː b ə l\n",
      "\t ˈ ʌ b l ˌ w ʊ g ɝ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: train loss: 0.5289\tdev loss: 0.4524                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˌ æ n t r iː ˈ n ɑː k j ə n\n",
      "\t ˈ m ɝː z\n",
      "\t ˈ p oʊ f\n",
      "\t ˈ r iː ˌ k aɪ\n",
      "\t ˈ f iː l ɛ k\n",
      "Epoch 208: train loss: 0.5288\tdev loss: 0.4523                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t ˈ v ɑː g ə s ə m\n",
      "\t ˈ f aɪ t s\n",
      "\t ə ˈ h ɝː m ə n\n",
      "\t d ɪ ˈ s t r ʌ n ʃ ɪ\n",
      "\t ˈ w ɪ m p l ɝ\n",
      "Epoch 209: train loss: 0.5288\tdev loss: 0.4523                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t ˈ n ɝː ə n\n",
      "\t ˌ n ɛ n ə n ɝ ˈ iː n ə\n",
      "\t s ə ˈ t r ɪ tʃ ɪ k\n",
      "\t l ɪ ˈ n ɪ l ə\n",
      "\t ˈ k ʌ n ɝ l ɪ ŋ\n",
      "Epoch 210: train loss: 0.5287\tdev loss: 0.4523                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ l oʊ ə b ə l z\n",
      "\t ˈ p l ɔɪ n ə t\n",
      "\t ˈ v ɪ s l i\n",
      "\t ˈ r ɑː n ə\n",
      "\t ˌ dʒ iː f ə ˈ l ɔ n d i\n",
      "Epoch 211: train loss: 0.5288\tdev loss: 0.4524                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t k ə ˈ s iː s t s\n",
      "\t ˈ t iː p r ɪ k s\n",
      "\t ˈ r æ k i\n",
      "\t f j ə ˈ n æ s p ɝ\n",
      "\t ɛ ˈ d ɪ t\n",
      "Epoch 212: train loss: 0.5288\tdev loss: 0.4523                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˌ ɛ dʒ ə ˈ j eɪ j ə d ə l\n",
      "\t s ə ˈ n ɔ r eɪ\n",
      "\t ə ˈ r ɛ r ɛ n\n",
      "\t ˈ l oʊ z ə n\n",
      "\t ˈ g r iː l\n",
      "Epoch 213: train loss: 0.5287\tdev loss: 0.4522                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ h æ n dʒ ə s\n",
      "\t ˈ m oʊ d ə n t\n",
      "\t s ə ˈ ɛ l uː l i\n",
      "\t ˈ k æ l ə n z\n",
      "\t k ə n ˈ v eɪ s ɔ\n",
      "Epoch 214: train loss: 0.5286\tdev loss: 0.4522                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ tʃ ɛ r ˌ l ɛ ŋ k\n",
      "\t ˈ m ɑː r ˌ d ɔ m\n",
      "\t ˈ k w ɪ k t ə l\n",
      "\t d ɪ ˈ w eɪ l d\n",
      "\t m ɔ r ˈ f j ɑː v ɝ i\n",
      "Epoch 215: train loss: 0.5285\tdev loss: 0.4522                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˌ z oʊ ˈ t r ɛ t ə\n",
      "\t s ɪ ˈ g eɪ n j i\n",
      "\t r ə ˈ s ɪ l\n",
      "\t ˈ t ɛ n θ ɝ m ə n s ə\n",
      "\t ˈ p r oʊ z\n",
      "Epoch 216: train loss: 0.5285\tdev loss: 0.4521                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 6%, novel: 80%\n",
      "\t b ɑː ˈ n ɛ ŋ k s i\n",
      "\t ˈ s k w ɔ l\n",
      "\t ˈ l ʌ n s d iː ˌ ʃ iː d\n",
      "\t ˈ s t æ n ə l ɪ ŋ\n",
      "\t ˈ ɔ r ɝ\n",
      "Epoch 217: train loss: 0.5287\tdev loss: 0.4522                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 6%, novel: 88%\n",
      "\t ˈ æ n s ə s t\n",
      "\t ˈ s w ɑː k ə t iː z\n",
      "\t ˈ s l oʊ ˌ b ɑː t\n",
      "\t oʊ ˈ k ɑː t ə ˌ l æ k s\n",
      "\t ˈ s ʌ t r ə k\n",
      "Epoch 218: train loss: 0.5285\tdev loss: 0.4521                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ g aʊ n t ɝ ˌ g r eɪ s\n",
      "\t m ə ˈ w ɑː m ə n\n",
      "\t ˌ b ɛ r ə ˈ s t ɔ k d\n",
      "\t ˈ l ɔ r ˌ k oʊ l z\n",
      "\t ˈ h aʊ ɝ\n",
      "Epoch 219: train loss: 0.5284\tdev loss: 0.4520                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ə ˈ s ɪ n d\n",
      "\t ˈ g ɑː r d oʊ\n",
      "\t ˈ k æ f ɪ t s\n",
      "\t k j ɑː ˈ l aɪ ə t ɪ n\n",
      "\t s oʊ ˈ b uː\n",
      "Epoch 220: train loss: 0.5284\tdev loss: 0.4521                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˌ ɛ n s ɑː l ˈ t oʊ l d i\n",
      "\t ˈ p æ ð ɝ\n",
      "\t ˈ d ɛ l ɪ dʒ iː ɝ\n",
      "\t ˈ p æ ð ɪ z\n",
      "\t ˈ k w ɪ r dʒ ɪ d\n",
      "Epoch 221: train loss: 0.5285\tdev loss: 0.4521                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ tʃ ɛ n m ə m z\n",
      "\t v ə ˈ g ɔ r b i\n",
      "\t ˈ b ʌ k s\n",
      "\t m ə ˈ b l iː t ə\n",
      "\t ˈ b uː p l ɪ ŋ z\n",
      "Epoch 222: train loss: 0.5284\tdev loss: 0.4520                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ æ k iː z\n",
      "\t ˌ ɛ dʒ ɝ ˈ ɑː t oʊ\n",
      "\t ˈ ɔ s t r ə l i\n",
      "\t r iː ˈ ʌ m p ɝ d\n",
      "\t ˈ b ɛ r ɪ t s\n",
      "Epoch 223: train loss: 0.5283\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ k æ m ɑː n\n",
      "\t ˈ g iː n ˌ m ɪ s ə v\n",
      "\t ˈ s aɪ f ɪ k\n",
      "\t ˈ h ʌ n d ɪ ʃ ɪ d\n",
      "\t k ə k ˈ s ɪ h ə l\n",
      "Epoch 224: train loss: 0.5283\tdev loss: 0.4520                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ˈ r ʌ l\n",
      "\t ˈ n ɛ s i\n",
      "\t ˈ s l ɛ ˌ s t iː v aɪ s\n",
      "\t ˈ æ v r ɪ n\n",
      "\t ˈ k æ ŋ g ɝ ə l\n",
      "Epoch 225: train loss: 0.5284\tdev loss: 0.4520                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t d iː ˈ n oʊ k\n",
      "\t ˈ k æ m ɑː ˌ l iː\n",
      "\t ˈ b oʊ ʃ\n",
      "\t ˌ s æ v ə ˈ b æ t r ə\n",
      "\t ˈ d ɪ k ɪ ŋ\n",
      "Epoch 226: train loss: 0.5283\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t ˈ aʊ ə k s ə n\n",
      "\t ˈ m ɛ n ɑː dʒ\n",
      "\t ˈ w eɪ ʃ ɔ s t\n",
      "\t ˈ n ɛ m ɔ\n",
      "\t f r ɪ ˈ f j uː s t\n",
      "Epoch 227: train loss: 0.5283\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˈ n ɪ s t s i\n",
      "\t l ə ˈ v uː b ɝ\n",
      "\t ˈ n uː ˌ w ʊ d\n",
      "\t ˌ h uː ˌ t ɪ t ə ˈ l ɛ r j ə\n",
      "\t ˈ aɪ k\n",
      "Epoch 228: train loss: 0.5282\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t ˈ b ɛ r l\n",
      "\t ˈ d iː dʒ\n",
      "\t ˈ r uː ʃ m ə n\n",
      "\t ˈ b ɝː d ə d\n",
      "\t d iː ˈ n uː r iː ə n\n",
      "Epoch 229: train loss: 0.5282\tdev loss: 0.4518                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t ˈ n ɑː n t ə l z\n",
      "\t ˈ oʊ l d ə n\n",
      "\t t r ɪ ˈ r eɪ n i\n",
      "\t oʊ l ə ˈ v eɪ t ɪ t\n",
      "\t ˈ ʃ æ t s\n",
      "Epoch 230: train loss: 0.5282\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ b ɝː ɪ t\n",
      "\t ˈ z iː d ɪ s\n",
      "\t ˈ g ɛ n tʃ ə ˌ l aɪ d z\n",
      "\t ˈ d iː ˌ w ʊ k s\n",
      "\t ˈ s t ɝː b ɝ z\n",
      "Epoch 231: train loss: 0.5282\tdev loss: 0.4519                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t d ɪ d ˈ d uː r z\n",
      "\t ˈ l æ v ɝ l i\n",
      "\t ˈ l æ k s ɪ n z\n",
      "\t ˈ s p æ n ɝ\n",
      "\t ˈ h w aɪ z ɝ\n",
      "Epoch 232: train loss: 0.5281\tdev loss: 0.4518                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ w æ z ɪ k ə l\n",
      "\t ˈ ʌ ŋ\n",
      "\t ˈ h j uː ˌ s t ɔ f\n",
      "\t ˈ s aɪ ˌ t aɪ n\n",
      "\t ˈ k r æ k ɪ d\n",
      "Epoch 233: train loss: 0.5282\tdev loss: 0.4518                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t ˌ n ɑː r iː ˈ iː n ə\n",
      "\t ˈ b ʊ r ɪ n\n",
      "\t ˈ g r ə g eɪ\n",
      "\t ˌ k ɪ s ˈ t ʌ s\n",
      "\t d ə ˈ p w ɑː g s t ɝ\n",
      "Epoch 234: train loss: 0.5281\tdev loss: 0.4518                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 4%, novel: 83%\n",
      "\t ˈ iː t ə ˌ f ɪ t\n",
      "\t ˈ k ʌ ŋ b ə l d\n",
      "\t ˈ b ɑː l t æ dʒ\n",
      "\t ə ˈ t ɑː m\n",
      "\t ˈ p l ɛ r\n",
      "Epoch 235: train loss: 0.5280\tdev loss: 0.4517                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ l æ g r uː ə t\n",
      "\t ˈ ɑː l v ɑː n\n",
      "\t h ɝ ˈ j eɪ ə\n",
      "\t ˌ j eɪ m ə n ˈ t oʊ v\n",
      "\t ˈ v ɑː s ɝ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236: train loss: 0.5280\tdev loss: 0.4517                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t ˈ d iː t\n",
      "\t ˈ r oʊ l z\n",
      "\t ˈ r iː n t ɝ\n",
      "\t ˌ d ɪ n ə f r iː ˈ l ɛ dʒ\n",
      "\t ɪ ˈ b r ɪ m ɪ n\n",
      "Epoch 237: train loss: 0.5280\tdev loss: 0.4516                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ d r ɔ t i\n",
      "\t ˈ æ ŋ k æ n\n",
      "\t ˌ ɪ n ˈ t ɛ k l ə k s\n",
      "\t ˈ f ɛ s\n",
      "\t ˈ dʒ ɔ r ə n\n",
      "Epoch 238: train loss: 0.5280\tdev loss: 0.4517                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ dʒ iː g\n",
      "\t ˈ s t aɪ s ɪ z\n",
      "\t ˈ m ɪ l ˌ f ɛ l t s\n",
      "\t ˈ g eɪ ʒ ə n\n",
      "\t ˌ k ɪ n ˈ t ɛ d\n",
      "Epoch 239: train loss: 0.5279\tdev loss: 0.4516                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 4%, novel: 84%\n",
      "\t s t ə ˈ k l aɪ\n",
      "\t ˈ r ɑː k\n",
      "\t ˈ r ɑː m z b ʊ r t\n",
      "\t b iː ˈ ɛ t oʊ\n",
      "\t d ə ˈ p ɑː ʒ\n",
      "Epoch 240: train loss: 0.5279\tdev loss: 0.4516                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˈ v æ n ə ˌ t j uː ə v m ɪ n z\n",
      "\t p r ɪ ˈ b ɝː g r ə n v iː n ɪ n\n",
      "\t p ɝ ˈ ɝː f s ɪ s\n",
      "\t ˈ m iː l ɪ n\n",
      "\t k ə ˈ n ɑː ə dʒ\n",
      "Epoch 241: train loss: 0.5280\tdev loss: 0.4517                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t p ə p ɪ ˈ f ɪ l\n",
      "\t ˈ b æ d b ɝ j\n",
      "\t ˌ aɪ ˈ d æ n ə\n",
      "\t ˈ s k ʌ p ɝ g ˌ n aɪ m ɪ ŋ\n",
      "\t ə m iː ˈ t eɪ r\n",
      "Epoch 242: train loss: 0.5279\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ l ɛ r ˌ f ɑː v\n",
      "\t ˈ s iː k s ɝ\n",
      "\t ˈ k r æ b\n",
      "\t ˈ j ɑː r ˌ d r æ ŋ\n",
      "\t iː ˈ z ɪ l ɪ k\n",
      "Epoch 243: train loss: 0.5279\tdev loss: 0.4516                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ v ɪ d ə l\n",
      "\t ˈ ɪ l t iː z\n",
      "\t r iː ˈ d ɛ k ɝ ə s\n",
      "\t ˈ k oʊ p s ɝ\n",
      "\t ˈ b æ n t\n",
      "Epoch 244: train loss: 0.5278\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t ˈ h ɔ d\n",
      "\t ˈ p r ɑː s t ɝ ˌ ɛ z\n",
      "\t d ə ˈ n oʊ l z\n",
      "\t ˈ b l æ n d\n",
      "\t ˈ b æ ˌ s n aɪ z\n",
      "Epoch 245: train loss: 0.5278\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ j ʊ r iː ə\n",
      "\t ˈ s n iː l z\n",
      "\t ˈ t ɑː r t ə n d\n",
      "\t ˌ s ɛ t ɛ l ˈ d ɑː p oʊ\n",
      "\t ˌ s ɛ l ɝ ˈ eɪ ʃ ə n ɪ s\n",
      "Epoch 246: train loss: 0.5278\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t k ɑː r iː ˈ ɛ n oʊ\n",
      "\t ˈ g ɑː r b ə l g ɝ\n",
      "\t ˈ m iː d ˌ b ɛ s t\n",
      "\t ˈ l ɝː ˌ oʊ\n",
      "\t ˈ n ɛ d ɝ ɪ n\n",
      "Epoch 247: train loss: 0.5277\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ r ɛ t ɝ\n",
      "\t ˈ r ɑː t\n",
      "\t ˈ v aɪ ˌ t ʊ d ˌ d l eɪ t\n",
      "\t ˈ r ɛ f ɝ t\n",
      "\t ˈ k eɪ ˌ g ɑː r v\n",
      "Epoch 248: train loss: 0.5277\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t g ə ˈ m ɛ ʃ ə n\n",
      "\t k aɪ ˈ t æ s k j ə l ɪ k\n",
      "\t ˌ t ɑː n aʊ t ˈ j uː d\n",
      "\t ˈ b æ l t ɝ d\n",
      "\t s ə ˈ p eɪ d oʊ\n",
      "Epoch 249: train loss: 0.5277\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 4%, novel: 85%\n",
      "\t ˈ b æ l k iː z\n",
      "\t ə ˌ b ɛ p l ɪ n m ə n ˈ p j uː n\n",
      "\t ˈ k ɑː v ɛ n oʊ\n",
      "\t ˈ g ɛ m ˌ k ɔ k\n",
      "\t ˈ oʊ l t ɝ\n",
      "Epoch 250: train loss: 0.5277\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t ˌ t oʊ l ə ˈ p æ t ɪ m\n",
      "\t ˈ p iː\n",
      "\t ˈ s uː h oʊ z\n",
      "\t ˌ t ɪ k ə n ˈ s t r ɪ ʃ ɪ l\n",
      "\t ˈ d ɪ l ɝ z ə n d\n",
      "Epoch 251: train loss: 0.5278\tdev loss: 0.4515                                                                                             \n",
      "\tGenerated: in train: 16%, assess: 5%, novel: 79%\n",
      "\t ˈ k r ɑː b ə ʃ\n",
      "\t ˌ ɛ t r ɪ ˈ l eɪ ʃ ə n\n",
      "\t ˈ s ɝː k l ə l\n",
      "\t ˈ p iː n ə\n",
      "\t ˈ ʃ ɑː v n ɪ k\n",
      "Epoch 252: train loss: 0.5276\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t iː n iː ˈ n iː n i\n",
      "\t ˈ w ɛ f ɪ z\n",
      "\t ˈ g ɛ k ɪ l d ɪ l\n",
      "\t ˈ θ aɪ l\n",
      "\t ˈ k ʌ l ɝ\n",
      "Epoch 253: train loss: 0.5276\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ ɛ r ə l\n",
      "\t ˌ ɛ n s ɪ ˈ v eɪ l i\n",
      "\t p ɔ d ˈ ɪ n t ə n d z\n",
      "\t ˈ s æ l aɪ dʒ\n",
      "\t ˈ k j uː d ɪ d\n",
      "Epoch 254: train loss: 0.5276\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t ə ˈ f iː k ˌ d oʊ m\n",
      "\t t r ə ˈ m ɛ r ə\n",
      "\t ˈ s t ɔ r w ə n\n",
      "\t ˈ g ɔ r p ɝ m ə n\n",
      "\t ˈ l uː z\n",
      "Epoch 255: train loss: 0.5277\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ t iː ˌ h uː t\n",
      "\t ˈ m ɪ n f i\n",
      "\t ˈ æ k\n",
      "\t ˈ g oʊ m ə\n",
      "\t ˈ g l oʊ t ɪ k\n",
      "Epoch 256: train loss: 0.5275\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˈ ɪ v ɪ d ˌ b æ k\n",
      "\t n ɪ ˈ s t uː r ə b iː l ə n t s\n",
      "\t ˈ f æ d z\n",
      "\t r iː ˈ d ɑː m ə b ə l\n",
      "\t ˈ æ s ə b r ə p ɝ\n",
      "Epoch 257: train loss: 0.5275\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t ˈ k ɑː r ʃ\n",
      "\t æ n ˈ b ɑː t\n",
      "\t t r ə s ɪ ˈ k æ l s t\n",
      "\t dʒ ˌ ɑː n iː ə n ˈ dʒ iː θ\n",
      "\t ˈ h æ tʃ i\n",
      "Epoch 258: train loss: 0.5275\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ f ɪ l d ə n\n",
      "\t ˈ d r ɛ dʒ i\n",
      "\t b ɝ m ˈ ɛ n k i\n",
      "\t d ˈ b ɪ r t i\n",
      "\t ˌ oʊ k ə ˈ g ɛ n d ɪ ʃ ə n\n",
      "Epoch 259: train loss: 0.5275\tdev loss: 0.4512                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t t r ɪ ˈ m ɛ b ə\n",
      "\t b ɪ ˈ l ɛ t iː ə s\n",
      "\t h ɔ l ˈ r ɛ t iː ə n\n",
      "\t ˈ t ɔ r t\n",
      "\t ˈ w iː m ə m\n",
      "Epoch 260: train loss: 0.5275\tdev loss: 0.4513                                                                                             \n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t ˈ s l æ g ə ˈ d æ k t ə d\n",
      "\t ˈ h aʊ r ˌ g oʊ z\n",
      "\t ˈ k r d uː w ɪ dʒ oʊ z\n",
      "\t v ɛ g ˈ l ə ʒ ə n z\n",
      "\t p ˈ m ɪ d ɪ n\n",
      "Epoch 261: train loss: 0.5275\tdev loss: 0.4512                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t ˌ d ɪ s ɪ ˈ g ɪ r iː z\n",
      "\t ˈ aɪ n f ɝ\n",
      "\t k ɑː r ˈ ɑː n oʊ\n",
      "\t ˈ d aʊ z ˌ m æ l z\n",
      "\t ˈ ʃ ʌ v\n",
      "Epoch 262: train loss: 0.5275\tdev loss: 0.4514                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t ˈ p ɛ s t ə s\n",
      "\t ˈ l oʊ ˌ ɑː l\n",
      "\t oʊ ˈ dʒ ɛ n d s ə n t\n",
      "\t v ɪ s ˈ f aɪ t s ə n\n",
      "\t ˈ g æ b\n",
      "Epoch 263: train loss: 0.5274\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t ˈ r ɪ tʃ i\n",
      "\t ˈ d ɔ r l d\n",
      "\t ˈ s ɛ m ə n ˌ f l æ n\n",
      "\t d ɪ s t ɑː ˈ v eɪ n iː ə\n",
      "\t s p ɝ ˈ oʊ ŋ\n",
      "Epoch 264: train loss: 0.5274\tdev loss: 0.4512                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 1%, novel: 80%\n",
      "\t ˈ ɔ ŋ\n",
      "\t ˈ f æ k s ɪ ŋ\n",
      "\t ˈ h oʊ l\n",
      "\t ˈ f ɑː r l eɪ\n",
      "\t ɛ k ˈ s l iː n oʊ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265: train loss: 0.5273\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t d ɪ ˈ g æ n p ə l ɝ\n",
      "\t ˈ g r ɪ b ɪ ʃ\n",
      "\t ˈ k æ n d ə l b ɝ g\n",
      "\t ˈ f r ɛ v ɝ\n",
      "\t ˈ h oʊ l d ɪ ˌ n ɛ r i\n",
      "Epoch 266: train loss: 0.5274\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ s k ʌ ŋ k ə l b ɝ g ɝ\n",
      "\t ˌ æ n ˈ d eɪ t s\n",
      "\t ˈ b ʌ n\n",
      "\t ˈ n ɛ ˌ t r æ s ɪ ŋ\n",
      "\t ˈ t ɑː f l i\n",
      "Epoch 267: train loss: 0.5274\tdev loss: 0.4512                                                                                             \n",
      "\tGenerated: in train: 3%, assess: 1%, novel: 96%\n",
      "\t r ɪ ˈ m ɛ r ə k ə n t s\n",
      "\t ˈ f r ɛ s\n",
      "\t ˈ ɛ ˌ m ɛ l eɪ\n",
      "\t ˈ k ɛ k s ə\n",
      "\t b iː ˈ ɑː v ə\n",
      "Epoch 268: train loss: 0.5273\tdev loss: 0.4512                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t ˈ k ɝː\n",
      "\t ˌ d oʊ ˈ k oʊ\n",
      "\t d ɪ ˈ s oʊ\n",
      "\t ˈ s p r ɪ ʃ ə n z\n",
      "\t ˈ b oʊ t ɝ\n",
      "Epoch 269: train loss: 0.5273\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t m ɑː s ə ˈ m æ l ɛ k s\n",
      "\t ˈ m æ m\n",
      "\t r ə ˈ p eɪ ʃ ɪ n\n",
      "\t ˈ h ɪ l k r iː n\n",
      "\t ˈ f j uː æ n dʒ\n",
      "Epoch 270: train loss: 0.5274\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t v ɑː ˈ n æ p t ə ˌ t eɪ t\n",
      "\t ˈ f ɪ n n ɝ\n",
      "\t ˈ p ɛ r z\n",
      "\t ˈ m æ s ə l ə n t s\n",
      "\t ˈ b l ʌ r i\n",
      "Epoch 271: train loss: 0.5273\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t k ˌ r æ z ˈ ɝː\n",
      "\t ə ˈ b aʊ ɝ z\n",
      "\t ˈ b ɝː ˌ eɪ t ɪ s n i\n",
      "\t ˈ w ɔ v ɪ l\n",
      "\t ˌ r aɪ d ɪ ˈ p ɪ r ɪ ŋ\n",
      "Epoch 272: train loss: 0.5272\tdev loss: 0.4511                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 0%, novel: 93%\n",
      "\t ə n ˈ s p iː s ə n t\n",
      "\t ˌ ɛ n ˈ k j uː t ɪ d\n",
      "\t ˈ s p oʊ ˌ g ɔ t\n",
      "\t ˈ ʃ ʊ n t oʊ\n",
      "\t ˈ r æ n d iː ə n\n",
      "Epoch 273: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 19%, assess: 3%, novel: 78%\n",
      "\t ˈ ɛ g ˌ d æ s\n",
      "\t ˈ s k ɝː n ə m z\n",
      "\t ˈ l æ n ɝ z\n",
      "\t ˈ l eɪ n ˌ k r ɛ s\n",
      "\t z ɝ ˈ eɪ t ɪ ŋ\n",
      "Epoch 274: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t ˈ r oʊ v ɪ k l ɔ r\n",
      "\t ˌ ɪ m ə ˈ d oʊ s ə n\n",
      "\t ˈ h iː t ɪ m iː æ k\n",
      "\t ˈ k ɑː s t ə l\n",
      "\t ˈ l iː ˌ k æ s\n",
      "Epoch 275: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ g eɪ\n",
      "\t ɑː d d ˈ p eɪ uː\n",
      "\t ˈ f ɛ r ˌ m ɔɪ n d\n",
      "\t ˈ r ʌ d i\n",
      "\t ˈ oʊ n i\n",
      "Epoch 276: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˈ g ɪ n ˌ ʃ ɛ r p\n",
      "\t ˈ t ɛ s t ə l z\n",
      "\t r iː ˈ d ɛ n d\n",
      "\t ˈ s eɪ ˌ h ɑː d\n",
      "\t t ə ˈ ɛ s k d\n",
      "Epoch 277: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 4%, novel: 83%\n",
      "\t ˈ l eɪ n ɝ\n",
      "\t ˈ n ɛ l ɪ ŋ\n",
      "\t ˈ ɛ l g ə n\n",
      "\t ˈ k ʌ l\n",
      "\t ˈ t ɔ ˌ m oʊ l d\n",
      "Epoch 278: train loss: 0.5271\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ s t j oʊ z ə s\n",
      "\t ˌ p ɪ n ˈ d ʌ p f ɝ\n",
      "\t ˌ m ɑː ˈ s æ n\n",
      "\t ˈ ɛ r ə ˌ n eɪ s\n",
      "\t ˌ p æ l t ə ˈ b aʊ t ə d\n",
      "Epoch 279: train loss: 0.5272\tdev loss: 0.4510                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 2%, novel: 92%\n",
      "\t ˈ h ʌ w ɑː l v\n",
      "\t h ɑː ˈ m ɑː p ə\n",
      "\t b r oʊ ˈ d æ n iː ə\n",
      "\t ˌ n ɛ s t ɝ ˈ ɛ t ɛ n z\n",
      "\t ˈ s ʌ z\n",
      "Epoch 280: train loss: 0.5270\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ n ɝː k ə l\n",
      "\t ˈ θ ɛ l m ə n s ɪ t\n",
      "\t ə ˈ l aɪ\n",
      "\t ˈ w ɛ f t\n",
      "\t ˈ dʒ ɛ n ɝ ˈ oʊ g ə m\n",
      "Epoch 281: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t ˈ p ɑː r d ɪ m ə n\n",
      "\t ˈ t ɔ r n\n",
      "\t ˈ s t æ b\n",
      "\t ˈ s ɛ l g n ɝ\n",
      "\t ˈ g ɑː p ɝ v ɪ ŋ\n",
      "Epoch 282: train loss: 0.5271\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t ˈ b l ɛ r ə k ɑː\n",
      "\t ˈ tʃ ɛ n\n",
      "\t ˈ d ʌ k ə l\n",
      "\t r ɪ k w iː ˈ n ɑː d ə\n",
      "\t ˈ p l eɪ d\n",
      "Epoch 283: train loss: 0.5271\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t k ə ˈ s ɛ t s\n",
      "\t ə s t ɪ ˈ t ɪ l f ɝ ˌ w eɪ t\n",
      "\t ˈ r ɪ l ə s ə n t s\n",
      "\t s ə n ˈ s p r aɪ s ə n ə t\n",
      "\t ˌ v ɛ n ɪ ˈ dʒ iː\n",
      "Epoch 284: train loss: 0.5270\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t ˈ v ɛ l ɪ l ə s\n",
      "\t ˈ r ʌ m p l ɝ eɪ t s\n",
      "\t ˈ h oʊ t ə n\n",
      "\t ˈ n j uː l i\n",
      "\t ˈ s ɛ s ɝ z\n",
      "Epoch 285: train loss: 0.5271\tdev loss: 0.4509                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t iː ˈ s t ɔ k ə\n",
      "\t ˈ h w ɔ\n",
      "\t s ə ˈ v ɑː n ɔ g ə ˌ t ɪ k l i\n",
      "\t p r eɪ ˈ t ɑː l ə d ɝ z\n",
      "\t ˈ h æ n k r oʊ l b ɝ g\n",
      "Epoch 286: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t l ɔ r ɑː ˈ g ɛ r s t\n",
      "\t r ɪ ˈ b iː s ə n\n",
      "\t ɝ ˈ ɪ k n ə n d\n",
      "\t ˈ s æ n ˌ b eɪ k ɝ\n",
      "\t ˈ t ɪ l ɝ z\n",
      "Epoch 287: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t n ə ˈ b aɪ f\n",
      "\t ˈ h aʊ n ˌ ɔ k\n",
      "\t ˈ p w ɪ r ˈ b aɪ n\n",
      "\t ɑː ˈ f ɑː l ə\n",
      "\t ˈ l ʌ g r ə tʃ iː uː\n",
      "Epoch 288: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t ˌ ɪ ʃ ɝ ˈ s ɛ n ʃ ə s ə n\n",
      "\t ˈ l ɛ k æ n d\n",
      "\t ˈ s k w aɪ z ə l\n",
      "\t v oʊ ˈ n æ n z ɝ\n",
      "\t ˈ k æ n ə z ɝ\n",
      "Epoch 289: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ h aɪ ˌ p r ɔ f\n",
      "\t ˈ h æ r n ɪ ŋ\n",
      "\t ˈ v uː k\n",
      "\t ˈ s aɪ ɝ ˌ b ɪ k\n",
      "\t ˈ h ɛ m s ɪ ŋ\n",
      "Epoch 290: train loss: 0.5269\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ w eɪ d ɝ\n",
      "\t ˈ t eɪ ʃ ɝ\n",
      "\t ˈ s ɑː d z\n",
      "\t ˈ k ɛ t ɝ z\n",
      "\t ˈ k j uː d i\n",
      "Epoch 291: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t ˈ s m æ l ə z\n",
      "\t ˈ n uː oʊ z\n",
      "\t ə z ˈ iː t\n",
      "\t ˈ b l æ dʒ ə n\n",
      "\t ɛ l ˈ k ɛ n t s\n",
      "Epoch 292: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t ˈ p oʊ ŋ\n",
      "\t ˈ p ɛ d\n",
      "\t ˈ v ɑː t ɝ iː ɪ n\n",
      "\t ˈ b ɑː p s\n",
      "\t ˈ l æ n w ɪ t\n",
      "Epoch 293: train loss: 0.5270\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t ˈ dʒ ə b ɪ k s\n",
      "\t ˈ l uː\n",
      "\t s p ə ˈ k ɔ l ɪ m\n",
      "\t ˈ h oʊ d\n",
      "\t ˈ n ɔ r b ɝ ˌ z ɔ d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294: train loss: 0.5269\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t ˈ h oʊ v ɝ ɪ m\n",
      "\t ˈ r ɪ n ɝ\n",
      "\t ˈ l ɔ r m ɪ ŋ l ɪ s t\n",
      "\t ˈ t r aɪ p ə n\n",
      "\t ˈ h w ɪ d ˌ m oʊ v p ɝ\n",
      "Epoch 295: train loss: 0.5268\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t ˈ w æ f ə l aɪ t ɝ\n",
      "\t ɑː r ˈ d oʊ z\n",
      "\t ˈ h eɪ t ə s\n",
      "\t ˈ θ l ə p ɝ ˌ g ɑː n\n",
      "\t ˈ θ r æ s t ɪ ŋ\n",
      "Epoch 296: train loss: 0.5268\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t ˈ h iː p ə dʒ z\n",
      "\t ˈ r eɪ s ə m\n",
      "\t ˈ dʒ ʌ n h ɑː r t i\n",
      "\t ˈ h ɛ m ɝ d\n",
      "\t ˈ l ɪ t ə b i\n",
      "Epoch 297: train loss: 0.5269\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t ˈ d ʌ b ˌ m eɪ t ə m z\n",
      "\t ˈ r ɑː m p θ\n",
      "\t ˈ f w oʊ l tʃ ɝ ə d n ɝ\n",
      "\t ˈ g l ɔ m ɪ ˌ l ə b\n",
      "\t ˈ ɛ s ˌ m ɑː r d ɪ k\n",
      "Epoch 298: train loss: 0.5269\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t ˈ iː t ə n z\n",
      "\t ˈ dʒ eɪ ˌ b ɔɪ n\n",
      "\t ˈ b ɪ h ɪ d z\n",
      "\t ˈ b r aɪ d\n",
      "\t ˈ p r æ l\n",
      "Epoch 299: train loss: 0.5268\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t ˈ t ɛ n æ ŋ k t\n",
      "\t ˈ g r uː m ə\n",
      "\t ˈ d ɔ r s ɝ\n",
      "\t ʒ ɑː l iː ˈ t aʊ\n",
      "\t ˈ g ɔ r m ə n s\n",
      "Epoch 300: train loss: 0.5268\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t ˌ n ɪ r ɑː ˈ n oʊ t iː oʊ\n",
      "\t d ɪ ˈ m ɪ l ə n s ə s t\n",
      "\t ˈ s t ɪ n s t ə s\n",
      "\t r iː ˈ r ɛ ˌ t iː ə\n",
      "\t iː ˈ f ɔɪ ə l\n",
      "Epoch 301: train loss: 0.5268\tdev loss: 0.4507                                                                                             \n",
      "\tGenerated: in train: 6%, assess: 3%, novel: 91%\n",
      "\t ˈ k l ʌ n b ɪ ʃ l i\n",
      "\t ˈ eɪ θ ˌ f ɔ r v\n",
      "\t ˈ aɪ z d\n",
      "\t ˈ w aɪ r k\n",
      "\t ˈ r eɪ ʃ ə n\n",
      "Epoch 302: train loss: 0.5269\tdev loss: 0.4508                                                                                             \n",
      "\tGenerated: in train: 9%, assess: 4%, novel: 87%\n",
      "\t ˈ l ɔ s b ə b l i\n",
      "\t ˈ s aʊ\n",
      "\t ˈ s æ n d f i\n",
      "\t ˌ r æ k ə n ˈ h j uː ˌ b oʊ l d\n",
      "\t ˈ m ɑː tʃ z\n",
      "CPU times: user 39min 7s, sys: 1min 45s, total: 40min 52s\n",
      "Wall time: 38min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping because of no decrease in 3 epochs.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_parameters = ModelParams(rnn_type='gru', num_layers=1, max_epochs=1000, early_stopping_rounds=3,\n",
    "                              embedding_dimension=20, hidden_dimension=20)\n",
    "model2 = LanguageModel(vocab, model_parameters, device_name='cuda')\n",
    "\n",
    "train_losses, dev_losses = model2.fit(\n",
    "    train_pronunciations.pronunciation.values.tolist(),\n",
    "    dev_pronunciations.pronunciation.values.tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expands</th>\n",
       "      <td>(ɪ, k, ˈ, s, p, æ, n, d, z)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rejecting</th>\n",
       "      <td>(r, iː, ˈ, dʒ, ɛ, k, t, ɪ, ŋ)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilmark</th>\n",
       "      <td>(ˈ, tʃ, ɪ, l, ˌ, m, ɑː, r, k)</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dworsky</th>\n",
       "      <td>(ˈ, d, w, ɝː, s, k, i)</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handyman</th>\n",
       "      <td>(ˈ, h, æ, n, d, iː, ˌ, m, æ, n)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                                      \n",
       "expands        (ɪ, k, ˈ, s, p, æ, n, d, z)             8              2   \n",
       "rejecting    (r, iː, ˈ, dʒ, ɛ, k, t, ɪ, ŋ)             8              2   \n",
       "chilmark     (ˈ, tʃ, ɪ, l, ˌ, m, ɑː, r, k)             7              1   \n",
       "dworsky             (ˈ, d, w, ɝː, s, k, i)             6              1   \n",
       "handyman   (ˈ, h, æ, n, d, iː, ˌ, m, æ, n)             8              2   \n",
       "\n",
       "           num_primary_stressed_syllables  \n",
       "word                                       \n",
       "expands                                 1  \n",
       "rejecting                               1  \n",
       "chilmark                                1  \n",
       "dworsky                                 1  \n",
       "handyman                                1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hammon</th>\n",
       "      <td>(ˈ, h, æ, m, ə, n)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podany</th>\n",
       "      <td>(p, ə, ˈ, d, ɔ, n, i)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belliveau</th>\n",
       "      <td>(ˈ, b, ɛ, l, ɪ, ˌ, v, oʊ)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheese</th>\n",
       "      <td>(ˈ, tʃ, iː, z)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relented</th>\n",
       "      <td>(r, iː, ˈ, l, ɛ, n, ə, d)</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                                \n",
       "hammon            (ˈ, h, æ, m, ə, n)             5              2   \n",
       "podany         (p, ə, ˈ, d, ɔ, n, i)             6              3   \n",
       "belliveau  (ˈ, b, ɛ, l, ɪ, ˌ, v, oʊ)             6              3   \n",
       "cheese                (ˈ, tʃ, iː, z)             3              0   \n",
       "relented   (r, iː, ˈ, l, ɛ, n, ə, d)             7              2   \n",
       "\n",
       "           num_primary_stressed_syllables  \n",
       "word                                       \n",
       "hammon                                  1  \n",
       "podany                                  1  \n",
       "belliveau                               1  \n",
       "cheese                                  1  \n",
       "relented                                1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pronunciations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98407, 24914)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pronunciations), len(dev_pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chromosome',\n",
       " 'hors',\n",
       " 'rapids',\n",
       " 'keogh',\n",
       " 'erasers',\n",
       " 'keanu',\n",
       " 'gadhafi',\n",
       " 'abuse',\n",
       " 'aaronson',\n",
       " 'fogarty',\n",
       " 'ringler',\n",
       " 'isolde',\n",
       " 'pocahontas',\n",
       " 'riches',\n",
       " 'economy',\n",
       " 'dyneer',\n",
       " 'battlement',\n",
       " 'messenger',\n",
       " 'kesling',\n",
       " 'voyaged',\n",
       " 'seasonally',\n",
       " 'overland',\n",
       " 'molded',\n",
       " 'commingling',\n",
       " 'barentine',\n",
       " 'atoll',\n",
       " 'buchi',\n",
       " 'internationale',\n",
       " 'accompaniments',\n",
       " 'untoward',\n",
       " 'directory',\n",
       " 'intercept',\n",
       " 'janet',\n",
       " 'affiliates',\n",
       " 'blackening',\n",
       " 'pena',\n",
       " 'kjellberg',\n",
       " 'feathery',\n",
       " 'cottage',\n",
       " 'interceptor',\n",
       " 'ecologically',\n",
       " 'increases',\n",
       " 'hertz',\n",
       " 'kokate',\n",
       " 'mondrian',\n",
       " 'transylvania',\n",
       " 'riyadh',\n",
       " 'whither',\n",
       " 'tischler',\n",
       " 'forearms',\n",
       " 'golan',\n",
       " 'fridays',\n",
       " 'miasma',\n",
       " 'comprises',\n",
       " 'canister',\n",
       " 'estimators',\n",
       " 'corabelle',\n",
       " 'michel',\n",
       " 'gallstones',\n",
       " 'cocksucker',\n",
       " 'scheufler',\n",
       " 'tended',\n",
       " 'whaler',\n",
       " 'outlasts',\n",
       " 'bass',\n",
       " 'abductor',\n",
       " 'whippoorwills',\n",
       " 'retreated',\n",
       " 'saddam',\n",
       " 'zeigler',\n",
       " 'duets',\n",
       " 'hovering',\n",
       " 'wimbush',\n",
       " 'respective',\n",
       " 'bandages',\n",
       " 'towering',\n",
       " 'furlett',\n",
       " 'anticipations',\n",
       " 'isadore',\n",
       " 'unreliable',\n",
       " 'posavina',\n",
       " 'edges',\n",
       " 'aeromar',\n",
       " 'templers',\n",
       " 'causes',\n",
       " 'cosic',\n",
       " 'estimates',\n",
       " 'abts',\n",
       " 'squirted',\n",
       " 'abboud',\n",
       " 'josephina',\n",
       " 'promotional',\n",
       " 'stretches',\n",
       " 'commemorative',\n",
       " 'nygren',\n",
       " 'legitimize',\n",
       " 'unfortunates',\n",
       " 'object',\n",
       " 'rasmin',\n",
       " 'incentives',\n",
       " 'emirate',\n",
       " 'desecration',\n",
       " 'upgrading',\n",
       " 'rejected',\n",
       " 'err',\n",
       " 'moderates',\n",
       " 'bestselling',\n",
       " 'greenhouses',\n",
       " 'gorges',\n",
       " 'yielded',\n",
       " 'hirshhorn',\n",
       " 'wheelwriter',\n",
       " 'eighteen',\n",
       " 'wheezes',\n",
       " 'pierrelouis',\n",
       " 'poses',\n",
       " 'expansionist',\n",
       " 'lambaste',\n",
       " 'obediently',\n",
       " 'mendez',\n",
       " 'sponsler',\n",
       " 'fortunato',\n",
       " 'stuart',\n",
       " 'fiance',\n",
       " 'jewellers',\n",
       " 'evacuations',\n",
       " 'melbourne',\n",
       " 'openness',\n",
       " 'entity',\n",
       " 'emotive',\n",
       " 'invited',\n",
       " 'acts',\n",
       " 'hughart',\n",
       " 'encrypt',\n",
       " 'lengthening',\n",
       " 'dresses',\n",
       " 'groucho',\n",
       " 'watergate',\n",
       " 'outta',\n",
       " 'ws',\n",
       " 'machete',\n",
       " 'bustling',\n",
       " 'prevailed',\n",
       " 'afterthought',\n",
       " 'whistle',\n",
       " 'kjar',\n",
       " 'changes',\n",
       " 'christians',\n",
       " 'predicted',\n",
       " 'pagenkopf',\n",
       " 'sweetening',\n",
       " 'baba',\n",
       " 'ornstein',\n",
       " 'buffeting',\n",
       " 'mezzaluna',\n",
       " 'strandlines',\n",
       " 'generalizing',\n",
       " 'kamin',\n",
       " 'abkhazians',\n",
       " 'temperamentally',\n",
       " 'nabi',\n",
       " 'prevailing',\n",
       " 'bridgette',\n",
       " 'enabler',\n",
       " 'fastener',\n",
       " 'altschuler',\n",
       " 'sketches',\n",
       " 'humanity',\n",
       " 'resigned',\n",
       " 'leisure',\n",
       " 'associations',\n",
       " 'receipts',\n",
       " 'cooperation',\n",
       " 'gabler',\n",
       " 'candid',\n",
       " 'whisler',\n",
       " 'internationally',\n",
       " 'altmeyer',\n",
       " 'doctrine',\n",
       " 'smrekar',\n",
       " 'narrow',\n",
       " 'madewell',\n",
       " 'rwanda',\n",
       " 'earmarks',\n",
       " 'basses',\n",
       " 'keplinger',\n",
       " 'hundred',\n",
       " 'bouygues',\n",
       " 'whimsy',\n",
       " 'focuses',\n",
       " 'fortunately',\n",
       " 'los',\n",
       " 'beauregard',\n",
       " 'weil',\n",
       " 'reaches',\n",
       " 'herbicide',\n",
       " 'uprising',\n",
       " 'firings',\n",
       " 'julian',\n",
       " 'dioceses',\n",
       " 'datacard',\n",
       " 'mistrusts',\n",
       " 'mitterand',\n",
       " 'cleavage',\n",
       " 'preferences',\n",
       " 'kabler',\n",
       " 'correlate',\n",
       " 'gettinger',\n",
       " 'favorite',\n",
       " 'koch',\n",
       " 'management',\n",
       " 'effingham',\n",
       " 'evangelize',\n",
       " 'protract',\n",
       " 'kamler',\n",
       " 'vietcong',\n",
       " 'remittances',\n",
       " 'preserves',\n",
       " 'retard',\n",
       " 'buckler',\n",
       " 'padded',\n",
       " 'returning',\n",
       " 'barrier',\n",
       " 'montevideo',\n",
       " 'danjus',\n",
       " 'gatwick',\n",
       " 'droessler',\n",
       " 'merits',\n",
       " 'participated',\n",
       " 'depresses',\n",
       " 'colorado',\n",
       " 'metrodome',\n",
       " 'rejecting',\n",
       " 'barry',\n",
       " 'wonderfully',\n",
       " 'refinanced',\n",
       " 'reichling',\n",
       " 'temperaments',\n",
       " 'sightseer',\n",
       " 'receiving',\n",
       " 'nano',\n",
       " 'ratchet',\n",
       " 'militia',\n",
       " 'climate',\n",
       " 'emeralds',\n",
       " 'yogiism',\n",
       " 'nedved',\n",
       " 'liposuction',\n",
       " 'effected',\n",
       " 'relies',\n",
       " 'hoechst',\n",
       " 'imports',\n",
       " 'pianos',\n",
       " 'lambastes',\n",
       " 'successes',\n",
       " 'appointed',\n",
       " 'associates',\n",
       " 'nirvana',\n",
       " 'bodeguita',\n",
       " 'haberson',\n",
       " 'earhart',\n",
       " 'druggists',\n",
       " 'cruelties',\n",
       " 'elsevier',\n",
       " 'mounties',\n",
       " 'roosevelts',\n",
       " 'dise',\n",
       " 'dorazio',\n",
       " 'marjory',\n",
       " 'amenable',\n",
       " 'forearm',\n",
       " 'pestillo',\n",
       " 'lifted',\n",
       " 'graduated',\n",
       " 'preferred',\n",
       " 'besler',\n",
       " 'businesses',\n",
       " 'herbivorous',\n",
       " 'intransigence',\n",
       " 'wickets',\n",
       " 'indigest',\n",
       " 'felicite',\n",
       " 'whales',\n",
       " 'instrumentals',\n",
       " 'selinas',\n",
       " 'yanomami',\n",
       " 'cautioned',\n",
       " 'clothes',\n",
       " 'whaling',\n",
       " 'astore',\n",
       " 'moscow',\n",
       " 'ole',\n",
       " 'quintile',\n",
       " 'leveraged',\n",
       " 'plodded',\n",
       " 'kaczynski',\n",
       " 'thomasine',\n",
       " 'causing',\n",
       " 'semilegendary',\n",
       " 'transcendental',\n",
       " 'recess',\n",
       " 'torment',\n",
       " 'wagnerian',\n",
       " 'continually',\n",
       " 'batiks',\n",
       " 'mcilvaine',\n",
       " 'tamil',\n",
       " 'versatile',\n",
       " 'spotted',\n",
       " 'firearm',\n",
       " 'prompted',\n",
       " 'decomposition',\n",
       " 'estimated',\n",
       " 'oriental',\n",
       " 'hafts',\n",
       " 'ireton',\n",
       " 'cholesterol',\n",
       " 'whinery',\n",
       " 'budapest',\n",
       " 'datacomm',\n",
       " 'documentary',\n",
       " 'ishmael',\n",
       " 'peaches',\n",
       " 'individualize',\n",
       " 'erlichman',\n",
       " 'inadvertently',\n",
       " 'moreno',\n",
       " 'wilkinson',\n",
       " 'mascarena',\n",
       " 'outland',\n",
       " 'bornstein',\n",
       " 'translates',\n",
       " 'physically',\n",
       " 'tae',\n",
       " 'whit',\n",
       " 'angelinos',\n",
       " 'pecan',\n",
       " 'ngai',\n",
       " 'egon',\n",
       " 'regimes',\n",
       " 'endured',\n",
       " 'averil',\n",
       " 'blushes',\n",
       " 'deferential',\n",
       " 'pepperidge',\n",
       " 'giard',\n",
       " 'dillard',\n",
       " 'lubavitchers',\n",
       " 'percentage',\n",
       " 'was',\n",
       " 'templer',\n",
       " 'darr',\n",
       " 'excess',\n",
       " 'carriers',\n",
       " 'restraints',\n",
       " 'udverhye',\n",
       " 'federalize',\n",
       " 'mon',\n",
       " 'whirl',\n",
       " 'humanities',\n",
       " 'hosea',\n",
       " 'hoffler',\n",
       " 'purim',\n",
       " 'commensurately',\n",
       " 'contest',\n",
       " 'dubrovsky',\n",
       " 'bridges',\n",
       " 'everywhere',\n",
       " 'surrealisms',\n",
       " 'guzzlers',\n",
       " 'excesses',\n",
       " 'vickery',\n",
       " 'michaeline',\n",
       " 'patronized',\n",
       " 'whitledge',\n",
       " 'rimpochet',\n",
       " 'shriveling',\n",
       " 'chideya',\n",
       " 'overwhelm',\n",
       " 'rychlik',\n",
       " 'boztepe',\n",
       " 'eisenstein',\n",
       " 'unrelated',\n",
       " 'barrack',\n",
       " 'ueno',\n",
       " 'guzzling',\n",
       " 'internationalized',\n",
       " 'cedras',\n",
       " 'backsaws',\n",
       " 'moorco',\n",
       " 'saudi',\n",
       " 'isu',\n",
       " 'obscenely',\n",
       " 'uninitiated',\n",
       " 'encircling',\n",
       " 'projectile',\n",
       " 'philandering',\n",
       " 'italia',\n",
       " 'juveniles',\n",
       " 'puerto',\n",
       " 'fantasize',\n",
       " 'mcgough',\n",
       " 'benetton',\n",
       " 'chivas',\n",
       " 'delacroix',\n",
       " 'zoloft',\n",
       " 'deeded',\n",
       " 'dostoevsky',\n",
       " 'broccoli',\n",
       " 'byelorussia',\n",
       " 'accepting',\n",
       " 'seigel',\n",
       " 'monroeville',\n",
       " 'taekwondo',\n",
       " 'dumas',\n",
       " 'matsushita',\n",
       " 'wharff',\n",
       " 'nedlloyd',\n",
       " 'appalachians',\n",
       " 'ecologists',\n",
       " 'exploration',\n",
       " 'healthcorp',\n",
       " 'porsche',\n",
       " 'yingst',\n",
       " 'wheeldon',\n",
       " 'baumgardner',\n",
       " 'vase',\n",
       " 'hyperbaric',\n",
       " 'withdrawals',\n",
       " 'injected',\n",
       " 'belgacom',\n",
       " 'softer',\n",
       " 'medically',\n",
       " 'republican',\n",
       " 'mulvihill',\n",
       " 'sani',\n",
       " 'harrisburg',\n",
       " 'superintendant',\n",
       " 'precinct',\n",
       " 'transform',\n",
       " 'laces',\n",
       " 'tsui',\n",
       " 'sympathetically',\n",
       " 'recounts',\n",
       " 'neural',\n",
       " 'advertisement',\n",
       " 'yemeni',\n",
       " 'rampaged',\n",
       " 'intellectualism',\n",
       " 'consisted',\n",
       " 'report',\n",
       " 'levy',\n",
       " 'greitz',\n",
       " 'remarkably',\n",
       " 'ration',\n",
       " 'animate',\n",
       " 'enactments',\n",
       " 'conditionally',\n",
       " 'lengths',\n",
       " 'kwangju',\n",
       " 'dove',\n",
       " 'interbrew',\n",
       " 'wheeler',\n",
       " 'charities',\n",
       " 'greenstein',\n",
       " 'afterthoughts',\n",
       " 'dethroned',\n",
       " 'heseltine',\n",
       " 'rebuked',\n",
       " 'sebastianis',\n",
       " 'fourteenth',\n",
       " 'nanos',\n",
       " 'slepian',\n",
       " 'conflicts',\n",
       " 'liang',\n",
       " 'tissue',\n",
       " 'raman',\n",
       " 'mentality',\n",
       " 'fuselage',\n",
       " 'ossetians',\n",
       " 'medina',\n",
       " 'tsingtao',\n",
       " 'compress',\n",
       " 'resented',\n",
       " 'keisling',\n",
       " 'yesterdays',\n",
       " 'davao',\n",
       " 'absorption',\n",
       " 'separate',\n",
       " 'ninos',\n",
       " 'innovator',\n",
       " 'dougens',\n",
       " 'hickory',\n",
       " 'interacts',\n",
       " 'chinooks',\n",
       " 'hunted',\n",
       " 'emirates',\n",
       " 'enters',\n",
       " 'flooded',\n",
       " 'ana',\n",
       " 'wires',\n",
       " 'nationalizing',\n",
       " 'weild',\n",
       " 'allying',\n",
       " 'receives',\n",
       " 'ane',\n",
       " 'ayyad',\n",
       " 'bowater',\n",
       " 'vasectomy',\n",
       " 'alternate',\n",
       " 'partially',\n",
       " 'salzhauer',\n",
       " 'disparate',\n",
       " 'sutherlin',\n",
       " 'ofarrell',\n",
       " 'iceskate',\n",
       " 'whisenhunt',\n",
       " 'whiteley',\n",
       " 'grandkids',\n",
       " 'environmentalists',\n",
       " 'salient',\n",
       " 'cowen',\n",
       " 'ib',\n",
       " 'gases',\n",
       " 'fetishist',\n",
       " 'hulett',\n",
       " 'plazas',\n",
       " 'swans',\n",
       " 'chamorro',\n",
       " 'flaccid',\n",
       " 'macpherson',\n",
       " 'juices',\n",
       " 'outler',\n",
       " 'reasonableness',\n",
       " 'adhesive',\n",
       " 'kassebaum',\n",
       " 'divergence',\n",
       " 'lowndes',\n",
       " 'concerts',\n",
       " 'semicircular',\n",
       " 'salzberg',\n",
       " 'whiddon',\n",
       " 'muckleroy',\n",
       " 'aisles',\n",
       " 'revolted',\n",
       " 'whiplashes',\n",
       " 'fall',\n",
       " 'procession',\n",
       " 'sours',\n",
       " 'mozambique',\n",
       " 'automobile',\n",
       " 'granted',\n",
       " 'hamelin',\n",
       " 'formulated',\n",
       " 'donoghue',\n",
       " 'garagiola',\n",
       " 'generally',\n",
       " 'stephens',\n",
       " 'arbitron',\n",
       " 'earphone',\n",
       " 'vojta',\n",
       " 'heterogeneity',\n",
       " 'corpses',\n",
       " 'his',\n",
       " 'unum',\n",
       " 'lewinsky',\n",
       " 'economic',\n",
       " 'joachim',\n",
       " 'kowtow',\n",
       " 'predictors',\n",
       " 'ritenour',\n",
       " 'fiato',\n",
       " 'pathetically',\n",
       " 'tottenham',\n",
       " 'hughston',\n",
       " 'knin',\n",
       " 'whittinghill',\n",
       " 'lengthened',\n",
       " 'krakow',\n",
       " 'cooperate',\n",
       " 'disputed',\n",
       " 'corp',\n",
       " 'antifraud',\n",
       " 'mcentee',\n",
       " 'hygienist',\n",
       " 'cerska',\n",
       " 'datum',\n",
       " 'findling',\n",
       " 'laos',\n",
       " 'wor',\n",
       " 'kotler',\n",
       " 'corridor',\n",
       " 'whistles',\n",
       " 'eleven',\n",
       " 'divest',\n",
       " 'maladich',\n",
       " 'directories',\n",
       " 'appointees',\n",
       " 'dexterity',\n",
       " 'tseng',\n",
       " 'rarity',\n",
       " 'gagne',\n",
       " 'kisler',\n",
       " 'hohenstein',\n",
       " 'whitbread',\n",
       " 'sentiments',\n",
       " 'resentment',\n",
       " 'glorification',\n",
       " 'pharoah',\n",
       " 'whats',\n",
       " 'kogler',\n",
       " 'erected',\n",
       " 'halevi',\n",
       " 'hugo',\n",
       " 'collaborative',\n",
       " 'willemsen',\n",
       " 'primakov',\n",
       " 'wesat',\n",
       " 'rototilling',\n",
       " 'clouthier',\n",
       " 'semitrailer',\n",
       " 'doiron',\n",
       " 'jacket',\n",
       " 'philips',\n",
       " 'archipelago',\n",
       " 'mation',\n",
       " 'capri',\n",
       " 'meir',\n",
       " 'langley',\n",
       " 'yasir',\n",
       " 'plentiful',\n",
       " 'pragmatically',\n",
       " 'reykjavik',\n",
       " 'conferences',\n",
       " 'systran',\n",
       " 'outtakes',\n",
       " 'gamsakhurdia',\n",
       " 'keough',\n",
       " 'grumblings',\n",
       " 'recuperating',\n",
       " 'innovation',\n",
       " 'reinvestment',\n",
       " 'whiff',\n",
       " 'goodyear',\n",
       " 'iras',\n",
       " 'milan',\n",
       " 'ecology',\n",
       " 'pedophile',\n",
       " 'claudina',\n",
       " 'interchangeably',\n",
       " 'lima',\n",
       " 'entourages',\n",
       " 'gauguin',\n",
       " 'traces',\n",
       " 'lockneys',\n",
       " 'emerald',\n",
       " 'protuberance',\n",
       " 'yours',\n",
       " 'intermediaries',\n",
       " 'bolivia',\n",
       " 'busler',\n",
       " 'torme',\n",
       " 'beebower',\n",
       " 'costs',\n",
       " 'kept',\n",
       " 'eternal',\n",
       " 'corridors',\n",
       " 'millstein',\n",
       " 'liabilities',\n",
       " 'coliform',\n",
       " 'kunstler',\n",
       " 'hated',\n",
       " 'tear',\n",
       " 'nesler',\n",
       " 'kinds',\n",
       " 'friday',\n",
       " 'haile',\n",
       " 'the',\n",
       " 'ejup',\n",
       " 'converses',\n",
       " 'exits',\n",
       " 'presbyterians',\n",
       " 'rambling',\n",
       " 'parte',\n",
       " 'ijaz',\n",
       " 'recovered',\n",
       " 'toronto',\n",
       " 'enchanted',\n",
       " 'dissections',\n",
       " 'predicating',\n",
       " 'fluid',\n",
       " 'buzze',\n",
       " 'forgotten',\n",
       " 'stupid',\n",
       " 'gettler',\n",
       " 'kirchberg',\n",
       " 'evolved',\n",
       " 'cluj',\n",
       " 'existence',\n",
       " 'refusing',\n",
       " 'wo',\n",
       " 'weisenberg',\n",
       " 'am',\n",
       " 'coverages',\n",
       " 'rebutting',\n",
       " 'calculated',\n",
       " 'envoy',\n",
       " 'bannister',\n",
       " 'laparoscopic',\n",
       " 'pajamas',\n",
       " 'sabir',\n",
       " 'alcatraz',\n",
       " 'obesity',\n",
       " 'pogroms',\n",
       " 'conduct',\n",
       " 'chancellor',\n",
       " 'sfernice',\n",
       " 'anastasio',\n",
       " 'kang',\n",
       " 'reading',\n",
       " 'herbivore',\n",
       " 'mclawhorn',\n",
       " 'alderidge',\n",
       " 'datsun',\n",
       " 'clinically',\n",
       " 'dreyfus',\n",
       " 'decrease',\n",
       " 'sentiment',\n",
       " 'yogiisms',\n",
       " 'cama',\n",
       " 'drobkov',\n",
       " 'ophthalmologists',\n",
       " 'deliberate',\n",
       " 'whiting',\n",
       " 'mitsui',\n",
       " 'treated',\n",
       " 'gengenbach',\n",
       " 'podhoretz',\n",
       " 'luxottica',\n",
       " 'morehart',\n",
       " 'ayer',\n",
       " 'acetic',\n",
       " 'federally',\n",
       " 'pitted',\n",
       " 'forbidden',\n",
       " 'evolution',\n",
       " 'pigeon',\n",
       " 'reckoning',\n",
       " 'glasgow',\n",
       " 'simonton',\n",
       " 'aberle',\n",
       " 'minority',\n",
       " 'painters',\n",
       " 'azidothymidine',\n",
       " 'generalized',\n",
       " 'desert',\n",
       " 'mikhail',\n",
       " 'whitney',\n",
       " 'remodeling',\n",
       " 'nationalize',\n",
       " 'monumentally',\n",
       " 'resorted',\n",
       " 'barrel',\n",
       " 'minister',\n",
       " 'datametrics',\n",
       " 'adolescence',\n",
       " 'elementary',\n",
       " 'vitaly',\n",
       " 'predate',\n",
       " 'divulge',\n",
       " 'frequenting',\n",
       " 'brittania',\n",
       " 'focussed',\n",
       " 'costly',\n",
       " 'hughson',\n",
       " 'sequences',\n",
       " 'ailes',\n",
       " 'pall',\n",
       " 'ehrenreich',\n",
       " 'whitesell',\n",
       " 'crumbling',\n",
       " 'prestigious',\n",
       " 'tietmeyer',\n",
       " 'mynatt',\n",
       " 'abzug',\n",
       " 'sriram',\n",
       " 'tinkler',\n",
       " 'began',\n",
       " 'psalm',\n",
       " 'miotke',\n",
       " 'lyphomed',\n",
       " 'evaluations',\n",
       " 'whites',\n",
       " 'financier',\n",
       " 'preceded',\n",
       " 'elizabeth',\n",
       " 'evelyn',\n",
       " 'interactivity',\n",
       " 'marchioness',\n",
       " 'frenzel',\n",
       " 'gerasimov',\n",
       " 'balm',\n",
       " 'lecithin',\n",
       " 'somebody',\n",
       " 'notre',\n",
       " 'actually',\n",
       " 'finance',\n",
       " 'presumption',\n",
       " 'embrace',\n",
       " 'shimbun',\n",
       " 'approximates',\n",
       " 'during',\n",
       " 'tsurumi',\n",
       " 'earpieces',\n",
       " 'boarded',\n",
       " 'retaliate',\n",
       " 'churchill',\n",
       " 'interim',\n",
       " 'promotion',\n",
       " 'dubilier',\n",
       " 'botha',\n",
       " 'whiteness',\n",
       " 'heckuva',\n",
       " 'fogler',\n",
       " 'receiver',\n",
       " 'whittenburg',\n",
       " 'foret',\n",
       " 'idling',\n",
       " 'reappointed',\n",
       " 'carries',\n",
       " 'directorship',\n",
       " 'warriors',\n",
       " 'stangeland',\n",
       " 'aigner',\n",
       " 'retiring',\n",
       " 'inches',\n",
       " 'mammalian',\n",
       " 'whitener',\n",
       " 'grindlay',\n",
       " 'introductions',\n",
       " 'trying',\n",
       " 'deposited',\n",
       " 'whiner',\n",
       " 'dush',\n",
       " 'topeka',\n",
       " 'mcabee',\n",
       " 'hackler',\n",
       " 'communities',\n",
       " 'ounces',\n",
       " 'miniseries',\n",
       " 'directionless',\n",
       " 'aylwin',\n",
       " 'debut',\n",
       " 'skulls',\n",
       " 'gamete',\n",
       " 'digital',\n",
       " 'duopoly',\n",
       " 'chesler',\n",
       " 'lubricants',\n",
       " 'nice',\n",
       " 'kinetic',\n",
       " 'reliable',\n",
       " 'protest',\n",
       " 'bestsellers',\n",
       " 'often',\n",
       " 'nestle',\n",
       " 'presby',\n",
       " 'mcilvain',\n",
       " 'arctic',\n",
       " 'mysteriously',\n",
       " 'disinvestment',\n",
       " 'troubling',\n",
       " 'iraqi',\n",
       " 'ramseys',\n",
       " 'evangelism',\n",
       " 'preventable',\n",
       " 'multilevel',\n",
       " 'reverted',\n",
       " 'rossler',\n",
       " 'presses',\n",
       " 'giscard',\n",
       " 'decor',\n",
       " 'johanning',\n",
       " 'reports',\n",
       " 'facilities',\n",
       " 'velobind',\n",
       " 'evoke',\n",
       " 'introducing',\n",
       " 'paoli',\n",
       " 'toweling',\n",
       " 'gobbler',\n",
       " 'promptly',\n",
       " 'entertainment',\n",
       " 'planted',\n",
       " 'morays',\n",
       " 'predicament',\n",
       " 'patronize',\n",
       " 'productive',\n",
       " 'translation',\n",
       " 'simulcast',\n",
       " 'oregon',\n",
       " 'cxc',\n",
       " 'bahraini',\n",
       " 'baronet',\n",
       " 'whitting',\n",
       " 'eclipsing',\n",
       " 'behemoth',\n",
       " 'whiteaker',\n",
       " 'sundays',\n",
       " 'surrebuttal',\n",
       " 'crafts',\n",
       " 'vacationing',\n",
       " 'angeloff',\n",
       " 'concord',\n",
       " 'became',\n",
       " 'mccambridge',\n",
       " 'duesler',\n",
       " 'vantage',\n",
       " 'enmities',\n",
       " 'vukovich',\n",
       " 'koffler',\n",
       " 'semiannual',\n",
       " 'naturalized',\n",
       " 'buehrer',\n",
       " 'cotler',\n",
       " 'birchler',\n",
       " 'fleuri',\n",
       " 'hustlers',\n",
       " 'governmental',\n",
       " 'oblak',\n",
       " 'akins',\n",
       " 'mileage',\n",
       " 'zumstein',\n",
       " 'doberstein',\n",
       " 'shatz',\n",
       " 'recruit',\n",
       " 'draconian',\n",
       " 'coverage',\n",
       " 'bonobo',\n",
       " 'edition',\n",
       " 'govs',\n",
       " 'fernand',\n",
       " 'forsythias',\n",
       " 'procedurally',\n",
       " 'gayshill',\n",
       " 'carried',\n",
       " 'quito',\n",
       " 'alwaleed',\n",
       " 'tara',\n",
       " 'presumed',\n",
       " 'instrumentalists',\n",
       " 'mentor',\n",
       " 'reserving',\n",
       " 'pedophiles',\n",
       " 'antireformer',\n",
       " 'proportionally',\n",
       " 'gamelin',\n",
       " 'desecrated',\n",
       " 'hughlett',\n",
       " 'supplement',\n",
       " 'enrichment',\n",
       " 'trusler',\n",
       " 'reprise',\n",
       " 'rapid',\n",
       " 'hoepfner',\n",
       " 'elaborate',\n",
       " 'kilometres',\n",
       " 'abduction',\n",
       " 'resets',\n",
       " 'mendota',\n",
       " 'vosler',\n",
       " 'dangler',\n",
       " 'grier',\n",
       " 'conjectures',\n",
       " 'dwindling',\n",
       " 'revoking',\n",
       " 'hasta',\n",
       " 'sui',\n",
       " 'predicting',\n",
       " 'introduce',\n",
       " 'settlers',\n",
       " 'sistine',\n",
       " 'fondue',\n",
       " 'patrimonial',\n",
       " 'wheeze',\n",
       " 'whorley',\n",
       " 'travelling',\n",
       " 'antisense',\n",
       " 'lxi',\n",
       " 'wheelchair',\n",
       " 'erupting',\n",
       " 'breidenstein',\n",
       " 'credential',\n",
       " 'cyclical',\n",
       " 'rusted',\n",
       " 'boise',\n",
       " 'tunis',\n",
       " 'fosler',\n",
       " 'whirling',\n",
       " 'kotsonis',\n",
       " ...}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_pronunciations.index) & set(dev_pronunciations.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pronunciation                     (k, eɪ, ˈ, ɑː, n, uː)\n",
       "num_phonemes                                          5\n",
       "num_syllables                                         1\n",
       "num_primary_stressed_syllables                        1\n",
       "Name: keanu, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations.loc['keanu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('k', 'iː', 'ˈ', 'ɑː', 'n', 'uː')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pronunciations.loc['keanu'].pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pronunciations['perplexity'] = dev_pronunciations.pronunciation.apply(model2.perplexity_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/sonorous/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_pronunciations['perplexity'] = train_pronunciations.pronunciation.apply(model2.perplexity_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.840700e+04\n",
       "mean     9.454545e+01\n",
       "std      1.436103e+04\n",
       "min      3.780680e+00\n",
       "25%      8.714275e+00\n",
       "50%      1.114043e+01\n",
       "75%      1.494983e+01\n",
       "max      2.599575e+06\n",
       "Name: perplexity, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations.perplexity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004013807497792406"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dev_pronunciations.num_phonemes==1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ɪ', 'n', 'ˈ', 'v', 'aɪ', 'r', 'ə', 'n', 'm', 'ə', 'n', 't')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['environment'].pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ˈ     69549\n",
       "ˌ      7943\n",
       "m      2279\n",
       "k      2037\n",
       "d      2037\n",
       "ə      1990\n",
       "r      1726\n",
       "p      1435\n",
       "s      1273\n",
       "b      1021\n",
       "ɪ       806\n",
       "l       666\n",
       "f       563\n",
       "t       550\n",
       "v       501\n",
       "g       455\n",
       "ɑː      439\n",
       "ɛ       420\n",
       "n       366\n",
       "h       327\n",
       "æ       301\n",
       "oʊ      242\n",
       "dʒ      227\n",
       "j       167\n",
       "z       156\n",
       "tʃ      141\n",
       "ʃ       135\n",
       "ɝ       129\n",
       "iː      119\n",
       "w        88\n",
       "ɔ        81\n",
       "aɪ       62\n",
       "aʊ       48\n",
       "eɪ       36\n",
       "θ        35\n",
       "ʒ        33\n",
       "uː       16\n",
       "ð         8\n",
       "Name: pronunciation, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations.pronunciation.apply(lambda p: p[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pt', 'wb') as fh:\n",
    "    model.save(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (_encoder): Embedding(47, 100)\n",
       "  (_rnn): GRU(100, 20, batch_first=True)\n",
       "  (_decoder): Linear(in_features=20, out_features=47, bias=True)\n",
       "  (_dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (_encoder): Embedding(47, 20)\n",
       "  (_rnn): GRU(20, 20, batch_first=True)\n",
       "  (_decoder): Linear(in_features=20, out_features=47, bias=True)\n",
       "  (_dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 0.1157408282160759),\n",
       " ('k', 0.08229496330022812),\n",
       " ('b', 0.07638482749462128),\n",
       " ('h', 0.0634717047214508),\n",
       " ('m', 0.06258977204561234),\n",
       " ('r', 0.05845705047249794),\n",
       " ('p', 0.051873404532670975),\n",
       " ('f', 0.04908735677599907),\n",
       " ('l', 0.0490451417863369),\n",
       " ('g', 0.04636289179325104),\n",
       " ('d', 0.04572166129946709),\n",
       " ('t', 0.04444989934563637),\n",
       " ('w', 0.03888579085469246),\n",
       " ('n', 0.029962318018078804),\n",
       " ('ʃ', 0.023488372564315796),\n",
       " ('æ', 0.021215857937932014),\n",
       " ('v', 0.01706729456782341),\n",
       " ('ɛ', 0.015526660718023777),\n",
       " ('dʒ', 0.015337788499891758),\n",
       " ('ɑː', 0.012288525700569153),\n",
       " ('tʃ', 0.011904851533472538),\n",
       " ('j', 0.011207259260118008),\n",
       " ('ɪ', 0.009802079759538174),\n",
       " ('oʊ', 0.008307610638439655),\n",
       " ('θ', 0.005722980946302414),\n",
       " ('z', 0.00557325966656208),\n",
       " ('ɔ', 0.005239768885076046),\n",
       " ('ʌ', 0.004391584079712629),\n",
       " ('eɪ', 0.004019142594188452),\n",
       " ('aʊ', 0.0030948740895837545),\n",
       " ('aɪ', 0.002752031432464719),\n",
       " ('iː', 0.0026345818769186735),\n",
       " ('ɝː', 0.0016971119912341237),\n",
       " ('uː', 0.001286481972783804),\n",
       " ('ˌ', 0.001090734382160008),\n",
       " ('ʒ', 0.0005573923699557781),\n",
       " ('ð', 0.0004217646783217788),\n",
       " ('ɔɪ', 0.0003664632677100599),\n",
       " ('ə', 0.0003038114809896797),\n",
       " ('ˈ', 0.00019881621119566262),\n",
       " ('ŋ', 9.072782268049195e-05),\n",
       " ('ʊ', 4.8771355068311095e-05),\n",
       " ('<PAD>', 2.169449180655647e-05),\n",
       " ('<END>', 7.648613973287866e-06),\n",
       " ('ɝ', 4.5518900151364505e-06),\n",
       " ('i', 1.5742766663606744e-06),\n",
       " ('<START>', 3.2569366226198326e-07)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pron = (\"ˈ\", )\n",
    "sorted(model.next_probabilities(pron).items(), key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>(k, ə, n)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.148166e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mc</th>\n",
       "      <td>(m, ɪ, k)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.299671e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olmert</th>\n",
       "      <td>(oʊ, l, m, ɝ, t)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.879959e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>(d, ɪ, d)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.382492e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>(d, ə)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.509939e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarin</th>\n",
       "      <td>(s, ɑː, r, ɪ, n)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.327210e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er</th>\n",
       "      <td>(ɝ,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.599575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>(ð, ɪ, s)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.229038e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du</th>\n",
       "      <td>(d, ə)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.509939e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>(t, ɪ)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.546479e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                    \n",
       "can            (k, ə, n)             3              1   \n",
       "mc             (m, ɪ, k)             3              1   \n",
       "olmert  (oʊ, l, m, ɝ, t)             5              2   \n",
       "did            (d, ɪ, d)             3              1   \n",
       "de                (d, ə)             2              1   \n",
       "...                  ...           ...            ...   \n",
       "sarin   (s, ɑː, r, ɪ, n)             5              1   \n",
       "er                  (ɝ,)             1              1   \n",
       "this           (ð, ɪ, s)             3              1   \n",
       "du                (d, ə)             2              1   \n",
       "to                (t, ɪ)             2              1   \n",
       "\n",
       "        num_primary_stressed_syllables    perplexity  \n",
       "word                                                  \n",
       "can                                  0  1.148166e+02  \n",
       "mc                                   0  1.299671e+02  \n",
       "olmert                               0  1.879959e+02  \n",
       "did                                  0  1.382492e+02  \n",
       "de                                   0  3.509939e+03  \n",
       "...                                ...           ...  \n",
       "sarin                                0  8.327210e+01  \n",
       "er                                   0  2.599575e+06  \n",
       "this                                 0  5.229038e+02  \n",
       "du                                   0  3.509939e+03  \n",
       "to                                   0  3.546479e+03  \n",
       "\n",
       "[82 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations[train_pronunciations.num_primary_stressed_syllables==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>(ˈ, d, ɪ, d)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>(d, ɪ, d)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                              \n",
       "did   (ˈ, d, ɪ, d)             3              1   \n",
       "did      (d, ɪ, d)             3              1   \n",
       "\n",
       "      num_primary_stressed_syllables  \n",
       "word                                  \n",
       "did                                1  \n",
       "did                                0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['did']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>(ɝ,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.599575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er</th>\n",
       "      <td>(ɝ,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.599575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>(ɝ,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.599575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>(ə,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496432e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>(t, ə)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.789262e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                              \n",
       "are           (ɝ,)             1              1   \n",
       "er            (ɝ,)             1              1   \n",
       "or            (ɝ,)             1              1   \n",
       "a             (ə,)             1              1   \n",
       "to          (t, ə)             2              1   \n",
       "\n",
       "      num_primary_stressed_syllables    perplexity  \n",
       "word                                                \n",
       "are                                0  2.599575e+06  \n",
       "er                                 0  2.599575e+06  \n",
       "or                                 0  2.599575e+06  \n",
       "a                                  0  1.496432e+05  \n",
       "to                                 0  9.789262e+03  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pronunciations.sort_values('perplexity', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>(ð, ə)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14001.083358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>(ð, ə, t)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6166.914781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hye</th>\n",
       "      <td>(h, aɪ)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5195.251682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>(ð, ə, m)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2393.481473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>(ə, n)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1551.952516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                              \n",
       "the         (ð, ə)             2              1   \n",
       "that     (ð, ə, t)             3              1   \n",
       "hye        (h, aɪ)             2              1   \n",
       "them     (ð, ə, m)             3              1   \n",
       "an          (ə, n)             2              1   \n",
       "\n",
       "      num_primary_stressed_syllables    perplexity  \n",
       "word                                                \n",
       "the                                0  14001.083358  \n",
       "that                               0   6166.914781  \n",
       "hye                                0   5195.251682  \n",
       "them                               0   2393.481473  \n",
       "an                                 0   1551.952516  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pronunciations.sort_values('perplexity', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24914.000000\n",
       "mean        14.475538\n",
       "std        104.557572\n",
       "min          3.870974\n",
       "25%          8.730506\n",
       "50%         11.144563\n",
       "75%         14.927530\n",
       "max      14001.083358\n",
       "Name: perplexity, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pronunciations.perplexity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ə     131\n",
       "ɑː    104\n",
       "r      81\n",
       "ɝ      40\n",
       "ɪ      36\n",
       "uː     28\n",
       "ˈ      25\n",
       "oʊ     25\n",
       "l      16\n",
       "w      16\n",
       "æ      14\n",
       "ɔ      13\n",
       "iː      5\n",
       "ɛ       5\n",
       "ˌ       5\n",
       "eɪ      3\n",
       "ʊ       2\n",
       "aɪ      2\n",
       "j       1\n",
       "aʊ      1\n",
       "Name: pronunciation, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[pronunciations.pronunciation.apply(lambda p: p[0]) == 'g'].pronunciation.apply(lambda p: p[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ə', 0.3280123174190521),\n",
       " ('r', 0.12613198161125183),\n",
       " ('ɑː', 0.11936482042074203),\n",
       " ('ɪ', 0.09128992259502411),\n",
       " ('ɝ', 0.08214181661605835),\n",
       " ('oʊ', 0.038501884788274765),\n",
       " ('ˈ', 0.03032498247921467),\n",
       " ('uː', 0.02914828062057495),\n",
       " ('ɛ', 0.02716413140296936),\n",
       " ('ɔ', 0.02546863444149494),\n",
       " ('iː', 0.02414916269481182),\n",
       " ('l', 0.0208772961050272),\n",
       " ('æ', 0.014327534474432468),\n",
       " ('ʊ', 0.009786877781152725),\n",
       " ('eɪ', 0.007247230038046837),\n",
       " ('aɪ', 0.005708749871701002),\n",
       " ('j', 0.005124278366565704),\n",
       " ('w', 0.0040793027728796005),\n",
       " ('aʊ', 0.0024103124160319567),\n",
       " ('ˌ', 0.0022820117883384228),\n",
       " ('s', 0.0016470968257635832),\n",
       " ('n', 0.001252837828360498),\n",
       " ('m', 0.0012219400377944112),\n",
       " ('ɝː', 0.0006574296858161688),\n",
       " ('ɔɪ', 0.0005285788211040199),\n",
       " ('ʌ', 0.0002027501177508384),\n",
       " ('<END>', 0.00019332046213094145),\n",
       " ('ʃ', 0.00016001783660613),\n",
       " ('t', 0.0001365228818031028),\n",
       " ('b', 8.011871977942064e-05),\n",
       " ('z', 7.801431638654321e-05),\n",
       " ('f', 7.120994268916547e-05),\n",
       " ('h', 4.8149664507946e-05),\n",
       " ('p', 4.35175170423463e-05),\n",
       " ('i', 4.318717765272595e-05),\n",
       " ('k', 3.1339051929535344e-05),\n",
       " ('tʃ', 1.8826893210643902e-05),\n",
       " ('θ', 1.2897756278107408e-05),\n",
       " ('g', 1.2864563359471504e-05),\n",
       " ('d', 8.743769285501912e-06),\n",
       " ('ʒ', 3.0127364425425185e-06),\n",
       " ('ð', 2.58974341704743e-06),\n",
       " ('dʒ', 1.5807793261046754e-06),\n",
       " ('v', 1.5579005321342265e-06),\n",
       " ('ŋ', 2.442676247937925e-07),\n",
       " ('<PAD>', 8.298171394471865e-08),\n",
       " ('<START>', 1.3212918759109016e-08)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation = ('g',)\n",
    "sorted(model2.next_probabilities(pronunciation).items(), key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pronunciation                     (ˈ, f, æ, ŋ)\n",
       "num_phonemes                                 3\n",
       "num_syllables                                1\n",
       "num_primary_stressed_syllables               1\n",
       "Name: fang, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['fang']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the vocab. All look good?\n",
    "* Check generated stress patterns vs in corpus. starting with primary. number of stresses. \n",
    "* --plot the loss for both. makes sense?--. Sort of; weird that dev drops more...\n",
    "* --recheck train and dev loaders--. seems consistent\n",
    "\n",
    "* check perplexity on dev and train sets. are there high perplexity words in the training set? or long words or something?\n",
    "* are dev and train distributions the same?\n",
    "  * num phonemes\n",
    "  * num syllables\n",
    "  * phoneme hists overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f36892d3898>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(dev_losses, label='dev')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ɪ', 'n', 'ˈ', 'v', 'aɪ', 'r', 'ə', 'n', 'm', 'ə', 'n', 't')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['environment'].pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<END>', 0.23827940225601196),\n",
       " ('n', 0.18405938148498535),\n",
       " ('l', 0.12095028162002563),\n",
       " ('t', 0.11505918204784393),\n",
       " ('s', 0.1045665368437767),\n",
       " ('ˌ', 0.09903314709663391),\n",
       " ('m', 0.03616911917924881),\n",
       " ('z', 0.017551984637975693),\n",
       " ('d', 0.015750762075185776),\n",
       " ('b', 0.014727246947586536),\n",
       " ('k', 0.012879342772066593),\n",
       " ('dʒ', 0.009734299033880234),\n",
       " ('p', 0.006754468195140362),\n",
       " ('ʃ', 0.004392565228044987),\n",
       " ('f', 0.0037111674901098013),\n",
       " ('v', 0.0027258722111582756),\n",
       " ('ŋ', 0.0022488520480692387),\n",
       " ('tʃ', 0.0021722023375332355),\n",
       " ('ˈ', 0.0016706361202523112),\n",
       " ('w', 0.001512062270194292),\n",
       " ('h', 0.0010829651728272438),\n",
       " ('g', 0.001038959133438766),\n",
       " ('θ', 0.0010268627665936947),\n",
       " ('ɪ', 0.0007660716073587537),\n",
       " ('ə', 0.0006719491793774068),\n",
       " ('ɝ', 0.00032007807749323547),\n",
       " ('r', 0.0002714544825721532),\n",
       " ('i', 0.0002026021684287116),\n",
       " ('ʒ', 0.0001496801123721525),\n",
       " ('aɪ', 8.44288369989954e-05),\n",
       " ('ð', 8.016002539079636e-05),\n",
       " ('eɪ', 7.193924830062315e-05),\n",
       " ('iː', 6.54843170195818e-05),\n",
       " ('ɔ', 5.3937539632897824e-05),\n",
       " ('<PAD>', 3.262731115682982e-05),\n",
       " ('ɛ', 3.0262712243711576e-05),\n",
       " ('uː', 2.3292905098060146e-05),\n",
       " ('j', 2.2667903976980597e-05),\n",
       " ('oʊ', 2.0462521206354722e-05),\n",
       " ('ɑː', 1.4823362107563298e-05),\n",
       " ('ʊ', 5.900061296415515e-06),\n",
       " ('aʊ', 4.3408299461589195e-06),\n",
       " ('æ', 4.161021479376359e-06),\n",
       " ('ɔɪ', 3.5162936455890303e-06),\n",
       " ('ɝː', 2.237790113213123e-06),\n",
       " ('ʌ', 3.1085517093742965e-07),\n",
       " ('<START>', 3.086220488057734e-07)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation = ('ɪ', 'n', 'ˈ', 'v', 'aɪ', 'r', 'ə')\n",
    "sorted(model.next_probabilities(pronunciation).items(), key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonorous.languagemodel import build_data_loader\n",
    "train_loader = build_data_loader(train_pronunciations.pronunciation.values.tolist(), vocab)\n",
    "dev_loader = build_data_loader(dev_pronunciations.pronunciation.values.tolist(), vocab)\n",
    "all_loader = build_data_loader(pronunciations.pronunciation.values.tolist(), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5294013107031621"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45317746707209383"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4521759484323973"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(all_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'embedding_dimension': [10, 50, 100],\n",
    "    'hidden_dimension': [10, 50, 100],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    model_parameters = ModelParams(rnn_type='gru', num_layers=1, max_epochs=1000, early_stopping_rounds=1, **params)\n",
    "    model = LanguageModel(vocab, model_parameters, device_name='cuda')\n",
    "\n",
    "    print('Model Params:', model_parameters)\n",
    "    \n",
    "    train_losses, dev_losses = model.fit(\n",
    "        train_pronunciations.pronunciation.values.tolist(),\n",
    "        dev_pronunciations.pronunciation.values.tolist()\n",
    "    )\n",
    "    \n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "        \n",
    "        record['rnn_type'] = 'rnn'\n",
    "        record['num_layers'] = 1 \n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'embedding_dimension': [50],\n",
    "    'hidden_dimension': [2],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    model_parameters = ModelParams(rnn_type='rnn', num_layers=1, max_epochs=1000, early_stopping_rounds=1, **params)\n",
    "    model = LanguageModel(vocab, model_parameters, device_name='cpu')\n",
    "\n",
    "    print('Model Params:', model_parameters)\n",
    "    \n",
    "    train_losses, dev_losses = model.fit(\n",
    "        train_pronunciations.pronunciation.values.tolist(),\n",
    "        dev_pronunciations.pronunciation.values.tolist()\n",
    "    )\n",
    "    \n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are {meow} models with a dev error of around .76. I'll choose the simplest one, which \n",
    "\n",
    "* point out that no matter how low the train error gets, the dev error\n",
    "* which model parameters fail to ever get to the lowest dev error\n",
    "* which model parameters overfit the most\n",
    "\n",
    "* isolate the group of models with about .76 dev error. choose the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = models_df[(models_df.embedding_dimension==50) & (models_df.hidden_dimension==100) & (models_df.num_layers==3)]\n",
    "t = t.set_index('epoch')\n",
    "t.dev_loss.plot()\n",
    "t.train_loss.plot()\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('dev_loss').iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best \"model\" was at an earlier epoch I don't have access to it. So I'll train a model with that model's parameters and set the number of epochs to MEOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = PhonemeLM(\n",
    "    phoneme_to_idx, device='cuda', rnn_type='gru',\n",
    "    embedding_dimension=50, hidden_dimension=100, num_layers=3,\n",
    "    max_epochs=69, early_stopping_rounds=69, batch_size=1024,\n",
    ")\n",
    "\n",
    "train_loss, dev_loss = model.fit(train_df.pronunciation.values.tolist(), dev_df.pronunciation.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have what I hope is the best model I can test how well it does on the holdout test set, which I haven't look at at all during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_data_loader(test_df.pronunciation.values.tolist(), lm.phoneme_to_idx)\n",
    "lm.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = build_data_loader(dev_df.pronunciation.values.tolist(), lm.phoneme_to_idx)\n",
    "lm.evaluate(dev_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: compute the test error for the final model. Bar chart for the train, dev, and test errors\n",
    "\n",
    "Comment on findings, probably that test is higher and that's expected because language models are very sensitive to corpus difference (and I probably overfit the dev set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Final Model ##\n",
    "Now that I've found the best parameters for the model according to the dev set I'll train a final model using all of the data. This should increase model performance overall since more data is better, but is also necessary since I'll be using the model to predict probabilities of all English words. If some of those words weren't in the training set they would artificially get lower probabilities. (Another approach here could be to train a model on e.g. 4/5 folds of the data and make predictions about the remaining 1/5, doing that 5 times to get unbiased predictions for all data, but this would have taken much longer to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_params = ModelParams(\n",
    "    rnn_type='gru', embedding_dimension=50, hidden_dimension=50, num_layers=1,\n",
    "    max_epochs=3, early_stopping_rounds=3, batch_size=1024\n",
    ")\n",
    "\n",
    "language_model = LanguageModel(vocab, model_params, device_name='cpu')\n",
    "\n",
    "_ = language_model.fit(pronunciations.pronunciation.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, I'll save the model so I can use it in the next notebook, `Phoneme Exploration.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phoneme_language_model.pt', 'wb') as fh:\n",
    "    model.save(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
