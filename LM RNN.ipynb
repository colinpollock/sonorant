{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from phoneme_lm import PhonemeLM, build_data_loader, build_vocab, encode_pronunciation\n",
    "from utils import load_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_idx, idx_to_phoneme = build_vocab(df.pronunciation.values)\n",
    "df['phoneme_ids'] = df.pronunciation.apply(lambda pronunciation: encode_pronunciation(pronunciation, phoneme_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pronunciation_string'] = df.pronunciation.apply(' '.join)\n",
    "df['length'] = df.pronunciation.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 25000, 1250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, dev_df, test_df = split_data(df, dev_proportion=.2, test_proportion=.01)\n",
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# lm = PhonemeLM(\n",
    "#     phoneme_to_idx, device='cuda', rnn_type='gru',\n",
    "#     embedding_dimension=20, hidden_dimension=100, num_layers=3,\n",
    "#     max_epochs=2000, early_stopping_rounds=3,\n",
    "#     lr=1e-3, batch_size=1024\n",
    "# )\n",
    "\n",
    "\n",
    "# train_loss, dev_loss = lm.fit(train_df.pronunciation.values.tolist(), dev_df.pronunciation.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.7981\tassess loss: 1.2296\n",
      "\tGenerated: in train: 2%, assess: 0%, novel: 98%\n",
      "\t AA0 R IH1 EY0 N T N EY1\n",
      "\t UH2 EY1 HH ER1 D\n",
      "\t IH2 IY1 EH0 OW2 TH\n",
      "\t JH AE2 TH N AH0 D N AH0 EY1\n",
      "\t AE1 M AW1 AH0 B\n",
      "Epoch 2: train loss: 0.7184\tassess loss: 1.1110\n",
      "\tGenerated: in train: 2%, assess: 0%, novel: 98%\n",
      "\t AA0 D K AH0 ER0\n",
      "\t K ER0 F K AH0 L L IY0 K\n",
      "\t EY2 T AE1 Z IH0 T AH0\n",
      "\t AA1 K R M S\n",
      "\t L JH IH0 N\n",
      "Epoch 3: train loss: 0.6996\tassess loss: 1.0826\n",
      "\tGenerated: in train: 5%, assess: 0%, novel: 95%\n",
      "\t N K AH1 S AH0 Z\n",
      "\t N ER1 N ER1 AH0 V N AH0 AO0\n",
      "\t S IH0 M IY0 AA2 R L G\n",
      "\t IY1 M D Z Z IY0\n",
      "\t AH1 G R EY1 S\n",
      "Epoch 4: train loss: 0.6702\tassess loss: 1.0372\n",
      "\tGenerated: in train: 2%, assess: 1%, novel: 97%\n",
      "\t S T ER1 R ER0\n",
      "\t P R AH0 AA1 Z G Z\n",
      "\t K IH1 OW1 D ER0 AH0 R\n",
      "\t K S CH L\n",
      "\t NG EH1 Y S T N IH0 T L\n",
      "Epoch 5: train loss: 0.6359\tassess loss: 0.9843\n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t R AE0 B AO1 B AH0 N S T AH0 K\n",
      "\t K AA0 NG AH0 D EH2 L T D T IY0\n",
      "\t M AO1 ER1 AH1 EY2\n",
      "\t N IH1 K IH0 S AH0 M\n",
      "\t R AO1 AA1 N T IY0\n",
      "Epoch 6: train loss: 0.6083\tassess loss: 0.9418\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t L AH1 N IY0\n",
      "\t M AH1 NG D IY0 EH2 N\n",
      "\t IY0 F IH1 P IH0 V T AA1 N\n",
      "\t L EH1 M T AA2 N AE2\n",
      "\t JH R UW1 N Z\n",
      "Epoch 7: train loss: 0.5945\tassess loss: 0.9206\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t HH R UW1 T S IY0\n",
      "\t P R OW1 M IH0 D\n",
      "\t K IH0 K EH1 L IH0 K IH0 NG\n",
      "\t Y IY1 G HH IY0 AH0\n",
      "\t N IH1 S S HH EY1 T\n",
      "Epoch 8: train loss: 0.5862\tassess loss: 0.9080\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t F EH1 JH\n",
      "\t V AH2 S D W ER0 D EY0\n",
      "\t CH EH1 D AH0 L\n",
      "\t JH R IH0 K AH0 D IH0 G IH1 T OW0\n",
      "\t K W AE1 V AH0 L\n",
      "Epoch 9: train loss: 0.5794\tassess loss: 0.8975\n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t B R AE1 K AH0 P S\n",
      "\t K IY1 Z AH0\n",
      "\t R AE1 P D AH0 Z\n",
      "\t P R IH1 K IH0 T IH0 NG\n",
      "\t M EY1 B IY2 W L ER0\n",
      "Epoch 10: train loss: 0.5731\tassess loss: 0.8879\n",
      "\tGenerated: in train: 6%, assess: 1%, novel: 93%\n",
      "\t G AA1 L D IH0 T L AH0 JH T S\n",
      "\t R W AY1 G AH0 N\n",
      "\t B R EH1 W IY0\n",
      "\t IY0 K AE1 F S D OW0\n",
      "\t IH0 K S W AA1 D ER0\n",
      "Epoch 11: train loss: 0.5689\tassess loss: 0.8816\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t EH1 N IH0 NG\n",
      "\t B EH1 R AH0 N V ER0\n",
      "\t R AE1 D K T\n",
      "\t OW1 P S AH0 L\n",
      "\t M AE1 F R OW0 SH IH2 N IY0\n",
      "Epoch 12: train loss: 0.5655\tassess loss: 0.8764\n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t S IH0 V IH1 K AH0 K T\n",
      "\t P AO1 R\n",
      "\t B IH1 S AH0 T IH0 NG\n",
      "\t B AY1 L M SH L IY0\n",
      "\t SH AO1 K S\n",
      "Epoch 13: train loss: 0.5633\tassess loss: 0.8730\n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t HH ER1 N T\n",
      "\t F AA1 N ER0\n",
      "\t N IH1 F AH0 T\n",
      "\t AA0 N K EH1 S AH0 L\n",
      "\t R IY0 B R AO0 R T IY1 AH0 Z\n",
      "Epoch 14: train loss: 0.5605\tassess loss: 0.8686\n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t M AO1 R Z\n",
      "\t M EH1 V F AH0 L AY2\n",
      "\t K ER1 N OW0 N\n",
      "\t JH EH1 B IH0 K V UH2 L S\n",
      "\t L IY0 EH1 CH\n",
      "Epoch 15: train loss: 0.5574\tassess loss: 0.8640\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t F IH1 S\n",
      "\t W AH1 D T\n",
      "\t EH1 G F\n",
      "\t F R EY1 T IH0 D\n",
      "\t IY1 HH IY0\n",
      "Epoch 16: train loss: 0.5556\tassess loss: 0.8612\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t V IH1 K AH0 N T IY0\n",
      "\t P IY1 F AH0 T R\n",
      "\t AH0 V AE1 CH IH0 K S\n",
      "\t AH0 N M L AE1 SH P AY2 IY0 Z\n",
      "\t AH0 L AE1 M K T B AA2 T S\n",
      "Epoch 17: train loss: 0.5535\tassess loss: 0.8579\n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t TH EH1 D IH0 M\n",
      "\t P R IH1 N D\n",
      "\t OW1 W EH0 B N AH0 F IY1 N\n",
      "\t R AE1 K N AA2 T\n",
      "\t F AA1 S AH0 N S T AO2\n",
      "Epoch 18: train loss: 0.5512\tassess loss: 0.8547\n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t M IY1 Z\n",
      "\t M AH0 B ER1 L EH0 M D IH0 D\n",
      "\t P R AA1 L IH0 NG\n",
      "\t W IH1 S ER0\n",
      "\t D IH0 D AY1 T EH0 M\n",
      "Epoch 19: train loss: 0.5505\tassess loss: 0.8535\n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t P R IY1 D\n",
      "\t JH AH0 K AO1 R T ER0\n",
      "\t D Y EY1 T D\n",
      "\t SH L AH1 M S T\n",
      "\t D EH1 M D IH0 NG\n",
      "Epoch 20: train loss: 0.5479\tassess loss: 0.8497\n",
      "\tGenerated: in train: 11%, assess: 4%, novel: 85%\n",
      "\t B IH1 N AH0 S T\n",
      "\t W AO1 CH AH0 L\n",
      "\t P AA1 L ER0\n",
      "\t OY1 L IH0 NG\n",
      "\t S AY1 K IH0 NG\n",
      "Epoch 21: train loss: 0.5469\tassess loss: 0.8481\n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t B ER1 AH0 S L EH2 B AY0\n",
      "\t HH IH1 SH\n",
      "\t HH OW1 L N\n",
      "\t HH EH0 M IY1 L\n",
      "\t K L IH1 N IH0 K S\n",
      "Epoch 22: train loss: 0.5452\tassess loss: 0.8457\n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t HH AH2 N T IH0 M P L OW1 SH AH0 N\n",
      "\t P AO1 M AH0 T S\n",
      "\t S EY1 B AH0 L D\n",
      "\t HH AA1 B D\n",
      "\t N EH0 M UW0 G EY1 S IH0 K\n",
      "Epoch 23: train loss: 0.5443\tassess loss: 0.8444\n",
      "\tGenerated: in train: 8%, assess: 3%, novel: 89%\n",
      "\t IH2 N S AE1 S AH0 T\n",
      "\t W IH1 L IH0 NG\n",
      "\t S T EH1 N ER0\n",
      "\t M AW1\n",
      "\t K R IH1 NG D IY0\n",
      "Epoch 24: train loss: 0.5438\tassess loss: 0.8434\n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t AH0 N T IH0 S P L EY1 IH0 NG AH0 D\n",
      "\t D AA2 B UH1 T ER0 Z\n",
      "\t K R IH1 M P\n",
      "\t F AH0 M Y UW1 G EH0\n",
      "\t SH EH1 D L IY0\n",
      "Epoch 25: train loss: 0.5428\tassess loss: 0.8421\n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t R EY1 S AH0 N AH0 L\n",
      "\t Z AE2 AA2 K AH0 M EY1 V ER0 AH0 N\n",
      "\t L OW1 M P AY2 K\n",
      "\t AH0 V AA1 V AH0\n",
      "\t IH0 N T IH1 T ER0 AH0 T\n",
      "Epoch 26: train loss: 0.5413\tassess loss: 0.8398\n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t AH0 N S UW1 L ER0\n",
      "\t L AA0 S P IY0 AA1 L AH0\n",
      "\t JH IH0 K EH1 N AH0 T\n",
      "\t S P OW1 L N\n",
      "\t M AH0 K OW1 CH AH0\n",
      "Epoch 27: train loss: 0.5409\tassess loss: 0.8391\n",
      "\tGenerated: in train: 17%, assess: 1%, novel: 82%\n",
      "\t P L EY1 G IH0 NG\n",
      "\t P L AH0 V AE1 N T\n",
      "\t AH0 N D EH1 T N AH0\n",
      "\t EH2 N T D UW0 AA1 N OW0 N\n",
      "\t M AH1 L NG TH\n",
      "Epoch 28: train loss: 0.5395\tassess loss: 0.8371\n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t R IY1 G\n",
      "\t HH AO1 N D R AE0 SH\n",
      "\t D IH0 S K AA1 N T AH0 L AH0 NG\n",
      "\t B EH1 K\n",
      "\t M AA0 L IH1 L Z\n",
      "Epoch 29: train loss: 0.5386\tassess loss: 0.8359\n",
      "\tGenerated: in train: 8%, assess: 3%, novel: 89%\n",
      "\t IY0 AE1 P AH0 N EY1 D AH0 D\n",
      "\t HH AO1 HH AH0 V IH0 S T\n",
      "\t AH0 V OW1 ZH HH AH0 L IH0 N\n",
      "\t AH1 L Z\n",
      "\t OW0 K EH1 N D IH0 JH\n",
      "Epoch 30: train loss: 0.5381\tassess loss: 0.8350\n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t R IY1 P S\n",
      "\t R IH0 G AA1 N IY0 AH0\n",
      "\t K IH2 NG V Y UW0 L OW1 V B AH0 L\n",
      "\t IH2 P ER0 T IY1 N\n",
      "\t G AH1 K T ER0 IH0 NG\n",
      "Epoch 31: train loss: 0.5378\tassess loss: 0.8347\n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t UH2 L S AH0 L AA1 V IH0 T IY0\n",
      "\t P EY1 N AH0 N TH\n",
      "\t HH AA1 R M IY0\n",
      "\t AE0 T Y UW1 T M L EH2 N T S\n",
      "\t D AW1 M Z\n",
      "Epoch 32: train loss: 0.5373\tassess loss: 0.8339\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t T AE1 T IH0 N\n",
      "\t S IY1 N\n",
      "\t B EY1 M ER0 M AH0 N\n",
      "\t AA0 R OW1 B ER0 IH0 K S\n",
      "\t G AE1 Z IY0\n",
      "Epoch 33: train loss: 0.5360\tassess loss: 0.8319\n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t R OY1 OW0\n",
      "\t NG K AE1 S K OW0\n",
      "\t G AO1 R L ER0\n",
      "\t F EH1 R AH0 W AA2 N\n",
      "\t D IH0 T EH1 D IY0 AA2 R AH0 N\n",
      "Epoch 34: train loss: 0.5356\tassess loss: 0.8314\n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t D AH0 P W ER1 G ER0\n",
      "\t IY1 ER0 Z\n",
      "\t B OW1 L D\n",
      "\t R AH0 JH UW1 K\n",
      "\t K EY1 F L ER0\n",
      "Epoch 35: train loss: 0.5349\tassess loss: 0.8304\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t K AA1 L S T OW0\n",
      "\t K AE1 K AH0 N S\n",
      "\t F AA0 T AA1 R Z\n",
      "\t HH AA1 M IH0 G\n",
      "\t K AE1 S T AH0 N T\n",
      "Epoch 36: train loss: 0.5348\tassess loss: 0.8304\n",
      "\tGenerated: in train: 8%, assess: 0%, novel: 92%\n",
      "\t R AH1 K S AH0\n",
      "\t K AE1 B ER0 G Y UW0 AA2 L\n",
      "\t IH2 K S AH0 K AE1 K T IH0 D AH0 L Z\n",
      "\t T AW1 V\n",
      "\t EH1 L B R AH0 F S K AA0 K\n",
      "Epoch 37: train loss: 0.5347\tassess loss: 0.8301\n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t HH AA1 T L IH0 D Y\n",
      "\t M AW1 L T AH0 D\n",
      "\t B ER1 S T R AH0 L Z\n",
      "\t S K R IY0\n",
      "\t R OW0 S T IY1 L IH0 K AH0 L\n",
      "Epoch 38: train loss: 0.5342\tassess loss: 0.8294\n",
      "\tGenerated: in train: 7%, assess: 4%, novel: 89%\n",
      "\t K R EH1 D\n",
      "\t P ER1 CH\n",
      "\t R EH2 Z OW0 K AA1 R T OW0\n",
      "\t AA0 AE1 G AH0 L Z\n",
      "\t G AE1 S T AH0 N S AH0 N\n",
      "Epoch 39: train loss: 0.5337\tassess loss: 0.8287\n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t EH2 N D AH0 L EY2 T R OW0 M IY1 JH IH0 NG\n",
      "\t SH AH1 M B EH1 R\n",
      "\t P EH2 Y AH0 L AA1 M AH0 K R EY0 T\n",
      "\t M AE1 S AH0 N AH0 S AO0 F\n",
      "\t S AH0 V EH1 L IY0\n",
      "Epoch 40: train loss: 0.5328\tassess loss: 0.8276\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t R OW1 ER0\n",
      "\t W EH1 S\n",
      "\t S T IY1 R IH0 S T\n",
      "\t W EH1 N AH0 L D\n",
      "\t R EH1 S K AW2 T\n",
      "Epoch 41: train loss: 0.5326\tassess loss: 0.8273\n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t AA1 R D ER0\n",
      "\t B IY1 M AH0 N\n",
      "\t IH0 N IH0 V IH1 K T\n",
      "\t K AH0 M IH0 N AA1 DH IY0\n",
      "\t P AA1 R S T AH0 N OW2 Z IY0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: train loss: 0.5332\tassess loss: 0.8283\n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t HH AE1 M AH0 K AA1 N\n",
      "\t B OW1 L D Z\n",
      "\t B EH1 L\n",
      "\t P IH1 L AH0\n",
      "\t T AY2 P AE1 S T AH0 K S\n",
      "Epoch 43: train loss: 0.5320\tassess loss: 0.8263\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t V IH0 L AA1 N Z\n",
      "\t OW1 M AA0 F\n",
      "\t P AH0 M EH1 L\n",
      "\t N AA1 L AH0 N S AH2 N\n",
      "\t EH1 N W IY0 M\n",
      "Epoch 44: train loss: 0.5311\tassess loss: 0.8251\n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t B R IY1 NG M AH0 N\n",
      "\t OW1 R Z EH2 D\n",
      "\t AA1 R W IH2 T IH0 K\n",
      "\t B R AA1 DH IY0\n",
      "\t M OW1 T R ER2 K ER0\n",
      "Epoch 45: train loss: 0.5307\tassess loss: 0.8245\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t EH1 G L IY0\n",
      "\t AA2 M AH0 M OW1 N IY0 AH0 N\n",
      "\t K R AO1 Z\n",
      "\t B OY1 T AH0 N\n",
      "\t K AE1 S IY1\n",
      "Epoch 46: train loss: 0.5303\tassess loss: 0.8241\n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t R IH1 S T R IH0 S T\n",
      "\t M IH1 NG K AH0 L\n",
      "\t P AA1 R B AH0 L OW0\n",
      "\t G R EY1 B\n",
      "\t G R AO1 S K AE2 T ER0 Z\n",
      "Epoch 47: train loss: 0.5317\tassess loss: 0.8261\n",
      "\tGenerated: in train: 7%, assess: 4%, novel: 89%\n",
      "\t AH0 P EY1 M\n",
      "\t P L IY1 N R IY0 M AH0 N\n",
      "\t IH0 F W AA1 N S AH0 M B IY2\n",
      "\t S T R OY1 D M AH0 N S\n",
      "\t T AE1 B Z\n",
      "Epoch 48: train loss: 0.5299\tassess loss: 0.8235\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t HH AA1 L AH0 N\n",
      "\t HH AA1 M T\n",
      "\t N OW0 S EH1 L IY0\n",
      "\t AH1 N D IY0 P IY0 OW2\n",
      "\t T AO1 R N IH0 F\n",
      "Epoch 49: train loss: 0.5308\tassess loss: 0.8249\n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t W AA1 N R AH0 T\n",
      "\t P AY1 N D\n",
      "\t M EY1 D M AH0 N\n",
      "\t N AY1 M W N S T\n",
      "\t T EH1 M T ER0\n",
      "Epoch 50: train loss: 0.5309\tassess loss: 0.8251\n",
      "\tGenerated: in train: 4%, assess: 2%, novel: 94%\n",
      "\t F EY1 Z\n",
      "\t R IH1 D IY0\n",
      "\t R IY0 W UH1 NG T AH0\n",
      "\t L AE1 K CH AH0 N\n",
      "\t S ER1 K AH0 M\n",
      "Epoch 51: train loss: 0.5289\tassess loss: 0.8221\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t AH0 P AA1 G OW0\n",
      "\t B AW1 ER0 JH ER0\n",
      "\t AH0 D AA1 L AH0 N Z\n",
      "\t M IH0 F EH1 L OW0\n",
      "\t HH AA1 D AH0 N T\n",
      "Epoch 52: train loss: 0.5285\tassess loss: 0.8216\n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t S IH1 N T S\n",
      "\t M AA1 K ER0\n",
      "\t SH AA1 F\n",
      "\t IH2 B AH0 W EH1 L D AH0 M\n",
      "\t R AE1 N D AH0 L\n",
      "Epoch 53: train loss: 0.5290\tassess loss: 0.8221\n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t L EY1 F\n",
      "\t B EY2 T W OW0 L EY1\n",
      "\t JH AA1 M\n",
      "\t V AE1 N Z\n",
      "\t K AH0 N UW1\n",
      "Epoch 54: train loss: 0.5288\tassess loss: 0.8219\n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t B EH1 G N AH0 N\n",
      "\t IH0 M AH0 D IH0 V Y UW2 B EY1 T\n",
      "\t B IH1 NG K L AH0 S\n",
      "\t R AY1 AH0 L AY2 T ER0\n",
      "\t B UW1 G AH0 N ER2 N\n",
      "Epoch 55: train loss: 0.5276\tassess loss: 0.8203\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t W AE1 D L AY2 N D ER0\n",
      "\t D OW1 L IH0 NG\n",
      "\t S M OW1 L IH0 NG\n",
      "\t F AY1 IH0 NG\n",
      "\t W AA1 R T L P ER0\n",
      "Epoch 56: train loss: 0.5279\tassess loss: 0.8211\n",
      "\tGenerated: in train: 18%, assess: 4%, novel: 78%\n",
      "\t P R IH1 G AH0 T S\n",
      "\t L IH0 K EY1 N\n",
      "\t D IH0 S K IH1 P T IY0\n",
      "\t R EH0 S T AA1 L IH0 K IY0\n",
      "\t R AY1 ER0\n",
      "Epoch 57: train loss: 0.5276\tassess loss: 0.8203\n",
      "\tGenerated: in train: 19%, assess: 1%, novel: 80%\n",
      "\t N AA1 R K AA2 D\n",
      "\t P AY1 N Z\n",
      "\t S EH1 L Z\n",
      "\t D AH0 K EH1 N IH0\n",
      "\t W EY1 L K AW2 L Z\n",
      "Epoch 58: train loss: 0.5269\tassess loss: 0.8191\n",
      "\tGenerated: in train: 7%, assess: 2%, novel: 91%\n",
      "\t L IY1 ER0\n",
      "\t L AY1 AH0 K OY2 D\n",
      "\t M AE1 N D AH0 M\n",
      "\t SH AA1 K W AE2 K\n",
      "\t L IH1 P IH0 NG\n",
      "Epoch 59: train loss: 0.5269\tassess loss: 0.8192\n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t S K OW1 L M AH0 N\n",
      "\t R IH1 N G OW2\n",
      "\t M EY1 K AH0 N\n",
      "\t B R IH1 N IH0 Z IH0 Z\n",
      "\t D IH1 S D AO1 R IH0 NG\n",
      "Epoch 60: train loss: 0.5268\tassess loss: 0.8191\n",
      "\tGenerated: in train: 7%, assess: 1%, novel: 92%\n",
      "\t M AH0 G AE1 L AH0\n",
      "\t EH1 R IH0 NG\n",
      "\t AA1 N G W AE2 N\n",
      "\t EH1 M P IY0 AH0\n",
      "\t V IH1 N HH AY2 D\n",
      "Epoch 61: train loss: 0.5262\tassess loss: 0.8183\n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t S AH0 P EH0 K S K EH1 L IY0\n",
      "\t JH EH1 K M EH2 K T\n",
      "\t B AE1 S AH0 N\n",
      "\t ER0 K IH1 P T IH0 T AH0 Z Z\n",
      "\t P AH1 L AH0 M\n",
      "Epoch 62: train loss: 0.5268\tassess loss: 0.8194\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t OW1 L ER0\n",
      "\t F IH0 D ER1 M IH0 NG\n",
      "\t K AA0 N EH0 N AA0 IH1 G R OW0\n",
      "\t S IY1 T\n",
      "\t S AE1 L S AH0 M AY2 Z\n",
      "Epoch 63: train loss: 0.5258\tassess loss: 0.8177\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t SH IY1 N OW2 N ER0 Z\n",
      "\t N IH1 K L AH0 F R IH0 Z\n",
      "\t M AH0 M AA1 N AH0 T\n",
      "\t HH AO1 R HH AH0 N AH0 K\n",
      "\t S AW1 M AH0 N R IY0\n",
      "Epoch 64: train loss: 0.5256\tassess loss: 0.8176\n",
      "\tGenerated: in train: 15%, assess: 5%, novel: 80%\n",
      "\t S T AY1 T\n",
      "\t P ER1\n",
      "\t K AH1 M\n",
      "\t B R AY1 M Z\n",
      "\t P AE1 Z IH0 N\n",
      "Epoch 65: train loss: 0.5253\tassess loss: 0.8172\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t P AA2 T IH0 K EH2 R F AH0 N OY1 L IH0 K S\n",
      "\t SH R AE1 P AA2 N\n",
      "\t AW1 JH AH0 D EY2 L\n",
      "\t SH EH1 N T AH0 CH EH0 T\n",
      "\t R IY0 B L OW1 ZH AH0 N Z\n",
      "Epoch 66: train loss: 0.5258\tassess loss: 0.8177\n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t AE1 L K AH0 N\n",
      "\t V AA1 N T IH2 K T\n",
      "\t IH2 N T ER0 AE1 V ER0 IY0 AH0 B AH0 L IH0 Z\n",
      "\t IH0 TH ER0 L IY1 S ER0 D\n",
      "\t M EH1 L ER0 B R N AH0 N\n",
      "Epoch 67: train loss: 0.5257\tassess loss: 0.8177\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t K AE1 NG G AH0 L Z\n",
      "\t K AA0 P IY0 AA1 N IH0 K\n",
      "\t K AO1 T IH0 N\n",
      "\t S EH1 TH ER0 Z\n",
      "\t S UW1 B ER0 B AW0 R\n",
      "Epoch 68: train loss: 0.5256\tassess loss: 0.8176\n",
      "\tGenerated: in train: 18%, assess: 5%, novel: 77%\n",
      "\t S AH0 M AA1 N UW0\n",
      "\t M IH1 N D IY0\n",
      "\t JH AY2 T ER0 IY0 OW0 N IH1 T IY0\n",
      "\t B AH1 M B ER0 TH\n",
      "\t K AH1 M P\n",
      "Epoch 69: train loss: 0.5249\tassess loss: 0.8166\n",
      "\tGenerated: in train: 26%, assess: 3%, novel: 71%\n",
      "\t M EH1 L AH0 F\n",
      "\t IH0 N V AO1 R Z\n",
      "\t D OW1 SH AH0 N\n",
      "\t B IY1 L D Z\n",
      "\t B AH1 Z ER0 V\n",
      "Epoch 70: train loss: 0.5246\tassess loss: 0.8162\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t R IY1 F OW0 Z\n",
      "\t W AO1 D\n",
      "\t K AH1 L AW0 F IH0 V\n",
      "\t IH0 N D EH1 N Y AH0 N D\n",
      "\t D AE1 NG G W ER0 AE2 T\n",
      "Epoch 71: train loss: 0.5251\tassess loss: 0.8168\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t G L AE1 G ER0\n",
      "\t D IH0 F IY1 Z\n",
      "\t EH1 M N IH2 L\n",
      "\t JH IH1 N\n",
      "\t G AE1 N W AE2 CH T\n",
      "Epoch 72: train loss: 0.5241\tassess loss: 0.8153\n",
      "\tGenerated: in train: 6%, assess: 2%, novel: 92%\n",
      "\t D IH0 K AA2 AO1 L OW0\n",
      "\t K AE1 AE2 K T S\n",
      "\t T EH1 N AH0 K AA2 M ER0\n",
      "\t B IH1 R W AA0 D\n",
      "\t N OW0 V AO1 L IY0\n",
      "Epoch 73: train loss: 0.5244\tassess loss: 0.8156\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t K AH0 P AO1 R M B EY2 T IH0 NG\n",
      "\t S AA1 D Z\n",
      "\t SH W EY1 F L AH0 L D\n",
      "\t HH AE1 N Z D\n",
      "\t TH AO1 R SH\n",
      "Epoch 74: train loss: 0.5242\tassess loss: 0.8155\n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t R ER1 T CH IH0 S T\n",
      "\t L EY1 N JH AH0\n",
      "\t B IH0 N AO1 R IH0 K\n",
      "\t K AE1 L AH0 N W AE2 Z AH0 L EY2 T AH0 D\n",
      "\t R IH1 K M AH0 N\n",
      "Epoch 75: train loss: 0.5244\tassess loss: 0.8157\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t L IY1 L IY0\n",
      "\t CH OW1 K Z\n",
      "\t L AE1 N D N AH0 L D\n",
      "\t K OW1 P\n",
      "\t R AE1 Z G R AH0 L\n",
      "Epoch 76: train loss: 0.5232\tassess loss: 0.8142\n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t S K Y UW1 V AH0 L AY2 Z IH0 NG\n",
      "\t D AH0 M IH1 T IY0 OW0\n",
      "\t D AA1 K AH0 L\n",
      "\t HH AA1 R CH N OW2\n",
      "\t D IH1 D AH0 L\n",
      "Epoch 77: train loss: 0.5233\tassess loss: 0.8142\n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t IH0 M ER0 EH1 K AH0 B AH0 L\n",
      "\t B EH1 S AH0 N\n",
      "\t B ER1 N ER0\n",
      "\t HH EH1 L HH AA0\n",
      "\t T R EY1 P HH AW2 N Z\n",
      "Epoch 78: train loss: 0.5234\tassess loss: 0.8144\n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t R OW1 L M AH0 N\n",
      "\t AH1 D M OW0 R F EH2 L\n",
      "\t G AE1 M P R UH2 D Z\n",
      "\t HH AA1 R W IH2 L\n",
      "\t AY1 S T S\n",
      "Epoch 79: train loss: 0.5233\tassess loss: 0.8142\n",
      "\tGenerated: in train: 16%, assess: 3%, novel: 81%\n",
      "\t TH OW1 S IY0\n",
      "\t D IH0 G EY1 D AE0 N\n",
      "\t D EY1 F AH0 K AH0 L Z\n",
      "\t F AH1 K T\n",
      "\t S T EY1 N JH UW0 L AA0 V\n",
      "Epoch 80: train loss: 0.5235\tassess loss: 0.8146\n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t B IH1 N IH0 S\n",
      "\t SH IH1 K AH0 ER0\n",
      "\t P AA1 T IY0\n",
      "\t S AH0 B IY1 N IY0\n",
      "\t TH R UW1 N IH0 D ER0\n",
      "Epoch 81: train loss: 0.5231\tassess loss: 0.8139\n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t EH1 K K AH0 SH AH0 P IH0 NG\n",
      "\t S P AA1 R S IH0 NG\n",
      "\t IH0 L AE1 N HH AH0 N\n",
      "\t AE2 N AH0 L AA1 V ER0 SH IH2 K SH IY0 EY2 D Z\n",
      "\t P AH0 M AY1 D IY0 AH0 M\n",
      "Epoch 82: train loss: 0.5235\tassess loss: 0.8146\n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t P AA1 P AH0 L\n",
      "\t M AH0 K EY1 SH AH0 N Z\n",
      "\t S P ER1 K W EH2 CH AH0 T\n",
      "\t M AO1 R AH0 S AH0 N M AH0 N\n",
      "\t AA1 S T ER0 Z\n",
      "Epoch 83: train loss: 0.5233\tassess loss: 0.8144\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t S K EH1 P TH\n",
      "\t HH AO1 R L AA2 M IH0 NG\n",
      "\t SH UH1 L T S K OW0\n",
      "\t M EH1 G D OY2 CH ER0 Z\n",
      "\t S AA1 OY1 D AH0 F L IY0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: train loss: 0.5232\tassess loss: 0.8144\n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t AH1 N D AH0 L EY2 T IH0 NG\n",
      "\t D ER1 K\n",
      "\t D IY0 B AY1 T\n",
      "\t Y IY1 B AH0 L\n",
      "\t AH0 N B EH1 T S\n",
      "Epoch 85: train loss: 0.5229\tassess loss: 0.8139\n",
      "\tGenerated: in train: 9%, assess: 3%, novel: 88%\n",
      "\t JH OW1 P IH0 D\n",
      "\t HH AW2 M AH0 R EH1 L AH0 D EY2 T AH0 D\n",
      "\t HH AE1 B AH0 L ER0\n",
      "\t B AW1 AH0 N T IH0 M\n",
      "\t V EH1 L OW0\n",
      "Epoch 86: train loss: 0.5236\tassess loss: 0.8147\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t HH EH1 R IY0 Z\n",
      "\t S AH0 N T EY0 S EH1 M\n",
      "\t T AA1 R JH IY0\n",
      "\t AE1 M AY2 AH0 JH IH0 S\n",
      "\t T AH1 F\n",
      "Epoch 87: train loss: 0.5226\tassess loss: 0.8134\n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t HH AO1 R JH S\n",
      "\t L EY1 P IH0 NG\n",
      "\t D R AA2 R G R Y UW1\n",
      "\t F ER1 Z\n",
      "\t M AE1 T ER0\n",
      "Epoch 88: train loss: 0.5221\tassess loss: 0.8126\n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t S AH1 R D\n",
      "\t M AH0 K N OW1 T IH0 D\n",
      "\t B R AY1 ER0\n",
      "\t S EH1 L\n",
      "\t K AO1 R M AH0 N\n",
      "Epoch 89: train loss: 0.5225\tassess loss: 0.8133\n",
      "\tGenerated: in train: 6%, assess: 1%, novel: 93%\n",
      "\t T EH1 M SH ER0\n",
      "\t G AH0 L EY1 V AH0\n",
      "\t K AO1 R AH0 L ER0\n",
      "\t EY2 T S K OW1 G AH0\n",
      "\t IH0 G JH UW0 ER1 K AH0 N AY2 T IH0 NG\n",
      "Epoch 90: train loss: 0.5224\tassess loss: 0.8132\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t HH AE1 N S T W EH2 K T ER0\n",
      "\t P AO1 R M IH0 NG\n",
      "\t IH0 NG K Y IH1 R\n",
      "\t S ER1 L IY0 UW2\n",
      "\t AE2 L OW0 TH AA1 L IH0 S\n",
      "Epoch 91: train loss: 0.5223\tassess loss: 0.8132\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t K IH1 G IY0\n",
      "\t AA1 V ER0 T EH1 N T Z\n",
      "\t SH IH1 S ER0 HH AH2 D TH AH0 N\n",
      "\t T AH1 B M AH0 S\n",
      "\t T AA1 L IH0 G\n",
      "Epoch 92: train loss: 0.5218\tassess loss: 0.8122\n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t R IH0 Z EH1 N D AH0\n",
      "\t K OW0 S EH1 P R AH0\n",
      "\t AO1 R IY0 AH0 B AH0 L\n",
      "\t AE1 TH IY0\n",
      "\t IH1 L HH AH0 S\n",
      "Epoch 93: train loss: 0.5216\tassess loss: 0.8117\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t AA1 T AH0 M IY0 L IH2 N D\n",
      "\t P AW1 N ER0 Z\n",
      "\t F UH1 B M N IY0\n",
      "\t G R IY1 V AH0 N\n",
      "\t P EH1 T M AE2 N S K R AA2 M\n",
      "Epoch 94: train loss: 0.5212\tassess loss: 0.8115\n",
      "\tGenerated: in train: 19%, assess: 1%, novel: 80%\n",
      "\t D AH1 S N ER0\n",
      "\t M ER0 AA1 K R IY0 UW\n",
      "\t S T IH1 L\n",
      "\t L UW0 Z EH1 D IY0\n",
      "\t L AO1 R M IH0 SH AH0\n",
      "Epoch 95: train loss: 0.5213\tassess loss: 0.8117\n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t L AY1 T S EH0 L\n",
      "\t D IH0 S P AY1 K AH0 N AH0 L AY2 Z D\n",
      "\t F IY1\n",
      "\t M AH0 G R AO1 M EH0 CH\n",
      "\t S IY1 G AH0\n",
      "Epoch 96: train loss: 0.5213\tassess loss: 0.8114\n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t K AA1 R V AH0 L M AH0 N\n",
      "\t JH EH1 K IH0 N\n",
      "\t R IY1 B ER0 G Z\n",
      "\t N AH2 M Y UW0 AE0 N D IH1 S T\n",
      "\t T AE1 S\n",
      "Epoch 97: train loss: 0.5210\tassess loss: 0.8111\n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t S OW1 L OW0\n",
      "\t M IH0 S T R ER1 IH0 F UH0 R F\n",
      "\t S AY1 DH ER0 IY0\n",
      "\t M AA0 N B R AA1 N OW0\n",
      "\t K R AH1 IY0 IH0 NG\n",
      "Epoch 98: train loss: 0.5214\tassess loss: 0.8118\n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t G R AE1 TH AH0 N\n",
      "\t D AH0 S EH1 N Z\n",
      "\t B R AA1 M P ER0\n",
      "\t S IH2 S HH IY0 EH0 N S IH0 JH UW0 IH1 N T AH0 L IY0 Z\n",
      "\t HH ER1 B IH0 D AH0\n",
      "Epoch 99: train loss: 0.5221\tassess loss: 0.8128\n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t R IY1 T W IH2 NG K\n",
      "\t K R AE1 S ER0 IH0 NG Z\n",
      "\t M AA1 N T ER0\n",
      "\t L IH0 D IY1 S AH0 N\n",
      "\t B L AA1 R B IY0\n",
      "Epoch 100: train loss: 0.5212\tassess loss: 0.8116\n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t HH AW1 B AH0 N Z\n",
      "\t M ER0 CH AO1 R\n",
      "\t S K AA2 R T EH1 L K OW0\n",
      "\t B UH1 T AH0\n",
      "\t F AA2 L IY0 EY1 S IY0 EY2 T\n",
      "Epoch 101: train loss: 0.5204\tassess loss: 0.8103\n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t G AE1 D IH0 T L IY0\n",
      "\t R AA0 Z AH0 K AH0 L EH1 T IH0 K\n",
      "\t P EY1 Z UH0 L\n",
      "\t F AA1 T S P AA0 R T\n",
      "\t M IH0 T R IH1 N IH0 S\n",
      "Epoch 102: train loss: 0.5216\tassess loss: 0.8119\n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t L AE1 NG K AH0 T AH0 M\n",
      "\t EY1 K AH0 N S IH2 S T\n",
      "\t F ER1 N S AE0 D\n",
      "\t HH EY1\n",
      "\t AE1 K M EH2 S T IH0 F ER0\n",
      "Epoch 103: train loss: 0.5202\tassess loss: 0.8101\n",
      "\tGenerated: in train: 7%, assess: 5%, novel: 88%\n",
      "\t N AO1 F M AH0 N\n",
      "\t W W IY1 N Z\n",
      "\t W IH1 M W AH0 L AE0 T\n",
      "\t N IH0 M ER1 N\n",
      "\t M EH1 L IY1 AH0 D\n",
      "Epoch 104: train loss: 0.5200\tassess loss: 0.8098\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t B AA1 R N Z\n",
      "\t L AA1 T\n",
      "\t K L OW1 AH0 L\n",
      "\t HH UW1 L M AH0 N\n",
      "\t K R AH1 S K AH0 L D\n",
      "Epoch 105: train loss: 0.5202\tassess loss: 0.8101\n",
      "\tGenerated: in train: 17%, assess: 1%, novel: 82%\n",
      "\t F AA1 L M EY2 T\n",
      "\t M ER0 UW1 N IY0\n",
      "\t K B IY1 G AH0 N\n",
      "\t N IY1 L AH0 N\n",
      "\t AE1 M P S AH0 N S\n",
      "Epoch 106: train loss: 0.5207\tassess loss: 0.8109\n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t EH1 TH AH0 D\n",
      "\t IH0 L IH1 S AH0 D EY2 T S\n",
      "\t F IH1 N AH0 N\n",
      "\t B OW1 K AH0 S\n",
      "\t HH OW1 L V AH0 N SH AY2 G\n",
      "Epoch 107: train loss: 0.5206\tassess loss: 0.8104\n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t V EH1 R IH0 NG T AH0 V\n",
      "\t P IH1 N IY0\n",
      "\t R IH1 F K\n",
      "\t IH0 K S P EH1 R AH0 N\n",
      "\t SH UW0 AA1 L IY0\n",
      "Epoch 108: train loss: 0.5211\tassess loss: 0.8115\n",
      "\tGenerated: in train: 17%, assess: 4%, novel: 79%\n",
      "\t V IH0 Z OW1 B AH0\n",
      "\t B AE1 N AH0 K\n",
      "\t T R IH1 DH ER0 Z\n",
      "\t B IY2 G AE1 N Z\n",
      "\t P IH1 N UW0 D\n",
      "Epoch 109: train loss: 0.5205\tassess loss: 0.8104\n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t P AH1 S T\n",
      "\t L AH0 G AO1 R Y AH0 JH ER2 Z IH0 Z\n",
      "\t T ER1 L AH0 N T S\n",
      "\t N OW1 Z IY0 OW0\n",
      "\t M P AY1 N IH0 CH AH0 N\n",
      "Epoch 110: train loss: 0.5198\tassess loss: 0.8096\n",
      "\tGenerated: in train: 12%, assess: 7%, novel: 81%\n",
      "\t K R AO1 L IH0 S M ER0 D\n",
      "\t M AH0 K OW1 N IY0 IY0\n",
      "\t T UH1 SH\n",
      "\t G R AE1 S UW0 D\n",
      "\t AA0 N D S EH1 F L AH0 T\n",
      "Epoch 111: train loss: 0.5198\tassess loss: 0.8096\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t R UW1 TH AY2 N\n",
      "\t S T R AO1 K\n",
      "\t CH EY1 S AH0 N IH0 S\n",
      "\t D AA1 B L R IH0 T\n",
      "\t P R AH0 L EY2 Z M EH1 R IH0 K T\n",
      "Epoch 112: train loss: 0.5207\tassess loss: 0.8108\n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t K L AE1 M M AH0 N\n",
      "\t K AH1 N S ER0 D\n",
      "\t S T R UW1 V IY0 D\n",
      "\t SH AE1 S T AH0 N AY2 Z\n",
      "\t K L AY0 AE1 L AH0\n",
      "Epoch 113: train loss: 0.5203\tassess loss: 0.8106\n",
      "\tGenerated: in train: 15%, assess: 1%, novel: 84%\n",
      "\t IY1 K W IH0 S\n",
      "\t D EY1 N S IH0 NG K Y AH0 V AE2 S T IY0\n",
      "\t S T R AE1 JH AH0 N\n",
      "\t B EY1 D\n",
      "\t B IH1 S T IH0 D\n",
      "Epoch 114: train loss: 0.5193\tassess loss: 0.8090\n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t D EH1 N T N IY0\n",
      "\t P AE2 N D IY1\n",
      "\t HH IH1 NG S T OW2 M AH0 N\n",
      "\t B L UW1 M IH0 N S\n",
      "\t M AH0 K OW1 S\n",
      "Epoch 115: train loss: 0.5198\tassess loss: 0.8097\n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t S OW0 K AA1 P AH0 L AH0 S T\n",
      "\t N OW1 D ER0\n",
      "\t R EH1 N D HH IH0 K AH0 L AY2 Z ER0\n",
      "\t S EH1 L OW0\n",
      "\t P AA1 Z AH0 T\n",
      "Epoch 116: train loss: 0.5196\tassess loss: 0.8094\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t HH AO1 L D UW0 N IH0 NG\n",
      "\t N AA1 N JH AH0\n",
      "\t N UH1 R D Z\n",
      "\t M IH0 S IH0 L EH1 N AH0 JH IY0\n",
      "\t L IH1 F IY0\n",
      "Epoch 117: train loss: 0.5205\tassess loss: 0.8106\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t EH1 N T R OW0 Z\n",
      "\t HH AE1 NG K P AY2 T Z\n",
      "\t EY1 K L EY2 T S\n",
      "\t W UW1 G ER0 Z\n",
      "\t HH OW1 L IH0 K S\n",
      "Epoch 118: train loss: 0.5195\tassess loss: 0.8092\n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t D IY0 V IY1 N\n",
      "\t M AA1 N T IH0 JH\n",
      "\t EH1 M IH2 S\n",
      "\t K AA2 M IY0 L OW1 Z IY0\n",
      "\t P EH1 N F ER0 EY2 T IH0 M\n",
      "Epoch 119: train loss: 0.5192\tassess loss: 0.8088\n",
      "\tGenerated: in train: 10%, assess: 2%, novel: 88%\n",
      "\t S K EY1 S IY0\n",
      "\t F IH1 D AH0 L\n",
      "\t K AH1 V ER0 IH0 NG\n",
      "\t W AE1 N D AH0\n",
      "\t EH1 G S T IH0 NG ER0 Z\n",
      "Epoch 120: train loss: 0.5214\tassess loss: 0.8120\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t P EH1 SH IY0 AH0 N\n",
      "\t AY1 N ER0\n",
      "\t K R AE1 N IY0 AH0\n",
      "\t AE1 K L AH0 N AH0\n",
      "\t W OW1 K L IY0\n",
      "Epoch 121: train loss: 0.5194\tassess loss: 0.8090\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t M AA1 L AH0 S EH0 Z\n",
      "\t K AE1 P ER0\n",
      "\t TH AH0 P UW1 N\n",
      "\t F L IY0 L EY0 G AA1 N OW0\n",
      "\t IH2 N S IY0 K Y UW1 CH IH0 N\n",
      "Epoch 122: train loss: 0.5199\tassess loss: 0.8101\n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t S T EY1 L M AH0 N\n",
      "\t AE1 V ER0 IH0 N T\n",
      "\t G R AE1 N AH0\n",
      "\t OW2 L IH0 K AE1 L IH0 JH\n",
      "\t OW1 K Y UW0 T\n",
      "Epoch 123: train loss: 0.5194\tassess loss: 0.8090\n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t K ER0 AH1 P S AA1 K\n",
      "\t W IH1 P IH0 N\n",
      "\t S AE1 N D R IH0 N\n",
      "\t Y UW1 R IY0 AA1 R S T\n",
      "\t D IH1 K CH IH0 SH\n",
      "Epoch 124: train loss: 0.5190\tassess loss: 0.8086\n",
      "\tGenerated: in train: 15%, assess: 0%, novel: 85%\n",
      "\t IH1 N T R AH0 S\n",
      "\t K AH0 M P AW1 N T\n",
      "\t M AH0 CH IY1 N IH0 NG\n",
      "\t K AW1 NG K AH0 T\n",
      "\t K AA2 R N AA1 D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: train loss: 0.5185\tassess loss: 0.8079\n",
      "\tGenerated: in train: 18%, assess: 3%, novel: 79%\n",
      "\t K AA1 W IY0\n",
      "\t S AE1 M\n",
      "\t F R AE1 K AH0 L\n",
      "\t W EH1 N S IH0 Z\n",
      "\t S T EH1 L CH ER0 Z\n",
      "Epoch 126: train loss: 0.5190\tassess loss: 0.8087\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t F AA1 R D M B OW2 T\n",
      "\t JH EH1 P T AH0 N\n",
      "\t L IH1 K Y AH0 N Z\n",
      "\t V EH1 CH IH0 B OW2 AH0\n",
      "\t R EH1 M B K IH2 T\n",
      "Epoch 127: train loss: 0.5196\tassess loss: 0.8096\n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t B AA1 L ER0\n",
      "\t B ER1 ER0 IY0\n",
      "\t D IH0 M B L UW1 SH AO0\n",
      "\t OW2 G OW0 N T EH2 R IH0 T AH0 G AH1 N JH AH0 L Z\n",
      "\t P R IH0 K AH1 N S IY0\n",
      "Epoch 128: train loss: 0.5190\tassess loss: 0.8087\n",
      "\tGenerated: in train: 18%, assess: 2%, novel: 80%\n",
      "\t K EH1 R IY0\n",
      "\t SH EH2 S T W AH0 Z IH1 K F AH0 L IH0 S\n",
      "\t R IY0 P EH0 K Y UW1 N AH0 L IY0\n",
      "\t AE2 S K AA0 R Z AE1 L IH0 JH IH0 S T\n",
      "\t G OW1 L Y UW2 Z\n",
      "Epoch 129: train loss: 0.5186\tassess loss: 0.8080\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t G ER1 Z AH0 B IH0 M Z\n",
      "\t AY1 D L AY2 N\n",
      "\t R OW1 SH AH0 N\n",
      "\t M OW0 EH1 N T IH0 N IY0\n",
      "\t F R EH2 L AH0 K L AY1 IY0\n",
      "Epoch 130: train loss: 0.5185\tassess loss: 0.8079\n",
      "\tGenerated: in train: 16%, assess: 3%, novel: 81%\n",
      "\t K IH1 M B IY0 AH0 L\n",
      "\t AH0 N K OW1 N ER0\n",
      "\t IH1 N ER0\n",
      "\t AA1 G AA0 L\n",
      "\t B R OW1 TH\n",
      "Epoch 131: train loss: 0.5188\tassess loss: 0.8084\n",
      "\tGenerated: in train: 17%, assess: 1%, novel: 82%\n",
      "\t L V AE1 N S EH0 K\n",
      "\t D AY2 V UH1 R AH0 S L IY0\n",
      "\t AY1 N D IY0\n",
      "\t P L AE1 F\n",
      "\t M AA1 SH IH0 K\n",
      "Epoch 132: train loss: 0.5187\tassess loss: 0.8082\n",
      "\tGenerated: in train: 21%, assess: 3%, novel: 76%\n",
      "\t F R AE1 N D\n",
      "\t G AA1 P AH0 N\n",
      "\t SH IH2 N S IY0 AH0 SH AW1 IY0\n",
      "\t S L EY1 N Z\n",
      "\t F ER1 Z\n",
      "Epoch 133: train loss: 0.5182\tassess loss: 0.8074\n",
      "\tGenerated: in train: 14%, assess: 3%, novel: 83%\n",
      "\t Y OW1 K\n",
      "\t P R IY0 S K UW1 B IH0 S T S\n",
      "\t D UW1 S OW0\n",
      "\t K L UW1 M ER0 Z\n",
      "\t IH0 N D AW1 L D Z\n",
      "Epoch 134: train loss: 0.5201\tassess loss: 0.8101\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t IH0 K S P EH1 R\n",
      "\t EH0 S K AW1 T\n",
      "\t HH EY1 N T L IY0\n",
      "\t S UW1 V D\n",
      "\t IY0 V EY1 K AH0 N\n",
      "Epoch 135: train loss: 0.5181\tassess loss: 0.8072\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t G EH2 R AH0 M AO1 R AH0 M IY0 Z\n",
      "\t OW1 V D\n",
      "\t K EH1 N ER0 S IH0 S\n",
      "\t K IY2 T EY1 N AH2 K S\n",
      "\t B AA1 R T IH0 D\n",
      "Epoch 136: train loss: 0.5177\tassess loss: 0.8065\n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t P AE1 T HH W AA2 M\n",
      "\t F IH1 N D EY0 Z\n",
      "\t HH ER1 S IY0\n",
      "\t B UW1 JH IY0\n",
      "\t AW1 R AH0 N Z\n",
      "Epoch 137: train loss: 0.5185\tassess loss: 0.8077\n",
      "\tGenerated: in train: 18%, assess: 3%, novel: 79%\n",
      "\t R EH1 V AH0 L\n",
      "\t IH0 B S T EH1 L T ER0 N AH0\n",
      "\t D IY2 G L AE1 NG K IH0 V\n",
      "\t N AO1 L F W ER0\n",
      "\t Y UW1 G ER0 IH0 S\n",
      "Epoch 138: train loss: 0.5185\tassess loss: 0.8081\n",
      "\tGenerated: in train: 16%, assess: 3%, novel: 81%\n",
      "\t L AA1 K AH0 K S\n",
      "\t S N AO1 L\n",
      "\t M ER0 L AE1 N S IY0\n",
      "\t P L AE1 TH ER0\n",
      "\t D EH2 JH IH0 T OW1 N EY0\n",
      "Epoch 139: train loss: 0.5185\tassess loss: 0.8079\n",
      "\tGenerated: in train: 20%, assess: 1%, novel: 79%\n",
      "\t SH R AY0 N IH0 S T OY1 L\n",
      "\t EH1 K S T\n",
      "\t IH0 N F EH1 R T M AE2 L IH0 K S\n",
      "\t K R IY1 P ER0 D AY2 Z Z\n",
      "\t T IH1 NG F ER0 EY2 T IH0 NG\n",
      "Epoch 140: train loss: 0.5178\tassess loss: 0.8069\n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t AH0 N EY1 B ER0 D\n",
      "\t S N AA1 V ER0 N\n",
      "\t R AY1 S D EH2 K\n",
      "\t OW0 S EH1 F IH0 CH\n",
      "\t EH1 L B B IY0 AH0 N\n",
      "Epoch 141: train loss: 0.5179\tassess loss: 0.8067\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t R IH1 Z N ER0\n",
      "\t L AA1 M Y\n",
      "\t G UW1 F ER0 D\n",
      "\t EY1 T AH0 N AA0 N\n",
      "\t B AO0 R B EH1 L\n",
      "Epoch 142: train loss: 0.5173\tassess loss: 0.8060\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t B AA1 L IH0 NG ER0\n",
      "\t S EH1 L T IY0 ER0\n",
      "\t D IH0 S T R UW1 V IH0 D\n",
      "\t AA0 S EH1 R OW0\n",
      "\t F EH1 L AH0 S\n",
      "Epoch 143: train loss: 0.5177\tassess loss: 0.8068\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t M AH0 G Z UW1 N AH0 M\n",
      "\t EH0 S T R IH0 L EY1 Z\n",
      "\t D IH0 Z IH1 S T IH0 K S\n",
      "\t AA0 S AH0 T IH1 L AH0 JH IY0\n",
      "\t JH EY0 V IH1 S T IH0 K AH0 L\n",
      "Epoch 144: train loss: 0.5176\tassess loss: 0.8067\n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t AH0 N D R AO1\n",
      "\t K R EH1 N S T\n",
      "\t S L IH1 N CH\n",
      "\t P R EY1 S IH0 D B AE2 K\n",
      "\t D IH0 S P EH1 T S\n",
      "Epoch 145: train loss: 0.5181\tassess loss: 0.8074\n",
      "\tGenerated: in train: 8%, assess: 5%, novel: 87%\n",
      "\t S T EH1 B IH0 L EH0 N\n",
      "\t R IY0 P EY1 L IH0 NG\n",
      "\t F ER1 V\n",
      "\t Y AA1 R AA2\n",
      "\t AH2 N R IH0 SH AA1 N D\n",
      "Epoch 146: train loss: 0.5181\tassess loss: 0.8075\n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t F AA1 R K EY0 S OW2 N\n",
      "\t B IH1 L AH0 K S\n",
      "\t S K AW1 N F EH0 P CH AH0 N\n",
      "\t R IY1 S\n",
      "\t K AE1 V AH0 L\n",
      "Epoch 147: train loss: 0.5175\tassess loss: 0.8064\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t W AA1 N R IH0 K\n",
      "\t AO1 SH\n",
      "\t R AH1 S L ER0\n",
      "\t HH OW1 L AH0 L AY2 Z IH0 NG\n",
      "\t K L EH1 T ER0 D R EH2 K T\n",
      "Epoch 148: train loss: 0.5180\tassess loss: 0.8073\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t D IH0 SH D UW1\n",
      "\t R OW0 M EH1 R IY0\n",
      "\t M AA0 L EH1 S IY0\n",
      "\t M UW1 K R AH0 S T AY2 N\n",
      "\t T AA1 T\n",
      "Epoch 149: train loss: 0.5175\tassess loss: 0.8068\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t W EH1 R IY0 IH0 NG\n",
      "\t EH1 SH M EY1 N\n",
      "\t G EH1 L IH0 HH AH0 L IH2 Z\n",
      "\t P ER0 EH1 SH IH0 P S\n",
      "\t D AW1 AH2 TH ER0\n",
      "Epoch 150: train loss: 0.5176\tassess loss: 0.8066\n",
      "\tGenerated: in train: 9%, assess: 1%, novel: 90%\n",
      "\t M AH0 K AO1 L IY0\n",
      "\t B AA1 R B IH0 N HH AW2 S T AY2 N\n",
      "\t AA1 B UW2 ER0\n",
      "\t S K AW1 N ER0\n",
      "\t K AH0 N IY1 N OW0\n",
      "Epoch 151: train loss: 0.5174\tassess loss: 0.8064\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t D AA0 L AA1 R D Z\n",
      "\t D EH1 M AH0 N AE2 N\n",
      "\t B IH2 F ER0 W IH1 L IH0 K S\n",
      "\t R OW1 B IH0 K HH OW0 L Z\n",
      "\t L AY1 N ER0 Z\n",
      "Epoch 152: train loss: 0.5175\tassess loss: 0.8067\n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t EH1 S IH0 L IH0 N\n",
      "\t HH AE1 L T L AH0 K\n",
      "\t S N IH1 R B UW0\n",
      "\t B L AY1 D IH0 NG\n",
      "\t D IH0 N UW1 N Z\n",
      "Epoch 153: train loss: 0.5165\tassess loss: 0.8052\n",
      "\tGenerated: in train: 13%, assess: 2%, novel: 85%\n",
      "\t B R UW1 P IY0 Z\n",
      "\t G R EH1 NG\n",
      "\t HH EH1 L D IH0 G\n",
      "\t K AA0 D AA1 L OW0\n",
      "\t T R UW1 V ER0\n",
      "Epoch 154: train loss: 0.5170\tassess loss: 0.8058\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t AA1 T AH0 L T AE2 M\n",
      "\t G R AE1 M AH0 S\n",
      "\t HH R IY1 N IH0 NG\n",
      "\t M AA0 L T IY1 N OW0\n",
      "\t D AH0 B AA1 R D AH0 N AH0 Z\n",
      "Epoch 155: train loss: 0.5175\tassess loss: 0.8067\n",
      "\tGenerated: in train: 10%, assess: 5%, novel: 85%\n",
      "\t G AE1 N D B AO2\n",
      "\t B IY0 L IY1\n",
      "\t G EY1 ER0\n",
      "\t M AH0 G AA1 N OW0\n",
      "\t T ER0 V UW1 S T IY0 N\n",
      "Epoch 156: train loss: 0.5175\tassess loss: 0.8066\n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t L IY1 S K R UW2 T S\n",
      "\t N AO1 R B EY2 T ER0\n",
      "\t T AE0 D IY1 N IY0\n",
      "\t T AA1 L Z IH0 Z\n",
      "\t V IY1 Z\n",
      "Epoch 157: train loss: 0.5176\tassess loss: 0.8067\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t G AH1 F B UH2 NG K\n",
      "\t R AE1 N D ER0\n",
      "\t B IY1 V ER0 IY0\n",
      "\t S T AE1 P ER0\n",
      "\t AA2 P ER0 UW0 AO1 AH0\n",
      "Epoch 158: train loss: 0.5173\tassess loss: 0.8064\n",
      "\tGenerated: in train: 7%, assess: 3%, novel: 90%\n",
      "\t L AH1 B IH0 SH T\n",
      "\t HH EY1 S P IH0 L IH0 K ER0 Z\n",
      "\t JH EH1 M P IY0 ER0\n",
      "\t HH AH1 N CH ER0\n",
      "\t CH EH0 R IY0 T AH1 N IH0 CH AH0 N\n",
      "Epoch 159: train loss: 0.5170\tassess loss: 0.8059\n",
      "\tGenerated: in train: 8%, assess: 3%, novel: 89%\n",
      "\t K AA1 CH AH0\n",
      "\t R IH0 S AH1 N JH ER0 IH0 NG\n",
      "\t G IH1 R OW0\n",
      "\t L AA1 R D AH0 N\n",
      "\t W EH2 R IH0 K AA1 N D R IY0\n",
      "Epoch 160: train loss: 0.5171\tassess loss: 0.8062\n",
      "\tGenerated: in train: 6%, assess: 2%, novel: 92%\n",
      "\t R OW2 D R IH0 G UW1 N AH0 T IY0\n",
      "\t D ER1 AH0 N\n",
      "\t AE1 N S IH0 N D B R AA0 K S\n",
      "\t EH1 L B ER0\n",
      "\t Y AA0 R IY0 M IY1 K\n",
      "Epoch 161: train loss: 0.5176\tassess loss: 0.8069\n",
      "\tGenerated: in train: 7%, assess: 4%, novel: 89%\n",
      "\t P AA1 L M EY2\n",
      "\t P R IH1 S T AH0 JH EH0 S T IH0 NG\n",
      "\t P EH2 L AH0 T IY1 N OW0\n",
      "\t L AE1 NG K OW0\n",
      "\t S AH1 NG\n",
      "Epoch 162: train loss: 0.5166\tassess loss: 0.8052\n",
      "\tGenerated: in train: 7%, assess: 0%, novel: 93%\n",
      "\t P ER0 AE1 N Y AH0\n",
      "\t K AH0 B AA1 R D\n",
      "\t L IY1 AH0 N\n",
      "\t S AA1 N T AH0 L EY2 T ER0\n",
      "\t S AE1 D V AH0 N\n",
      "Epoch 163: train loss: 0.5169\tassess loss: 0.8060\n",
      "\tGenerated: in train: 22%, assess: 1%, novel: 77%\n",
      "\t HH AE1 NG K AO2 L\n",
      "\t F AA0 L OW1\n",
      "\t K AE1 K IY0\n",
      "\t B AE1 T ER0 T S\n",
      "\t D AA1 S T IH0 L IH0 S T S\n",
      "Epoch 164: train loss: 0.5166\tassess loss: 0.8054\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t D IH0 S IH1 R OW0\n",
      "\t R EH1 G R IH0 T\n",
      "\t L IH1 T IY0\n",
      "\t R EY0 P ER0 R EH1 S T AH0 S\n",
      "\t L AE1 T AH0 D Z\n",
      "Epoch 165: train loss: 0.5168\tassess loss: 0.8058\n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t F OW1 Z\n",
      "\t D IH2 M ER0 EY1 S IY0 AH0 N Z\n",
      "\t EY1 K AH0 L\n",
      "\t S ER0 EY1 SH AH0 N IY0\n",
      "\t M AO1 R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: train loss: 0.5168\tassess loss: 0.8058\n",
      "\tGenerated: in train: 12%, assess: 5%, novel: 83%\n",
      "\t S AE1 P S\n",
      "\t AE1 L S IH0 N B ER0 G ER0\n",
      "\t T ER1 AH0\n",
      "\t K IY1 Z AE2 N\n",
      "\t P R IY2 Z IY0 Y AH0 S EH1 L ER0 Z\n",
      "Epoch 167: train loss: 0.5168\tassess loss: 0.8059\n",
      "\tGenerated: in train: 15%, assess: 3%, novel: 82%\n",
      "\t K AA0 M EH1 D AH0\n",
      "\t B UW1 Z\n",
      "\t D IH1 K AH0 B ER2 CH D\n",
      "\t AH0 L EH1 R IY0\n",
      "\t IH0 N G R AH1 S IH0 L Z\n",
      "Epoch 168: train loss: 0.5164\tassess loss: 0.8051\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t N UH1 N F ER2 ER0\n",
      "\t P R AA1 M AH0 L\n",
      "\t AE0 K T AE1 M IH0 K S\n",
      "\t M AH0 S IY1 T M AH0 N T\n",
      "\t Y AA2 R IY0 N UW1 T OW0\n",
      "Epoch 169: train loss: 0.5166\tassess loss: 0.8054\n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t CH EY1 N\n",
      "\t B OW1 N IY0\n",
      "\t P AA1 M AH0 N AY0 Z IH0 NG\n",
      "\t AH0 N B AO1 R M IH0 NG\n",
      "\t P IH1 Z AH0 L D Z\n",
      "Epoch 170: train loss: 0.5162\tassess loss: 0.8048\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t HH AE1 D ER0 D\n",
      "\t K L AW1 S T IY0\n",
      "\t D IH2 S K W IY0 ZH OW1 N OW0\n",
      "\t K AE1 L AH0 N AH0 M\n",
      "\t EY0 K IH0 S AO1 AO1 R AH0\n",
      "Epoch 171: train loss: 0.5166\tassess loss: 0.8053\n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t K AE1 N IH0 S AH0 N\n",
      "\t L EH0 M AH0 T UW1 K OW0\n",
      "\t T AY1 D K AY2 P\n",
      "\t F AH1 NG K IH0 S\n",
      "\t B IH1 K ER0 B IY0 AH0 N\n",
      "Epoch 172: train loss: 0.5163\tassess loss: 0.8050\n",
      "\tGenerated: in train: 18%, assess: 3%, novel: 79%\n",
      "\t P R OW0 S EH1 N T AH0 N T L IY0\n",
      "\t HH W EH1 K AO0 R\n",
      "\t W AO1 K S T AY0 D IH2 G\n",
      "\t B IH1 N Y AH0 N CH\n",
      "\t G R EH1 S K R AW0 S T\n",
      "Epoch 173: train loss: 0.5169\tassess loss: 0.8061\n",
      "\tGenerated: in train: 10%, assess: 3%, novel: 87%\n",
      "\t AA0 B R IY2 K IY0 OW0 S EH1 S\n",
      "\t S P AO1 R IY0\n",
      "\t B L IH1 N ER0 D\n",
      "\t D IH0 S K L OW1\n",
      "\t HH UW1 N AH0\n",
      "Epoch 174: train loss: 0.5167\tassess loss: 0.8058\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t R UW0 S AA1 SH IY0 OW0\n",
      "\t K EH0 UW1 ER0 IY0\n",
      "\t P R EH1 B Z\n",
      "\t K ER0 EY1 SH AH0 N\n",
      "\t AW1 D AH0 N IH0 NG\n",
      "Epoch 175: train loss: 0.5160\tassess loss: 0.8045\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t L IH1 K SH AH0 N\n",
      "\t M IH1 CH\n",
      "\t F R IY1 V L IY0\n",
      "\t AH0 P L AE1 N M AH0 N\n",
      "\t S IH1 N S AH0 N D\n",
      "Epoch 176: train loss: 0.5167\tassess loss: 0.8056\n",
      "\tGenerated: in train: 18%, assess: 3%, novel: 79%\n",
      "\t IH0 N OW1 K ER0 Z\n",
      "\t T AY1 SH ER0\n",
      "\t IH1 N D ER0 S UW2 F\n",
      "\t JH EH1 R L IY0\n",
      "\t D OW1 L AH0 K\n",
      "Epoch 177: train loss: 0.5160\tassess loss: 0.8045\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t M AA1 R T S\n",
      "\t D AY1 N T\n",
      "\t K AA0 R IY1 AH0\n",
      "\t P R IH0 M EH1 N D ER0 Z\n",
      "\t JH IH1 R IH0 N\n",
      "Epoch 178: train loss: 0.5167\tassess loss: 0.8056\n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t AH2 N AH0 M T AA1 L AH0 JH IY0\n",
      "\t N IY0 AA1 EY1 V ER0\n",
      "\t B Y AA1 N AH0 S\n",
      "\t EH0 G F ER0 IY1 N AH0\n",
      "\t T EH1 N T R AH0 S\n",
      "Epoch 179: train loss: 0.5163\tassess loss: 0.8048\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t W AO1 T OW0 M P AA2 N D\n",
      "\t K OW0 R AA1 L AH0\n",
      "\t D EY0 ER0 EH1 R\n",
      "\t IH0 K S T R AE1 K SH AH0 S IH0 NG\n",
      "\t S IY1 V IY0\n",
      "Epoch 180: train loss: 0.5172\tassess loss: 0.8063\n",
      "\tGenerated: in train: 21%, assess: 1%, novel: 78%\n",
      "\t B AA1 R L\n",
      "\t D UH1 EH2 K L IY0\n",
      "\t OW0 AA1 R K OW0\n",
      "\t V AH0 HH AE1 L AH0 JH AH0\n",
      "\t D AY0 UW1 L\n",
      "Epoch 181: train loss: 0.5162\tassess loss: 0.8051\n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t Z AA1 N L AA0 L\n",
      "\t S T AE1 T IH0 K S T\n",
      "\t D EH1 M B R OW2 F AY2\n",
      "\t IY0 V AA1 R D IY0 AH0\n",
      "\t R OW1 Z AH0 N\n",
      "Epoch 182: train loss: 0.5162\tassess loss: 0.8047\n",
      "\tGenerated: in train: 16%, assess: 2%, novel: 82%\n",
      "\t B ER1 B IY0\n",
      "\t AE1 Z T ER1 T\n",
      "\t R OW1 B IY0\n",
      "\t P EH1 S T S\n",
      "\t Z UW1 N S AH0 N\n",
      "Epoch 183: train loss: 0.5160\tassess loss: 0.8048\n",
      "\tGenerated: in train: 14%, assess: 5%, novel: 81%\n",
      "\t P AA1 R AH0 T AO2 R IY0\n",
      "\t B AW1 S IH0 S\n",
      "\t D UW1 M\n",
      "\t IH0 N D EH1 L IH0 T AY2 Z\n",
      "\t K R AE1 SH K AW0\n",
      "Epoch 184: train loss: 0.5156\tassess loss: 0.8038\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t AH0 N S IH0 F EH2 N Y AH0 G EY1 SH\n",
      "\t F R AH1 N AH0 M AH0 N S\n",
      "\t IY1 F ER0\n",
      "\t K AE1 N D AH0 N ER0 Z\n",
      "\t K AA0 V OW1 N\n",
      "Epoch 185: train loss: 0.5156\tassess loss: 0.8039\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t K OW1 TH ER0\n",
      "\t P R OW1 M AH0 B AH0 N\n",
      "\t B AA1 R K AA2 R Z\n",
      "\t M AE0 T S K AA1 SH ER0 AY2 T\n",
      "\t D EH1 K ER0\n",
      "Epoch 186: train loss: 0.5158\tassess loss: 0.8044\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t K AO1 L AH0 S\n",
      "\t P OW1 T IY0\n",
      "\t SH AO1 R L AH0 N D\n",
      "\t K AO1 R T AO2 L\n",
      "\t V OW0 L AE1 N AH0\n",
      "Epoch 187: train loss: 0.5156\tassess loss: 0.8039\n",
      "\tGenerated: in train: 5%, assess: 1%, novel: 94%\n",
      "\t CH AY1\n",
      "\t T EY1 B\n",
      "\t IY2 L EH1 K\n",
      "\t K L OW1 N T\n",
      "\t D AA0 M AA0 R IY1 T OW0\n",
      "Epoch 188: train loss: 0.5163\tassess loss: 0.8050\n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t S AH1 D Z\n",
      "\t P ER1 M AH0 N Z\n",
      "\t K EH0 NG L AA0 T EH1 T S K IY0\n",
      "\t D AH1 N S ER0 AW1 T AH0 N S IY0\n",
      "\t V AO1 R IH0 K\n",
      "Epoch 189: train loss: 0.5155\tassess loss: 0.8036\n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t F R AA1 N S K AO0 K\n",
      "\t W IY1 L D AH0 N\n",
      "\t F ER1 V\n",
      "\t K AA1 B IH0 NG\n",
      "\t M AH0 G AE1 N IY0\n",
      "Epoch 190: train loss: 0.5157\tassess loss: 0.8042\n",
      "\tGenerated: in train: 12%, assess: 2%, novel: 86%\n",
      "\t V AY1 S AH0 N\n",
      "\t K L EY1 N IY0\n",
      "\t EH1 N IH0 Z\n",
      "\t P R IH0 S F AY1 T AH0 B AH0 L IY0\n",
      "\t V AE1 M B R IH0 K\n",
      "Epoch 191: train loss: 0.5163\tassess loss: 0.8052\n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t V EY2 L AA0 N AA1 V ER0\n",
      "\t CH IY1 AH0 N\n",
      "\t S T AA1 R K W EH0 N\n",
      "\t HH UW1 DH OW0\n",
      "\t SH AA1 B\n",
      "Epoch 192: train loss: 0.5153\tassess loss: 0.8037\n",
      "\tGenerated: in train: 14%, assess: 1%, novel: 85%\n",
      "\t AE1 R IY0 K AA0 K T\n",
      "\t P ER0 K AA1 N\n",
      "\t K AA1 P M AH0 N\n",
      "\t IH0 K T EY1 L\n",
      "\t B AE1 K L IY0\n",
      "Epoch 193: train loss: 0.5158\tassess loss: 0.8045\n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t F AO1 L AH0\n",
      "\t HH L AY1 W AY2 HH AA2 N\n",
      "\t AA1 R M IH0 G AH0 S\n",
      "\t N IY1 IH0 G R AH0\n",
      "\t P AA1 R SH AH0 P IH0 S T\n",
      "Epoch 194: train loss: 0.5162\tassess loss: 0.8050\n",
      "\tGenerated: in train: 8%, assess: 5%, novel: 87%\n",
      "\t S T AE1 NG G ER0 Z\n",
      "\t OW1 V ER0 D\n",
      "\t AH0 N F AY1 R EY2 T IH0 NG\n",
      "\t S K AW1 M\n",
      "\t F EH1 K AH0\n",
      "Epoch 195: train loss: 0.5158\tassess loss: 0.8042\n",
      "\tGenerated: in train: 8%, assess: 2%, novel: 90%\n",
      "\t IH2 N T ER0 F R AE1 N AH0 T IY0\n",
      "\t F AH0 K W IH1 N T S\n",
      "\t P AA1 P IY0\n",
      "\t P R AA1 P OW0\n",
      "\t K Y AA1 R EH1 L\n",
      "Epoch 196: train loss: 0.5160\tassess loss: 0.8048\n",
      "\tGenerated: in train: 13%, assess: 1%, novel: 86%\n",
      "\t R AE1 K SH AH0 M\n",
      "\t M OW0 D AA1 K S IY0 AH0 Z\n",
      "\t AO2 R N OW0 S EH1 V IH0 T S\n",
      "\t W OY0 OW0 D IY1 N AH0\n",
      "\t K AA2 D AH0 T AH0 L AH0 M AE1 N IH0 NG\n",
      "Epoch 197: train loss: 0.5156\tassess loss: 0.8040\n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t P IH0 R AY0 T EY1\n",
      "\t SH OW1 B\n",
      "\t P OW1 T IH0 NG\n",
      "\t B W EY1 B D\n",
      "\t M AO1 R L ER0 Z\n",
      "Epoch 198: train loss: 0.5159\tassess loss: 0.8045\n",
      "\tGenerated: in train: 12%, assess: 0%, novel: 88%\n",
      "\t P IH1 T Z ER0 IY0\n",
      "\t R AH1 R ER0 EH1 L\n",
      "\t IH0 N S IH0 Z AA1 N D\n",
      "\t B IH0 L IY1 D EY0\n",
      "\t D AA1 F S M AH0 N\n",
      "Epoch 199: train loss: 0.5165\tassess loss: 0.8058\n",
      "\tGenerated: in train: 11%, assess: 3%, novel: 86%\n",
      "\t D AE1 NG S T AH0 D\n",
      "\t EH1 D M AH0 N\n",
      "\t L AY1 B\n",
      "\t EH0 M P AA1 Y AH0\n",
      "\t S AH0 K W IH1 S S\n",
      "Epoch 200: train loss: 0.5154\tassess loss: 0.8040\n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t G AO1 Z\n",
      "\t EY1 L AH0 N\n",
      "\t K L AY1 AH0 N ER0\n",
      "\t CH EH1 F T\n",
      "\t G R IY1 D IH0 NG\n",
      "Epoch 201: train loss: 0.5160\tassess loss: 0.8046\n",
      "\tGenerated: in train: 13%, assess: 3%, novel: 84%\n",
      "\t T TH IH1 NG K S\n",
      "\t F ER0 S T EY1 N AH0 Z\n",
      "\t B ER1 G R OW0 IY0 N\n",
      "\t G AE1 SH\n",
      "\t T AA0 NG G IY1 D AH0 N AO0 R IY0\n",
      "Epoch 202: train loss: 0.5168\tassess loss: 0.8060\n",
      "\tGenerated: in train: 11%, assess: 0%, novel: 89%\n",
      "\t M AA1 D L AH0 S AH0 N\n",
      "\t P EY1 T EH0 S T\n",
      "\t AO0 D AA1 R S AH0 T IY0 Z\n",
      "\t D IH0 V OW1 N AH0 S IY0\n",
      "\t Y AH1 S T M AH0 N\n",
      "Epoch 203: train loss: 0.5152\tassess loss: 0.8035\n",
      "\tGenerated: in train: 8%, assess: 1%, novel: 91%\n",
      "\t JH ER0 N IY1\n",
      "\t W IH2 S IH0 N F AA1 L AH0 F IY0\n",
      "\t V AH1 N JH AH0 N D\n",
      "\t M AY1 B ER0\n",
      "\t CH AA0 K S AA1 R OW0\n",
      "Epoch 204: train loss: 0.5156\tassess loss: 0.8042\n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t B AA1 G AH0 L D\n",
      "\t G AO1 R AH0\n",
      "\t N UW1 N F IY2\n",
      "\t HH OW1 V Z\n",
      "\t M EY1 L B R UH0 K\n",
      "Epoch 205: train loss: 0.5159\tassess loss: 0.8048\n",
      "\tGenerated: in train: 16%, assess: 0%, novel: 84%\n",
      "\t EH0 L Y AA1 NG\n",
      "\t L UW1 V IH0 NG\n",
      "\t N AO1 R AH0 N ER0\n",
      "\t JH AA1 B Y AH0 N\n",
      "\t B AA0 L S T AA0 R OW1 N IY0\n",
      "Epoch 206: train loss: 0.5154\tassess loss: 0.8038\n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t K R OW1 N OW0\n",
      "\t T AH1 CH N IY0\n",
      "\t IH1 N K ER0 OW0 Z\n",
      "\t L EY1 CH M AH0 N\n",
      "\t M EY1 JH ER0 Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: train loss: 0.5154\tassess loss: 0.8038\n",
      "\tGenerated: in train: 9%, assess: 0%, novel: 91%\n",
      "\t K AA2 CH IY0 AA1 SH AH0\n",
      "\t S UH0 R P AA1 L OW0\n",
      "\t IH0 L IH1 T AH0 B AH0 L\n",
      "\t K Y OW1 N Y AH0\n",
      "\t L AE1 S K AH0 N D TH\n",
      "Epoch 208: train loss: 0.5152\tassess loss: 0.8036\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t W OW1 K AH0 M\n",
      "\t EY1 G HH EY2 L D Z\n",
      "\t B EH1 N AH0 G EH2 S T S\n",
      "\t F L IY0 AA1 T AH0 K\n",
      "\t P ER1 K L AW2 IH0 NG\n",
      "Epoch 209: train loss: 0.5152\tassess loss: 0.8036\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t L AA0 N T AA1 N D\n",
      "\t Y UW2 L AH0 Z EH1 L\n",
      "\t HH OW1 K IY0\n",
      "\t SH OW1 K ER0\n",
      "\t F EY1 T S\n",
      "Epoch 210: train loss: 0.5165\tassess loss: 0.8058\n",
      "\tGenerated: in train: 18%, assess: 2%, novel: 80%\n",
      "\t M EY1 DH D IH0 NG\n",
      "\t T EY1 D IH0 NG\n",
      "\t P IH0 K AE1 N T IH0 NG\n",
      "\t AE1 M AH0 L ER0\n",
      "\t K ER0 M AA1 N IH0 S T\n",
      "Epoch 211: train loss: 0.5156\tassess loss: 0.8040\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t L EY1 D ER0 L IY0\n",
      "\t V ZH IY1 D AH0 N\n",
      "\t K AH1 D ER0 Z\n",
      "\t G R EY1 N\n",
      "\t G AH0 L OW1\n",
      "Epoch 212: train loss: 0.5157\tassess loss: 0.8046\n",
      "\tGenerated: in train: 17%, assess: 0%, novel: 83%\n",
      "\t D AE1 N B AE0 K\n",
      "\t IH0 K IY1 M IH0 NG\n",
      "\t K IH1 K\n",
      "\t V IH1 K AH0 L\n",
      "\t W OW1 K ER0\n",
      "Epoch 213: train loss: 0.5151\tassess loss: 0.8035\n",
      "\tGenerated: in train: 14%, assess: 0%, novel: 86%\n",
      "\t P AA2 R IH0 B R IY0 EY1 T AH0 V EY2 T IH0 D\n",
      "\t N UW1 B HH AO2 R D\n",
      "\t B AO1 W AH0\n",
      "\t S AH1 B AH0 L IY0\n",
      "\t EY1 SH OW0\n",
      "Epoch 214: train loss: 0.5155\tassess loss: 0.8041\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t K W IY0 S T AE2 AH2 L Z\n",
      "\t M AH0 G L OW1 AH0 N\n",
      "\t K Y UW1 M AH0 N\n",
      "\t N IY1 V IH0 NG\n",
      "\t F IY0 T AA1 N IY0\n",
      "Epoch 215: train loss: 0.5148\tassess loss: 0.8031\n",
      "\tGenerated: in train: 17%, assess: 3%, novel: 80%\n",
      "\t AE1 T AH0 CH EH0 K S\n",
      "\t F AH1 N D\n",
      "\t L AH1 S D AH0 N\n",
      "\t M AA0 K S AA1 L AH0 P IH0 S\n",
      "\t AH0 L AY1 AA0 T\n",
      "Epoch 216: train loss: 0.5156\tassess loss: 0.8046\n",
      "\tGenerated: in train: 12%, assess: 1%, novel: 87%\n",
      "\t T AE1 D IH0 L Y UW2 D\n",
      "\t JH AA0 Z AA1 D AH0\n",
      "\t T IY1 L D\n",
      "\t S M IH1 T IH0 D ER0\n",
      "\t P R EH1 TH IH0 K AH0 L\n",
      "Epoch 217: train loss: 0.5154\tassess loss: 0.8042\n",
      "\tGenerated: in train: 11%, assess: 2%, novel: 87%\n",
      "\t T UH1 L P IY0\n",
      "\t V AY1 AH0 N\n",
      "\t B ER1 G L IY0\n",
      "\t D EH1 S T IH0 K AH0 L\n",
      "\t M OW0 AE1 T S K IY0 AH0 N S EY1 IY0 AH0 N\n",
      "Epoch 218: train loss: 0.5147\tassess loss: 0.8029\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t EY2 L EY1 N AH0\n",
      "\t M IH1 M B L N\n",
      "\t K OW1 Z AH0 N ER0\n",
      "\t S AY1 IY0 ER0\n",
      "\t R AA1 P K OW0\n",
      "Epoch 219: train loss: 0.5152\tassess loss: 0.8037\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t N IH1 B AH0 L\n",
      "\t K AH0 M AY1 N S K OW0\n",
      "\t S UW1 M ER0\n",
      "\t TH EH2 P ER0 AH0 L EY1 SH AH0 N\n",
      "\t S AA1 L IH0 NG Z\n",
      "Epoch 220: train loss: 0.5145\tassess loss: 0.8026\n",
      "\tGenerated: in train: 18%, assess: 1%, novel: 81%\n",
      "\t D AY1 D ER0 M OW0 N\n",
      "\t D EH1 V AH2 N\n",
      "\t HH AE1 B\n",
      "\t S T IH1 P IH0 NG\n",
      "\t M UW2 B AA2 R L AH0 AA0 DH\n",
      "Epoch 221: train loss: 0.5151\tassess loss: 0.8035\n",
      "\tGenerated: in train: 19%, assess: 2%, novel: 79%\n",
      "\t N UW1\n",
      "\t R ER1 AE1 SH S\n",
      "\t N EH2 L UW0 OW0 HH IY0 AH0 N T AE1 N D IH0 D\n",
      "\t HH EH1 N D IY0\n",
      "\t JH UW1\n",
      "Epoch 222: train loss: 0.5147\tassess loss: 0.8030\n",
      "\tGenerated: in train: 16%, assess: 1%, novel: 83%\n",
      "\t P AA1 L AH0 L\n",
      "\t B EH1 V AH0 L\n",
      "\t L AH1 B D S T R EY2 T S\n",
      "\t T R AE1 D AH0 N T\n",
      "\t R IY1 JH AH0 Z\n",
      "Epoch 223: train loss: 0.5152\tassess loss: 0.8037\n",
      "\tGenerated: in train: 9%, assess: 2%, novel: 89%\n",
      "\t Y AH0 N IH0 K AA1 N OW0\n",
      "\t K AA2 SH P ER0 P AA1 L AH0 T AH0 S AY2 Z D\n",
      "\t IH0 N S T AE1 DH ER0 AH0\n",
      "\t M AA0 G AA0 AO1 L AH0 IH0 K\n",
      "\t B Y ER0 IH1 K Y AH0 L AH0 S L IY0\n",
      "Epoch 224: train loss: 0.5153\tassess loss: 0.8041\n",
      "\tGenerated: in train: 15%, assess: 2%, novel: 83%\n",
      "\t D IH0 S P IH1 S T R IY0 AH0 L\n",
      "\t K L AH1 P\n",
      "\t EY1 V ER0 EH1 L IY0\n",
      "\t L AY1 B ER0\n",
      "\t R IH1 M AH0 N D\n",
      "Epoch 225: train loss: 0.5149\tassess loss: 0.8033\n",
      "\tGenerated: in train: 11%, assess: 1%, novel: 88%\n",
      "\t AW1\n",
      "\t D AY1 F UH1 R\n",
      "\t IH2 N T ER0 AW1 L AH0 M AH0 N T\n",
      "\t M AE1 K F AA0 R JH ER0\n",
      "\t M EH1 S T\n",
      "Epoch 226: train loss: 0.5158\tassess loss: 0.8042\n",
      "\tGenerated: in train: 10%, assess: 1%, novel: 89%\n",
      "\t AW1 AH0 M S T IY0 N Z\n",
      "\t D OY1 ER0\n",
      "\t S N UW1 M\n",
      "\t Y UW1 R IH0 K\n",
      "\t N IH1 B D AH0 N\n",
      "Epoch 227: train loss: 0.5146\tassess loss: 0.8028\n",
      "\tGenerated: in train: 17%, assess: 2%, novel: 81%\n",
      "\t R EH2 CH ER0 AH0 K T EH1 ZH IY0 AH0\n",
      "\t AA1 M AH0 L IH0 NG\n",
      "\t HH AE1 T W AY2 CH\n",
      "\t D UH1 V R IH0 N\n",
      "\t S AH1 M IH0 N\n",
      "Epoch 228: train loss: 0.5146\tassess loss: 0.8030\n",
      "\tGenerated: in train: 19%, assess: 2%, novel: 79%\n",
      "\t W AO1 B IH0 SH\n",
      "\t SH UH1 R IY0 Z\n",
      "\t K L UW1 S\n",
      "\t S P EH1 R AH0 L IH0 S\n",
      "\t R IY0 K AE1 SH AH0 N T\n",
      "Epoch 229: train loss: 0.5143\tassess loss: 0.8024\n",
      "\tGenerated: in train: 14%, assess: 2%, novel: 84%\n",
      "\t S W IH1 L AH0 N\n",
      "\t D AE1 S L IH0 NG\n",
      "\t S T R AY1 IY1\n",
      "\t K OW1 N IY0\n",
      "\t D IH0 EY1 K IH0 CH AH0 Z\n",
      "Epoch 230: train loss: 0.5148\tassess loss: 0.8034\n",
      "\tGenerated: in train: 13%, assess: 0%, novel: 87%\n",
      "\t K AE1 S M AH0 N\n",
      "\t S OW2 N AA0 G R OW0 N JH IY0 OW1 N IY0 OW0\n",
      "\t AE1 M B ER0 AH0 N S\n",
      "\t D AY2 AE1 N IY0 AH0 T AO2 R IY0\n",
      "\t HH EY1 CH IY0\n",
      "Epoch 231: train loss: 0.5149\tassess loss: 0.8033\n",
      "\tGenerated: in train: 12%, assess: 3%, novel: 85%\n",
      "\t S AY2 T S AH0 D\n",
      "\t P AW1 N S N AH0 T\n",
      "\t W EH1 S K IY0\n",
      "\t R AA0 K S OW1 D\n",
      "\t R AA1 F L IH0 NG\n",
      "Epoch 232: train loss: 0.5159\tassess loss: 0.8051\n",
      "\tGenerated: in train: 10%, assess: 0%, novel: 90%\n",
      "\t B R AE1 Z Z IH0 S S\n",
      "\t AY1 L HH UW1\n",
      "\t P ER1 L IY0\n",
      "\t S AE1 M AH0 T S\n",
      "\t F AA0 S AO0 F AA1 R M AH0\n",
      "CPU times: user 35min 16s, sys: 4min 54s, total: 40min 11s\n",
      "Wall time: 38min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping because of no decrease in 3 epochs.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cuda', rnn_type='gru',\n",
    "    embedding_dimension=20, hidden_dimension=100, num_layers=3,\n",
    "    max_epochs=2000, early_stopping_rounds=3,\n",
    "    lr=1e-3, batch_size=1024, l2_strength=1e-4\n",
    ")\n",
    "\n",
    "\n",
    "train_loss, dev_loss = lm.fit(train_df.pronunciation.values.tolist(), dev_df.pronunciation.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fit a model that gets train and validation loss to about .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('dev_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = models_df.groupby(['batch_size', 'lr'])\n",
    "\n",
    "columns = 3\n",
    "rows = int(math.ceil(len(g) / columns))\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(20, 10), sharey=True)\n",
    "for idx, ((embedding_dimension, rnn_hidden_dimension), t) in enumerate(g):\n",
    "    row, column = divmod(idx, columns)\n",
    "    ax = axs[row][column]\n",
    "    t.set_index('epoch').dev_loss.plot(ax=ax)\n",
    "    t.set_index('epoch').train_loss.plot(ax=ax)\n",
    "    ax.set_title(f'batch_size={embedding_dimension}, lr={rnn_hidden_dimension}')\n",
    "    plt.tight_layout()\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_df.batch_size.unique())\n",
    "print(models_df.lr.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df[models_df.batch_size==16384].sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, batch_size, lr):\n",
    "    t = models_df[(models_df.batch_size==batch_size) & (models_df.lr==lr)].set_index('epoch')\n",
    "    t.train_loss.plot()\n",
    "    t.dev_loss.plot()\n",
    "plot(df, 1024, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 minutes for 16 models. 4 minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'embedding_dimension': [20, 50, 100, 200],\n",
    "    'rnn_hidden_dimension': [50, 100, 200, 400],\n",
    "    'num_layers': [1, 2, 3],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    lm = PhonemeLM(\n",
    "        phoneme_to_idx, rnn_type='gru', device='cuda', batch_size=1024,\n",
    "        max_epochs=2000, early_stopping_rounds=3, **params\n",
    "    )\n",
    "    print('Model Params:', params)\n",
    "    train_losses, dev_losses = lm.fit(train_df.pronunciation.values.tolist(), dev_df.pronunciation.values.tolist())\n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.embedding_dimension.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)\n",
    "models_df.sort_values('dev_loss')\n",
    "t = models_df[(models_df.embedding_dimension==10) & (models_df.rnn_hidden_dimension==200)]\n",
    "t.set_index('epoch').train_loss.plot()\n",
    "t.set_index('epoch').dev_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'rnn_type': ['gru'],\n",
    "#     'embedding_dimension': [10, 100, 400],\n",
    "#     'rnn_hidden_dimension': [50, 200, 400],\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=3)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu',\n",
    "    rnn_type='gru', embedding_dimension=10, rnn_hidden_dimension=20,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, max_epochs=5, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = torch.load('lm_1.pt', map_location=torch.device('cpu'))\n",
    "lm.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Real Words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['probability'] = df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('probability', ascending=False, inplace=True)\n",
    "df.probability.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = train_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))\n",
    "da = dev_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.mean(), da.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = lm8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Pronunciations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'with'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'tomato'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word=='pajamas'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'february'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.word.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IY1', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S', 'T', 'R', 'UW1', 'Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PRONUNCIATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    pronunciation = lm.generate(100, temperature=None)\n",
    "    pronunciation_string = ' '.join(pronunciation)\n",
    "    matches = df[df.pronunciation_string == pronunciation_string]\n",
    "    \n",
    "    print(pronunciation_string)\n",
    "    if len(matches) > 0:\n",
    "        print('\\t', matches.iloc[0]['word'], len(matches), 'total')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of Next ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation = ['CH', 'EH0', 'N', 'V', 'AY2', 'R', 'AH0', 'N', 'M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['S', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "pronunciation = ['F', 'EH1', 'B', 'Y', 'AH0']\n",
    "\n",
    "\n",
    "next_probs = lm.next_probabilities(pronunciation)\n",
    "\n",
    "for phoneme, probability in sorted(next_probs.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{probability:.4f}] {phoneme}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_next(lm, pronunciation):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_pronunciation(['S'], lm.phoneme_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lm, 'lm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_phonemes(lm, embedding, topn=10):\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(lm.embedding_for(phoneme), embedding).item()\n",
    "        for phoneme in phoneme_to_idx\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(lm, lm.embedding_for('DH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = lm.embeddings\n",
    "# embeddings = lm.embedding.weight.cpu().detach().numpy()\n",
    "normed_embeddings = normalize(embeddings)\n",
    "\n",
    "num_clusters = 15\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(normed_embeddings)\n",
    "\n",
    "grouped = defaultdict(set)\n",
    "for idx, label in enumerate(kmeans.labels_):\n",
    "    phoneme = lm.vocab[idx]\n",
    "    grouped[label].add(phoneme)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consonants\n",
    "# - voicing\n",
    "# - place: bilabial, dental, alveolar, palatal, velar\n",
    "# - manner: stop, fricative, nasal\n",
    "\n",
    "# For vowels\n",
    "# - front/back\n",
    "# - closed/open\n",
    "# - rounding\n",
    "\n",
    "# General\n",
    "# - syllabic\n",
    "\n",
    "# TODO: combine multiple vectors together, e.g. {B, G, V, DH, D} for voiced\n",
    "voicing = lm.embedding_for('B') - lm.embedding_for('P')\n",
    "forwarding = lm.embedding_for('P') - lm.embedding_for('K')\n",
    "frication = lm.embedding_for('F') - lm.embedding_for('P')\n",
    "\n",
    "# new = lm.embedding_for('TH') + voicing\n",
    "new = lm.embedding_for('K') + voicing\n",
    "# new = lm.embedding_for('T') + frication\n",
    "# new = lm.embedding_for('G') + forwarding\n",
    "\n",
    "phoneme_to_sim = {}\n",
    "for phoneme in phoneme_to_idx:\n",
    "    this_embs = lm.embedding_for(phoneme)\n",
    "    sim = cosine_similarity(new, this_embs).item()\n",
    "    phoneme_to_sim[phoneme] = sim\n",
    "\n",
    "sorted(phoneme_to_sim.items(), key=lambda p: -p[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.mean([embedding_for('B'), embedding_for('V')], axis=0)\n",
    "voiced = np.mean([lm.embedding_for(phoneme) for phoneme in ['B', 'V', 'G', 'Z', 'ZH', 'DH', 'JH']], axis=0)\n",
    "voiceless = np.mean([lm.embedding_for(phoneme) for phoneme in ['P', 'F', 'K', 'S', 'SH', 'TH', 'CH']], axis=0)\n",
    "voicing = voiced - voiceless\n",
    "most_similar_phonemes(lm, voicing + lm.embedding_for('S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_phonemes(lm, voicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START, END, PAD\n",
    "def analogy(lm, a, b, c):\n",
    "    \"\"\"\n",
    "    a - b = c - w\n",
    "    argmax(w) over sim(w, c - a + b)\n",
    "    \"\"\"\n",
    "    emb_a = lm.embedding_for(a)\n",
    "    emb_b = lm.embedding_for(b)\n",
    "    emb_c = lm.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = set(lm.vocab) - {START, END, PAD}\n",
    "    \n",
    "    phoneme_to_sim = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb_p = lm.embedding_for(phoneme)\n",
    "        sim = cosine_similarity(emb_p, emb_c - emb_a + emb_b)\n",
    "        phoneme_to_sim[phoneme] = sim.item()\n",
    "    return phoneme_to_sim\n",
    "\n",
    "analogies = analogy(lm, 'P', 'K', 'B')\n",
    "for phoneme, sim in sorted(analogies.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{sim:.4f}] {phoneme}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START\n",
    "phoneme_idx = lm.phoneme_to_idx[START]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden_state = lm(torch.LongTensor([phoneme_idx]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros(1, 1, 10)\n",
    "\n",
    "lm(torch.LongTensor([phoneme_idx]).unsqueeze(0), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
