{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from phoneme_lm import PhonemeLM, build_data_loader, build_vocab, encode_pronunciation\n",
    "from utils import load_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_idx, idx_to_phoneme = build_vocab(df.pronunciation.values)\n",
    "df['phoneme_ids'] = df.pronunciation.apply(lambda pronunciation: encode_pronunciation(pronunciation, phoneme_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pronunciation_string'] = df.pronunciation.apply(' '.join)\n",
    "df['length'] = df.pronunciation.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = split_data(df, dev_proportion=.2, test_proportion=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 25000, 1250)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 3.0435\tassess loss: 3.0000\n",
      "\t SH EY1 IH2 S AW0 N AO2 OW2 SH UW0\n",
      "\t EH2 UW1 AY0 ZH EH1 IH2 AA1 UW0 AY1 S\n",
      "\t AA0 EH1 AY1 UW1 AO2 W <PAD> AY0 UW0 Y\n",
      "\t V IY0 M\n",
      "\t AE0 ER0 EY2 D L EY1 AH2 Z AW0 AY1\n",
      "Epoch 2: train loss: 1.9270\tassess loss: 1.8589\n",
      "\t L AE1 S <PAD> <PAD> UW0 <PAD> OY0 <PAD> <PAD>\n",
      "\t EY1 F\n",
      "\t V AA2 <PAD> <W> N AA0 AH0 UH2 <PAD> AH2\n",
      "\t B TH DH IH0 G <PAD> AA0 <PAD> K DH\n",
      "\t ER2 EY1 OW1 R AH0 EY2 HH G <PAD> AA1\n",
      "Epoch 3: train loss: 1.6919\tassess loss: 1.6234\n",
      "\t UH1 UH1 JH\n",
      "\t TH OW1 AO2 AH2 EY0 L\n",
      "\t <PAD> <PAD> DH <PAD> AW2 <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t AH1 JH AO2 UH1 <PAD> <PAD> AO0 <PAD> <PAD> <PAD>\n",
      "\t AA0 B T AH0 L <PAD> <PAD>\n",
      "Epoch 4: train loss: 1.6028\tassess loss: 1.5379\n",
      "\t AA2 G IY0 L AY1 <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t V <PAD> <PAD> <PAD> T <PAD> <PAD> <PAD> D <PAD>\n",
      "\t AO2 W B <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> EH0\n",
      "\t AA1 K AH2 EH0\n",
      "\t ER1 W IH0 AA1 T AH1\n",
      "Epoch 5: train loss: 1.5318\tassess loss: 1.4680\n",
      "\t \n",
      "\t AH2 UW IH2\n",
      "\t OW1\n",
      "\t <PAD> M AO1\n",
      "\t W AW2 AY2 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "CPU times: user 2min 6s, sys: 3.41 s, total: 2min 10s\n",
      "Wall time: 24.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.04351806640625,\n",
       "  1.9269580841064453,\n",
       "  1.691948652267456,\n",
       "  1.6028156280517578,\n",
       "  1.5318052768707275],\n",
       " [3.0000243186950684,\n",
       "  1.8588536977767944,\n",
       "  1.6234431266784668,\n",
       "  1.5378538370132446,\n",
       "  1.4680312871932983])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu',\n",
    "    rnn_type='gru', embedding_dimension=5, rnn_hidden_dimension=20,\n",
    "    max_epochs=5\n",
    ")\n",
    "\n",
    "lm.fit(train_df.pronunciation[:10000], dev_df.pronunciation, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 minutes for 16 models. 4 minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'rnn_type': ['gru'],\n",
    "    'embedding_dimension': [10, 50, 100, 200],\n",
    "    'rnn_hidden_dimension': [50, 100, 200, 400],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "    print('Model Params:', params)\n",
    "    train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)\n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.embedding_dimension.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)\n",
    "models_df.sort_values('dev_loss')\n",
    "t = models_df[(models_df.embedding_dimension==10) & (models_df.rnn_hidden_dimension==200)]\n",
    "t.set_index('epoch').train_loss.plot()\n",
    "t.set_index('epoch').dev_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'rnn_type': ['gru'],\n",
    "    'embedding_dimension': [10, 100, 400],\n",
    "    'rnn_hidden_dimension': [50, 200, 400],\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in tqdm(param_grid):\n",
    "    lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "    print('Model Params:', params)\n",
    "    train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=3)\n",
    "    for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "        record = params.copy()\n",
    "        record['epoch'] = epoch\n",
    "        record['train_loss'] = train_loss\n",
    "        record['dev_loss'] = dev_loss\n",
    "    \n",
    "        records.append(record)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = models_df.groupby(['embedding_dimension', 'rnn_hidden_dimension'])\n",
    "\n",
    "columns = 3\n",
    "rows = int(math.ceil(len(g) / columns))\n",
    "fig, axs = plt.subplots(columns, rows, figsize=(15, 10), sharey=True)\n",
    "for idx, ((embedding_dimension, rnn_hidden_dimension), t) in enumerate(g):\n",
    "    row, column = divmod(idx, columns)\n",
    "    ax = axs[row][column]\n",
    "    t.set_index('epoch').dev_loss.plot(ax=ax)\n",
    "    t.set_index('epoch').train_loss.plot(ax=ax)\n",
    "    ax.set_title(f'embed dim={embedding_dimension}, hidden={rnn_hidden_dimension}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu',\n",
    "    rnn_type='gru', embedding_dimension=10, rnn_hidden_dimension=20,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, max_epochs=5, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Real Words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['probability'] = df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('probability', ascending=False, inplace=True)\n",
    "df.probability.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = train_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))\n",
    "da = dev_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.mean(), da.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Pronunciations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'with'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'tomato'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word=='pajamas'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PRONUNCIATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    pronunciation = lm.generate(100, temperature=None)\n",
    "    pronunciation_string = ' '.join(pronunciation)\n",
    "    matches = df[df.pronunciation_string == pronunciation_string]\n",
    "    \n",
    "    print(pronunciation_string)\n",
    "    if len(matches) > 0:\n",
    "        print('\\t', matches.iloc[0]['word'], len(matches), 'total')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = lm.embedding_for('UW')\n",
    "v = lm.embedding_for('V')\n",
    "cosine_similarity(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def most_similar_phonemes(lm, embedding, topn=10):\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(lm.embedding_for(phoneme), embedding).item()\n",
    "        for phoneme in phoneme_to_idx\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        if other_phoneme != phoneme:\n",
    "            print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(lm, lm.embedding_for('V'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = lm.embeddings\n",
    "# embeddings = lm.embedding.weight.cpu().detach().numpy()\n",
    "normed_embeddings = normalize(embeddings)\n",
    "\n",
    "num_clusters = 15\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(normed_embeddings)\n",
    "\n",
    "grouped = defaultdict(set)\n",
    "for idx, label in enumerate(kmeans.labels_):\n",
    "    phoneme = lm.vocab[idx]\n",
    "    grouped[label].add(phoneme)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('word').loc['fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consonants\n",
    "# - voicing\n",
    "# - place: bilabial, dental, alveolar, palatal, velar\n",
    "# - manner: stop, fricative, nasal\n",
    "\n",
    "# For vowels\n",
    "# - front/back\n",
    "# - closed/open\n",
    "# - rounding\n",
    "\n",
    "# General\n",
    "# - syllabic\n",
    "\n",
    "# TODO: combine multiple vectors together, e.g. {B, G, V, DH, D} for voiced\n",
    "voicing = lm.embedding_for('B') - lm.embedding_for('P')\n",
    "forwarding = lm.embedding_for('P') - lm.embedding_for('K')\n",
    "frication = lm.embedding_for('F') - lm.embedding_for('P')\n",
    "\n",
    "new = lm.embedding_for('TH') + voicing\n",
    "# new = lm.embedding_for('K') + voicing\n",
    "# new = lm.embedding_for('T') + frication\n",
    "# new = lm.embedding_for('K') + forwarding\n",
    "\n",
    "phoneme_to_sim = {}\n",
    "for phoneme in phoneme_to_idx:\n",
    "    this_embs = lm.embedding_for(phoneme)\n",
    "    sim = cosine_similarity(new, this_embs).item()\n",
    "    phoneme_to_sim[phoneme] = sim\n",
    "\n",
    "sorted(phoneme_to_sim.items(), key=lambda p: -p[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.mean([embedding_for('B'), embedding_for('V')], axis=0)\n",
    "voiced = np.mean([lm.embedding_for(phoneme) for phoneme in ['B', 'V', 'G', 'Z', 'ZH', 'DH', 'JH']], axis=0)\n",
    "voiceless = np.mean([lm.embedding_for(phoneme) for phoneme in ['P', 'F', 'K', 'S', 'SH', 'TH', 'CH']], axis=0)\n",
    "voicing = voiced - voiceless\n",
    "most_similar_phonemes(lm, voicing + lm.embedding_for('S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_phonemes(lm, voicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START, END, PAD\n",
    "def analogy(lm, a, b, c):\n",
    "    \"\"\"\n",
    "    a - b = c - w\n",
    "    argmax(w) over sim(w, c - a + b)\n",
    "    \"\"\"\n",
    "    emb_a = lm.embedding_for(a)\n",
    "    emb_b = lm.embedding_for(b)\n",
    "    emb_c = lm.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = set(lm.vocab) - {START, END, PAD}\n",
    "    \n",
    "    phoneme_to_sim = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb_p = lm.embedding_for(phoneme)\n",
    "        sim = cosine_similarity(emb_p, emb_c - emb_a + emb_b)\n",
    "        phoneme_to_sim[phoneme] = sim.item()\n",
    "    return phoneme_to_sim\n",
    "\n",
    "analogies = analogy(lm, 'P', 'B', 'K')\n",
    "for phoneme, sim in sorted(analogies.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{sim:.4}] {phoneme}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3).fit_transform(embeddings)\n",
    "tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
