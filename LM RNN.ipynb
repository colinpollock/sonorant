{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from phoneme_lm import PhonemeLM, build_data_loader, build_vocab, encode_pronunciation\n",
    "from utils import load_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_idx, idx_to_phoneme = build_vocab(df.pronunciation.values)\n",
    "df['phoneme_ids'] = df.pronunciation.apply(lambda pronunciation: encode_pronunciation(pronunciation, phoneme_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pronunciation_string'] = df.pronunciation.apply(' '.join)\n",
    "df['length'] = df.pronunciation.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 25000, 1250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, dev_df, test_df = split_data(df, dev_proportion=.2, test_proportion=.01)\n",
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.5811\tassess loss: 0.8998\n",
      "\t M EY1 B AH0 L ER0 Z\n",
      "\t JH AY1 K ER0\n",
      "\t M UW0 R EH1 B AH0 L IH1 S\n",
      "\t JH IH1 T HH EH1 N S\n",
      "\t EY1 IY1 B AH0 N IY0 TH\n",
      "Epoch 2: train loss: 0.5496\tassess loss: 0.8524\n",
      "\t M EH1 JH ER0 D\n",
      "\t P UH1 CH\n",
      "\t R AO1 B L D\n",
      "\t B R OW1 EH1 R\n",
      "\t F S B AH1 N JH AH0\n",
      "Epoch 3: train loss: 0.5360\tassess loss: 0.8330\n",
      "\t F AO1 R D ER0\n",
      "\t G OW2 K OW0 L HH IH1 T S K\n",
      "\t D EH1 N T R AY0 HH OW1 SH T\n",
      "\t R AY1 D AH0 L D S P EH0 F\n",
      "\t G ER1 G R\n",
      "Epoch 4: train loss: 0.5276\tassess loss: 0.8207\n",
      "\t B IH1 L ER0\n",
      "\t M EY1 T ER0 ER0\n",
      "\t L AO1 NG ER0\n",
      "\t K AA1 R B AH0 S T\n",
      "\t AE1 N TH OW0 T IH0 K S\n",
      "Epoch 5; Batch 97 of 97; loss: 0.5198\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/phoneme_lm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_pronunciations, assess_pronunciations, lr, max_epochs, early_stopping_rounds, batch_size)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 )\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Epoch {epoch}: train loss: {train_loss:.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/phoneme_lm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/phoneme_lm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden_state)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/sonorous/venv/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 716\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu', rnn_type='gru',\n",
    "    embedding_dimension=100, hidden_dimension=100, num_layers=1,\n",
    "    max_epochs=10, early_stopping_rounds=5,\n",
    "    lr=5e-3, batch_size=1024\n",
    ")\n",
    "\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AE1', 'N', 'AH0', 'N', 'K', 'UW2', 'CH']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'batch_size': [2**7, 2**10, 2**12, 2**14],\n",
    "#     'lr': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(\n",
    "#         phoneme_to_idx, device='cuda', rnn_type='gru', embedding_dimension=50, hidden_dimension=50,\n",
    "#          max_epochs=200, early_stopping_rounds=3,\n",
    "#         **params\n",
    "#     )\n",
    "    \n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('dev_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = models_df.groupby(['batch_size', 'lr'])\n",
    "\n",
    "columns = 3\n",
    "rows = int(math.ceil(len(g) / columns))\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(20, 10), sharey=True)\n",
    "for idx, ((embedding_dimension, rnn_hidden_dimension), t) in enumerate(g):\n",
    "    row, column = divmod(idx, columns)\n",
    "    ax = axs[row][column]\n",
    "    t.set_index('epoch').dev_loss.plot(ax=ax)\n",
    "    t.set_index('epoch').train_loss.plot(ax=ax)\n",
    "    ax.set_title(f'batch_size={embedding_dimension}, lr={rnn_hidden_dimension}')\n",
    "    plt.tight_layout()\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_df.batch_size.unique())\n",
    "print(models_df.lr.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df[models_df.batch_size==16384].sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, batch_size, lr):\n",
    "    t = models_df[(models_df.batch_size==batch_size) & (models_df.lr==lr)].set_index('epoch')\n",
    "    t.train_loss.plot()\n",
    "    t.dev_loss.plot()\n",
    "plot(df, 1024, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 minutes for 16 models. 4 minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'rnn_type': ['gru'],\n",
    "#     'embedding_dimension': [10, 50, 100, 200],\n",
    "#     'rnn_hidden_dimension': [50, 100, 200, 400],\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.embedding_dimension.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)\n",
    "models_df.sort_values('dev_loss')\n",
    "t = models_df[(models_df.embedding_dimension==10) & (models_df.rnn_hidden_dimension==200)]\n",
    "t.set_index('epoch').train_loss.plot()\n",
    "t.set_index('epoch').dev_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'rnn_type': ['gru'],\n",
    "#     'embedding_dimension': [10, 100, 400],\n",
    "#     'rnn_hidden_dimension': [50, 200, 400],\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=3)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu',\n",
    "    rnn_type='gru', embedding_dimension=10, rnn_hidden_dimension=20,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, max_epochs=5, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = torch.load('lm_1.pt', map_location=torch.device('cpu'))\n",
    "lm.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Real Words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 16s, sys: 13.2 s, total: 11min 29s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['probability'] = df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1483d8750>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sort_values('probability', ascending=False, inplace=True)\n",
    "df.probability.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = train_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))\n",
    "da = dev_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.mean(), da.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Pronunciations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phoneme_ids</th>\n",
       "      <th>pronunciation_string</th>\n",
       "      <th>length</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122549</th>\n",
       "      <td>with</td>\n",
       "      <td>[W, IH1, TH]</td>\n",
       "      <td>[1, 58, 55, 18, 2]</td>\n",
       "      <td>W IH1 TH</td>\n",
       "      <td>3</td>\n",
       "      <td>3.002190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122548</th>\n",
       "      <td>with</td>\n",
       "      <td>[W, IH1, DH]</td>\n",
       "      <td>[1, 58, 55, 64, 2]</td>\n",
       "      <td>W IH1 DH</td>\n",
       "      <td>3</td>\n",
       "      <td>9.310457e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122550</th>\n",
       "      <td>with</td>\n",
       "      <td>[W, IH0, TH]</td>\n",
       "      <td>[1, 58, 32, 18, 2]</td>\n",
       "      <td>W IH0 TH</td>\n",
       "      <td>3</td>\n",
       "      <td>9.503819e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122551</th>\n",
       "      <td>with</td>\n",
       "      <td>[W, IH0, DH]</td>\n",
       "      <td>[1, 58, 32, 64, 2]</td>\n",
       "      <td>W IH0 DH</td>\n",
       "      <td>3</td>\n",
       "      <td>1.724583e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word pronunciation         phoneme_ids pronunciation_string  length  \\\n",
       "122549  with  [W, IH1, TH]  [1, 58, 55, 18, 2]             W IH1 TH       3   \n",
       "122548  with  [W, IH1, DH]  [1, 58, 55, 64, 2]             W IH1 DH       3   \n",
       "122550  with  [W, IH0, TH]  [1, 58, 32, 18, 2]             W IH0 TH       3   \n",
       "122551  with  [W, IH0, DH]  [1, 58, 32, 64, 2]             W IH0 DH       3   \n",
       "\n",
       "         probability  \n",
       "122549  3.002190e-05  \n",
       "122548  9.310457e-07  \n",
       "122550  9.503819e-08  \n",
       "122551  1.724583e-09  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word == 'with'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phoneme_ids</th>\n",
       "      <th>pronunciation_string</th>\n",
       "      <th>length</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113135</th>\n",
       "      <td>tomato</td>\n",
       "      <td>[T, AH0, M, AA1, T, OW2]</td>\n",
       "      <td>[1, 5, 3, 19, 10, 5, 30, 2]</td>\n",
       "      <td>T AH0 M AA1 T OW2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.421234e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113134</th>\n",
       "      <td>tomato</td>\n",
       "      <td>[T, AH0, M, EY1, T, OW2]</td>\n",
       "      <td>[1, 5, 3, 19, 4, 5, 30, 2]</td>\n",
       "      <td>T AH0 M EY1 T OW2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.273807e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             pronunciation                  phoneme_ids  \\\n",
       "113135  tomato  [T, AH0, M, AA1, T, OW2]  [1, 5, 3, 19, 10, 5, 30, 2]   \n",
       "113134  tomato  [T, AH0, M, EY1, T, OW2]   [1, 5, 3, 19, 4, 5, 30, 2]   \n",
       "\n",
       "       pronunciation_string  length   probability  \n",
       "113135    T AH0 M AA1 T OW2       6  1.421234e-09  \n",
       "113134    T AH0 M EY1 T OW2       6  1.273807e-09  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word == 'tomato'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word=='pajamas'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>phoneme_ids</th>\n",
       "      <th>pronunciation_string</th>\n",
       "      <th>length</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38408</th>\n",
       "      <td>february</td>\n",
       "      <td>[F, EH1, B, AH0, W, EH2, R, IY0]</td>\n",
       "      <td>[1, 51, 23, 11, 3, 58, 46, 6, 31, 2]</td>\n",
       "      <td>F EH1 B AH0 W EH2 R IY0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.367271e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38407</th>\n",
       "      <td>february</td>\n",
       "      <td>[F, EH1, B, Y, AH0, W, EH2, R, IY0]</td>\n",
       "      <td>[1, 51, 23, 11, 56, 3, 58, 46, 6, 31, 2]</td>\n",
       "      <td>F EH1 B Y AH0 W EH2 R IY0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.802322e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38411</th>\n",
       "      <td>february</td>\n",
       "      <td>[F, EH1, B, Y, UW0, W, EH2, R, IY0]</td>\n",
       "      <td>[1, 51, 23, 11, 56, 45, 58, 46, 6, 31, 2]</td>\n",
       "      <td>F EH1 B Y UW0 W EH2 R IY0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.254394e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38410</th>\n",
       "      <td>february</td>\n",
       "      <td>[F, EH1, B, UW0, W, EH2, R, IY0]</td>\n",
       "      <td>[1, 51, 23, 11, 45, 58, 46, 6, 31, 2]</td>\n",
       "      <td>F EH1 B UW0 W EH2 R IY0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.159944e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38409</th>\n",
       "      <td>february</td>\n",
       "      <td>[F, EH1, B, R, UW0, W, EH2, R, IY0]</td>\n",
       "      <td>[1, 51, 23, 11, 6, 45, 58, 46, 6, 31, 2]</td>\n",
       "      <td>F EH1 B R UW0 W EH2 R IY0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.072626e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                        pronunciation  \\\n",
       "38408  february     [F, EH1, B, AH0, W, EH2, R, IY0]   \n",
       "38407  february  [F, EH1, B, Y, AH0, W, EH2, R, IY0]   \n",
       "38411  february  [F, EH1, B, Y, UW0, W, EH2, R, IY0]   \n",
       "38410  february     [F, EH1, B, UW0, W, EH2, R, IY0]   \n",
       "38409  february  [F, EH1, B, R, UW0, W, EH2, R, IY0]   \n",
       "\n",
       "                                     phoneme_ids       pronunciation_string  \\\n",
       "38408       [1, 51, 23, 11, 3, 58, 46, 6, 31, 2]    F EH1 B AH0 W EH2 R IY0   \n",
       "38407   [1, 51, 23, 11, 56, 3, 58, 46, 6, 31, 2]  F EH1 B Y AH0 W EH2 R IY0   \n",
       "38411  [1, 51, 23, 11, 56, 45, 58, 46, 6, 31, 2]  F EH1 B Y UW0 W EH2 R IY0   \n",
       "38410      [1, 51, 23, 11, 45, 58, 46, 6, 31, 2]    F EH1 B UW0 W EH2 R IY0   \n",
       "38409   [1, 51, 23, 11, 6, 45, 58, 46, 6, 31, 2]  F EH1 B R UW0 W EH2 R IY0   \n",
       "\n",
       "       length   probability  \n",
       "38408       8  1.367271e-10  \n",
       "38407       9  8.802322e-12  \n",
       "38411       9  3.254394e-12  \n",
       "38410       8  3.159944e-12  \n",
       "38409       9  1.072626e-12  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word == 'february'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "february         5\n",
       "slanted          4\n",
       "scientists       4\n",
       "documentaries    4\n",
       "directives       4\n",
       "                ..\n",
       "beguiling        1\n",
       "inglett          1\n",
       "marolf           1\n",
       "perfetti         1\n",
       "yin              1\n",
       "Name: word, Length: 115533, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S', 'T', 'R', 'UW1', 'Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PRONUNCIATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F AE1 L AA0\n",
      "\n",
      "S T EH1 L K EH2 N\n",
      "\n",
      "B AO1 L V ER0\n",
      "\n",
      "K L EH1 N\n",
      "\n",
      "AA1 R D D\n",
      "\n",
      "P EH1 N K AE2 S T\n",
      "\n",
      "N EY1 B EH2 K\n",
      "\n",
      "D EH1 M ER0\n",
      "\t dehmer 2 total\n",
      "\n",
      "S T EY1 L ER0\n",
      "\t staebler 1 total\n",
      "\n",
      "M EH0 N D IY1 N OW0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    pronunciation = lm.generate(100, temperature=None)\n",
    "    pronunciation_string = ' '.join(pronunciation)\n",
    "    matches = df[df.pronunciation_string == pronunciation_string]\n",
    "    \n",
    "    print(pronunciation_string)\n",
    "    if len(matches) > 0:\n",
    "        print('\\t', matches.iloc[0]['word'], len(matches), 'total')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of Next ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4441] L\n",
      "[0.2840] N\n",
      "[0.0609] </W>\n",
      "[0.0428] T\n",
      "[0.0423] S\n",
      "[0.0201] K\n",
      "[0.0162] F\n",
      "[0.0143] Z\n",
      "[0.0131] G\n",
      "[0.0131] M\n",
      "[0.0069] D\n",
      "[0.0052] W\n",
      "[0.0048] B\n",
      "[0.0046] TH\n",
      "[0.0043] P\n",
      "[0.0039] SH\n",
      "[0.0034] R\n",
      "[0.0029] HH\n",
      "[0.0021] CH\n",
      "[0.0019] JH\n",
      "[0.0012] AH0\n",
      "[0.0011] V\n",
      "[0.0010] EY2\n",
      "[0.0008] NG\n",
      "[0.0006] Y\n",
      "[0.0004] ER0\n",
      "[0.0003] OW2\n",
      "[0.0003] AA2\n",
      "[0.0003] DH\n",
      "[0.0003] ZH\n",
      "[0.0002] AO2\n",
      "[0.0002] UW2\n",
      "[0.0002] AE2\n",
      "[0.0001] AA0\n",
      "[0.0001] EH2\n",
      "[0.0001] OY2\n",
      "[0.0001] EH0\n",
      "[0.0001] AW2\n",
      "[0.0001] AO0\n",
      "[0.0001] ER2\n",
      "[0.0001] EY1\n",
      "[0.0001] IH0\n",
      "[0.0001] EY0\n",
      "[0.0001] IY0\n",
      "[0.0001] AE0\n",
      "[0.0001] OW0\n",
      "[0.0001] AH2\n",
      "[0.0001] UW0\n",
      "[0.0001] AY2\n",
      "[0.0001] AY0\n",
      "[0.0001] AW0\n",
      "[0.0001] EH1\n",
      "[0.0000] IH2\n",
      "[0.0000] OY0\n",
      "[0.0000] IY2\n",
      "[0.0000] AE1\n",
      "[0.0000] UH0\n",
      "[0.0000] UH2\n",
      "[0.0000] UW1\n",
      "[0.0000] OW1\n",
      "[0.0000] <W>\n",
      "[0.0000] AA1\n",
      "[0.0000] UW\n",
      "[0.0000] <PAD>\n",
      "[0.0000] IH1\n",
      "[0.0000] UH1\n",
      "[0.0000] AO1\n",
      "[0.0000] IY1\n",
      "[0.0000] AH1\n",
      "[0.0000] AW1\n",
      "[0.0000] OY1\n",
      "[0.0000] ER1\n",
      "[0.0000] AY1\n"
     ]
    }
   ],
   "source": [
    "pronunciation = ['CH', 'EH0', 'N', 'V', 'AY2', 'R', 'AH0', 'N', 'M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['S', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "pronunciation = ['F', 'EH1', 'B', 'Y', 'AH0']\n",
    "\n",
    "\n",
    "next_probs = lm.next_probabilities(pronunciation)\n",
    "\n",
    "for phoneme, probability in sorted(next_probs.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{probability:.4f}] {phoneme}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_next(lm, pronunciation):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_pronunciation(['S'], lm.phoneme_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lm, 'lm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_phonemes(lm, embedding, topn=10):\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(lm.embedding_for(phoneme), embedding).item()\n",
    "        for phoneme in phoneme_to_idx\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(lm, lm.embedding_for('DH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = lm.embeddings\n",
    "# embeddings = lm.embedding.weight.cpu().detach().numpy()\n",
    "normed_embeddings = normalize(embeddings)\n",
    "\n",
    "num_clusters = 15\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(normed_embeddings)\n",
    "\n",
    "grouped = defaultdict(set)\n",
    "for idx, label in enumerate(kmeans.labels_):\n",
    "    phoneme = lm.vocab[idx]\n",
    "    grouped[label].add(phoneme)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consonants\n",
    "# - voicing\n",
    "# - place: bilabial, dental, alveolar, palatal, velar\n",
    "# - manner: stop, fricative, nasal\n",
    "\n",
    "# For vowels\n",
    "# - front/back\n",
    "# - closed/open\n",
    "# - rounding\n",
    "\n",
    "# General\n",
    "# - syllabic\n",
    "\n",
    "# TODO: combine multiple vectors together, e.g. {B, G, V, DH, D} for voiced\n",
    "voicing = lm.embedding_for('B') - lm.embedding_for('P')\n",
    "forwarding = lm.embedding_for('P') - lm.embedding_for('K')\n",
    "frication = lm.embedding_for('F') - lm.embedding_for('P')\n",
    "\n",
    "# new = lm.embedding_for('TH') + voicing\n",
    "# new = lm.embedding_for('K') + voicing\n",
    "# new = lm.embedding_for('T') + frication\n",
    "new = lm.embedding_for('G') + forwarding\n",
    "\n",
    "phoneme_to_sim = {}\n",
    "for phoneme in phoneme_to_idx:\n",
    "    this_embs = lm.embedding_for(phoneme)\n",
    "    sim = cosine_similarity(new, this_embs).item()\n",
    "    phoneme_to_sim[phoneme] = sim\n",
    "\n",
    "sorted(phoneme_to_sim.items(), key=lambda p: -p[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.mean([embedding_for('B'), embedding_for('V')], axis=0)\n",
    "voiced = np.mean([lm.embedding_for(phoneme) for phoneme in ['B', 'V', 'G', 'Z', 'ZH', 'DH', 'JH']], axis=0)\n",
    "voiceless = np.mean([lm.embedding_for(phoneme) for phoneme in ['P', 'F', 'K', 'S', 'SH', 'TH', 'CH']], axis=0)\n",
    "voicing = voiced - voiceless\n",
    "most_similar_phonemes(lm, voicing + lm.embedding_for('S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_phonemes(lm, voicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START, END, PAD\n",
    "def analogy(lm, a, b, c):\n",
    "    \"\"\"\n",
    "    a - b = c - w\n",
    "    argmax(w) over sim(w, c - a + b)\n",
    "    \"\"\"\n",
    "    emb_a = lm.embedding_for(a)\n",
    "    emb_b = lm.embedding_for(b)\n",
    "    emb_c = lm.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = set(lm.vocab) - {START, END, PAD}\n",
    "    \n",
    "    phoneme_to_sim = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb_p = lm.embedding_for(phoneme)\n",
    "        sim = cosine_similarity(emb_p, emb_c - emb_a + emb_b)\n",
    "        phoneme_to_sim[phoneme] = sim.item()\n",
    "    return phoneme_to_sim\n",
    "\n",
    "analogies = analogy(lm, 'P', 'K', 'B')\n",
    "for phoneme, sim in sorted(analogies.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{sim:.4f}] {phoneme}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START\n",
    "phoneme_idx = lm.phoneme_to_idx[START]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden_state = lm(torch.LongTensor([phoneme_idx]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros(1, 1, 10)\n",
    "\n",
    "lm(torch.LongTensor([phoneme_idx]).unsqueeze(0), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
