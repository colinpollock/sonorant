{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from phoneme_lm import PhonemeLM, build_data_loader, build_vocab, encode_pronunciation\n",
    "from utils import load_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_idx, idx_to_phoneme = build_vocab(df.pronunciation.values)\n",
    "df['phoneme_ids'] = df.pronunciation.apply(lambda pronunciation: encode_pronunciation(pronunciation, phoneme_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pronunciation_string'] = df.pronunciation.apply(' '.join)\n",
    "df['length'] = df.pronunciation.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 25000, 1250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, dev_df, test_df = split_data(df, dev_proportion=.2, test_proportion=.01)\n",
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.5828\tassess loss: 0.9029\n",
      "\t N P IH1 L D AH0 N AH0 B L\n",
      "\t S R R S Z UW1\n",
      "\t V OW1 N N IY0\n",
      "\t M ER1 EH0 L IY0\n",
      "\t P R AY1 K L AH0\n",
      "Epoch 2: train loss: 0.5515\tassess loss: 0.8553\n",
      "\t UW2 M AO1 R S AH0 L\n",
      "\t S P AE1 P T IH0 D\n",
      "\t N AO1 B AH2 T S\n",
      "\t S AO1 R S T\n",
      "\t D AH1 M K S\n",
      "CPU times: user 10min 13s, sys: 27.7 s, total: 10min 41s\n",
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.582791268825531, 0.5515130162239075],\n",
       " [0.9029074311256409, 0.8552573323249817])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu', rnn_type='gru',\n",
    "    embedding_dimension=100, hidden_dimension=100, num_layers=1,\n",
    "    max_epochs=2, early_stopping_rounds=5,\n",
    "    lr=5e-3, batch_size=1024, l2_strength=0\n",
    ")\n",
    "\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 4.2299\tassess loss: 4.2390\n",
      "\t V SH AE2 AY1 AE1 <W> EY2 DH AE0 AE2\n",
      "\t IY1 T N AY0 Y AW0 ER0 UH0 UH2 IY2\n",
      "\t AY2 IY1 EH0 NG UH0 OW1 UW2 AY0 AH1\n",
      "\t UW0 F UH1 M ER2 L CH IH0 OW0 UW1\n",
      "\t W AE0 AH2 OY1 UH1 EY0 ZH UW1 B IY1\n",
      "Epoch 2: train loss: 4.2299\tassess loss: 4.2390\n",
      "\t AA0 IH2 OY1 L\n",
      "\t P AO2 IY1 F UW2 IY2 Z AH0 AY0 N\n",
      "\t IY1 AE1 OY2 AO0 OY1 K OY1 D AY0 B\n",
      "\t AH0 HH N ER1 N P UW Y UH0 M\n",
      "\t AY1 Z NG EY1 UH0 JH OW0 HH AO1 S\n",
      "CPU times: user 10min 14s, sys: 27.4 s, total: 10min 42s\n",
      "Wall time: 2min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4.229948997497559, 4.22994327545166], [4.239027976989746, 4.238986015319824])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu', rnn_type='gru',\n",
    "    embedding_dimension=100, hidden_dimension=100, num_layers=1,\n",
    "    max_epochs=2, early_stopping_rounds=5,\n",
    "    lr=5e-3, batch_size=1024, l2_strength=10\n",
    ")\n",
    "\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'batch_size': [2**7, 2**10, 2**12, 2**14],\n",
    "#     'lr': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(\n",
    "#         phoneme_to_idx, device='cuda', rnn_type='gru', embedding_dimension=50, hidden_dimension=50,\n",
    "#          max_epochs=200, early_stopping_rounds=3,\n",
    "#         **params\n",
    "#     )\n",
    "    \n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df.sort_values('dev_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = models_df.groupby(['batch_size', 'lr'])\n",
    "\n",
    "columns = 3\n",
    "rows = int(math.ceil(len(g) / columns))\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(20, 10), sharey=True)\n",
    "for idx, ((embedding_dimension, rnn_hidden_dimension), t) in enumerate(g):\n",
    "    row, column = divmod(idx, columns)\n",
    "    ax = axs[row][column]\n",
    "    t.set_index('epoch').dev_loss.plot(ax=ax)\n",
    "    t.set_index('epoch').train_loss.plot(ax=ax)\n",
    "    ax.set_title(f'batch_size={embedding_dimension}, lr={rnn_hidden_dimension}')\n",
    "    plt.tight_layout()\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_df.batch_size.unique())\n",
    "print(models_df.lr.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df[models_df.batch_size==16384].sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, batch_size, lr):\n",
    "    t = models_df[(models_df.batch_size==batch_size) & (models_df.lr==lr)].set_index('epoch')\n",
    "    t.train_loss.plot()\n",
    "    t.dev_loss.plot()\n",
    "plot(df, 1024, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 minutes for 16 models. 4 minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'rnn_type': ['gru'],\n",
    "#     'embedding_dimension': [10, 50, 100, 200],\n",
    "#     'rnn_hidden_dimension': [50, 100, 200, 400],\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.embedding_dimension.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)\n",
    "models_df.sort_values('dev_loss')\n",
    "t = models_df[(models_df.embedding_dimension==10) & (models_df.rnn_hidden_dimension==200)]\n",
    "t.set_index('epoch').train_loss.plot()\n",
    "t.set_index('epoch').dev_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# param_grid = ParameterGrid({\n",
    "#     'rnn_type': ['gru'],\n",
    "#     'embedding_dimension': [10, 100, 400],\n",
    "#     'rnn_hidden_dimension': [50, 200, 400],\n",
    "# })\n",
    "\n",
    "# records = []\n",
    "# for params in tqdm(param_grid):\n",
    "#     lm = PhonemeLM(phoneme_to_idx, device='cuda', batch_size=1024,  max_epochs=200, **params)\n",
    "#     print('Model Params:', params)\n",
    "#     train_losses, dev_losses = lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=3)\n",
    "#     for epoch, (train_loss, dev_loss) in enumerate(zip(train_losses, dev_losses), start=1):\n",
    "#         record = params.copy()\n",
    "#         record['epoch'] = epoch\n",
    "#         record['train_loss'] = train_loss\n",
    "#         record['dev_loss'] = dev_loss\n",
    "    \n",
    "#         records.append(record)\n",
    "\n",
    "# models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.sort_values('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm = PhonemeLM(\n",
    "    phoneme_to_idx, device='cpu',\n",
    "    rnn_type='gru', embedding_dimension=10, rnn_hidden_dimension=20,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lm.fit(train_df.pronunciation, dev_df.pronunciation, max_epochs=5, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = torch.load('lm_1.pt', map_location=torch.device('cpu'))\n",
    "lm.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Real Words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['probability'] = df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('probability', ascending=False, inplace=True)\n",
    "df.probability.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = train_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))\n",
    "da = dev_df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.mean(), da.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Pronunciations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'with'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'tomato'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word=='pajamas'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'february'].sort_values('probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.word.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S', 'T', 'R', 'UW1', 'Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PRONUNCIATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    pronunciation = lm.generate(100, temperature=None)\n",
    "    pronunciation_string = ' '.join(pronunciation)\n",
    "    matches = df[df.pronunciation_string == pronunciation_string]\n",
    "    \n",
    "    print(pronunciation_string)\n",
    "    if len(matches) > 0:\n",
    "        print('\\t', matches.iloc[0]['word'], len(matches), 'total')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of Next ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation = ['CH', 'EH0', 'N', 'V', 'AY2', 'R', 'AH0', 'N', 'M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['M', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "# pronunciation = ['S', 'EH1', 'N', 'T', 'AH0', 'L', 'IH2']\n",
    "pronunciation = ['F', 'EH1', 'B', 'Y', 'AH0']\n",
    "\n",
    "\n",
    "next_probs = lm.next_probabilities(pronunciation)\n",
    "\n",
    "for phoneme, probability in sorted(next_probs.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{probability:.4f}] {phoneme}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_next(lm, pronunciation):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_pronunciation(['S'], lm.phoneme_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lm, 'lm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_phonemes(lm, embedding, topn=10):\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(lm.embedding_for(phoneme), embedding).item()\n",
    "        for phoneme in phoneme_to_idx\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(lm, lm.embedding_for('DH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = lm.embeddings\n",
    "# embeddings = lm.embedding.weight.cpu().detach().numpy()\n",
    "normed_embeddings = normalize(embeddings)\n",
    "\n",
    "num_clusters = 15\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(normed_embeddings)\n",
    "\n",
    "grouped = defaultdict(set)\n",
    "for idx, label in enumerate(kmeans.labels_):\n",
    "    phoneme = lm.vocab[idx]\n",
    "    grouped[label].add(phoneme)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consonants\n",
    "# - voicing\n",
    "# - place: bilabial, dental, alveolar, palatal, velar\n",
    "# - manner: stop, fricative, nasal\n",
    "\n",
    "# For vowels\n",
    "# - front/back\n",
    "# - closed/open\n",
    "# - rounding\n",
    "\n",
    "# General\n",
    "# - syllabic\n",
    "\n",
    "# TODO: combine multiple vectors together, e.g. {B, G, V, DH, D} for voiced\n",
    "voicing = lm.embedding_for('B') - lm.embedding_for('P')\n",
    "forwarding = lm.embedding_for('P') - lm.embedding_for('K')\n",
    "frication = lm.embedding_for('F') - lm.embedding_for('P')\n",
    "\n",
    "# new = lm.embedding_for('TH') + voicing\n",
    "# new = lm.embedding_for('K') + voicing\n",
    "# new = lm.embedding_for('T') + frication\n",
    "new = lm.embedding_for('G') + forwarding\n",
    "\n",
    "phoneme_to_sim = {}\n",
    "for phoneme in phoneme_to_idx:\n",
    "    this_embs = lm.embedding_for(phoneme)\n",
    "    sim = cosine_similarity(new, this_embs).item()\n",
    "    phoneme_to_sim[phoneme] = sim\n",
    "\n",
    "sorted(phoneme_to_sim.items(), key=lambda p: -p[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.mean([embedding_for('B'), embedding_for('V')], axis=0)\n",
    "voiced = np.mean([lm.embedding_for(phoneme) for phoneme in ['B', 'V', 'G', 'Z', 'ZH', 'DH', 'JH']], axis=0)\n",
    "voiceless = np.mean([lm.embedding_for(phoneme) for phoneme in ['P', 'F', 'K', 'S', 'SH', 'TH', 'CH']], axis=0)\n",
    "voicing = voiced - voiceless\n",
    "most_similar_phonemes(lm, voicing + lm.embedding_for('S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_phonemes(lm, voicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START, END, PAD\n",
    "def analogy(lm, a, b, c):\n",
    "    \"\"\"\n",
    "    a - b = c - w\n",
    "    argmax(w) over sim(w, c - a + b)\n",
    "    \"\"\"\n",
    "    emb_a = lm.embedding_for(a)\n",
    "    emb_b = lm.embedding_for(b)\n",
    "    emb_c = lm.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = set(lm.vocab) - {START, END, PAD}\n",
    "    \n",
    "    phoneme_to_sim = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb_p = lm.embedding_for(phoneme)\n",
    "        sim = cosine_similarity(emb_p, emb_c - emb_a + emb_b)\n",
    "        phoneme_to_sim[phoneme] = sim.item()\n",
    "    return phoneme_to_sim\n",
    "\n",
    "analogies = analogy(lm, 'P', 'K', 'B')\n",
    "for phoneme, sim in sorted(analogies.items(), key=lambda p: -p[1]):\n",
    "    print(f'[{sim:.4f}] {phoneme}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START\n",
    "phoneme_idx = lm.phoneme_to_idx[START]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden_state = lm(torch.LongTensor([phoneme_idx]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros(1, 1, 10)\n",
    "\n",
    "lm(torch.LongTensor([phoneme_idx]).unsqueeze(0), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
