{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from phoneme_lm import PhonemeLM, build_data_loader, build_vocab, encode_pronunciation\n",
    "from utils import load_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_idx, idx_to_phoneme = build_vocab(df.pronunciation.values)\n",
    "df['phoneme_ids'] = df.pronunciation.apply(lambda pronunciation: encode_pronunciation(pronunciation, phoneme_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pronunciation_string'] = df.pronunciation.apply(' '.join)\n",
    "df['length'] = df.pronunciation.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = split_data(df, dev_proportion=.2, test_proportion=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 25000, 1250)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    'rnn_type': ['rnn', 'lstm', 'gru'],\n",
    "    'embedding_dimension': [5, 10, 20, 50],\n",
    "    'rnn_hidden_dimension': [5, 10, 20, 50, 100],\n",
    "    'epochs': [10, 20, 40]\n",
    "})\n",
    "\n",
    "records = []\n",
    "for params in param_grid:\n",
    "    lm = PhonemeLM(phoneme_to_idx, idx_to_phoneme, **params)\n",
    "    lm.fit(train_df.pronunciation, dev_df.pronunciation)\n",
    "    \n",
    "    params['model'] = lm\n",
    "    records.append(params)\n",
    "\n",
    "models_df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = build_data_loader(train_df.pronunciation, phoneme_to_idx, batch_size=1028)\n",
    "dev_loader = build_data_loader(dev_df.pronunciation, phoneme_to_idx, batch_size=1028)\n",
    "\n",
    "models_df['train_loss'] = models_df.model.apply(lambda model: model.evaluate(train_loader))\n",
    "models_df['dev_loss'] = models_df.model.apply(lambda model: model.evaluate(dev_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 1.28310\tassess loss: 1.7726\n",
      "\t <W> <PAD> HH <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> OW2\n",
      "\t JH D Y EH0 EY2 AA0 UH2 OY2 K\n",
      "\t AE2 UW2 AE1 <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t F JH IY2 IY1 AO1 S <PAD> AH0 <PAD> <PAD>\n",
      "\t UW ER2 IY2 N <PAD> G <PAD> <PAD> <PAD> <PAD>\n",
      "Epoch 2: train loss: 0.97544\tassess loss: 1.4411\n",
      "\t SH\n",
      "\t UW2 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t SH AA0 AY0 IY1 <PAD> <PAD> OY0 <PAD> <PAD> <PAD>\n",
      "\t F N G JH\n",
      "\t OY2 L\n",
      "Epoch 3: train loss: 0.85462\tassess loss: 1.2931\n",
      "\t IY0 B AW1 IY0 N UH1 <PAD> <PAD> <PAD> <PAD>\n",
      "\t UW OW1\n",
      "\t AA2\n",
      "\t L T R\n",
      "\t EY0 IY0 AY0 EY0 D\n",
      "Epoch 4: train loss: 0.79675\tassess loss: 1.2167\n",
      "\t N CH Z K N\n",
      "\t D DH T G N N <PAD> <PAD> <PAD> <PAD>\n",
      "\t G F R ER2 Z Z IH0 M\n",
      "\t S L K\n",
      "\t N N\n",
      "Epoch 5: train loss: 0.75958\tassess loss: 1.1655\n",
      "\t L AH2 T K AY1\n",
      "\t \n",
      "\t AE1 OY1 D EY2 Z OW1\n",
      "\t EY1 IY0 L T D\n",
      "\t AE1 K G T Z IH0\n",
      "Epoch 6: train loss: 0.73292\tassess loss: 1.1265\n",
      "\t P S B T AH0 N AH0 T EH1 NG\n",
      "\t OY1 N D\n",
      "\t D EY2 UW R AA1 SH\n",
      "\t K L ER0 N T EH1\n",
      "\t M AH0 AO0 IH1 UW2 D AH0 D\n",
      "Epoch 7: train loss: 0.71187\tassess loss: 1.0954\n",
      "\t AA2 M AA1 ER1 AE1 <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t S ER1 L\n",
      "\t EH1 N AH0 W AH0 IH1 AH0 D\n",
      "\t OY1 IH0 M K IH1 <W> D ER2 <PAD> <PAD>\n",
      "\t L D CH AY0 AE1 AA0 UW0 K\n",
      "Epoch 8: train loss: 0.69401\tassess loss: 1.0695\n",
      "\t AW2 AE1 ER0 AH0 AY0 AO1\n",
      "\t N P B N S IH0 S ER0 P\n",
      "\t IH0 L B EH1 N\n",
      "\t S AW2 M UH0 S V ER0 R AH0 N\n",
      "\t S AY1 AH1 D\n",
      "Epoch 9: train loss: 0.67874\tassess loss: 1.0468\n",
      "\t NG HH IH0 R IY1 S N IH0\n",
      "\t R IH0 N IH1 R T D AW2\n",
      "\t D UW ER1 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\t R EH1 B G\n",
      "\t L V D L SH V\n",
      "Epoch 10: train loss: 0.6672\tassess loss: 1.0297\n",
      "\t P EY0 T OW1 D ER0 <PAD> <PAD> <PAD> <PAD>\n",
      "\t S AH0 NG OW2 L S T\n",
      "\t S AO1 JH M EY1 D IH0 Z\n",
      "\t K UH0 NG OW1 L T\n",
      "\t L JH AA1 N T\n",
      "CPU times: user 28min 14s, sys: 1min 19s, total: 29min 33s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rnn_lm = PhonemeLM(phoneme_to_idx, idx_to_phoneme, 'rnn', embedding_dimension=10, rnn_hidden_dimension=20, batch_size=1028)\n",
    "rnn_lm.fit(train_df.pronunciation, dev_df.pronunciation, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Real Words ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['probability'] = df.pronunciation.apply(lambda pronunciation: lm.calculate_probability(pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('probability', ascending=False, inplace=True)\n",
    "df.probability.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length == 3].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Pronunciations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word == 'tomato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.word=='pajamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.calculate_probability(['P', 'R', 'IH1', 'F', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PRONUNCIATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE1 L\n",
      "\t al 1 total\n",
      "\n",
      "AO1 R T Z\n",
      "\n",
      "L AA0 S IH1 SH AH0 L AH0 N\n",
      "\n",
      "L IH1 S T AW2 AH0 Z\n",
      "\n",
      "EH2 S IY1 N IH0 NG\n",
      "\n",
      "AH0 L IH1 D W ER0 G IY0\n",
      "\n",
      "AE1 B S\n",
      "\n",
      "R AY1 AH0 N\n",
      "\t rion 4 total\n",
      "\n",
      "AA1 M L S\n",
      "\n",
      "L EH2 K M T EH1 T ER0 Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    pronunciation = rnn_lm.generate(100, temperature=None)\n",
    "    pronunciation_string = ' '.join(pronunciation)\n",
    "    matches = df[df.pronunciation_string == pronunciation_string]\n",
    "    \n",
    "    print(pronunciation_string)\n",
    "    if len(matches) > 0:\n",
    "        print('\\t', matches.iloc[0]['word'], len(matches), 'total')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.769]\tD\n",
      "[0.621]\tL\n",
      "[0.564]\tF\n",
      "[0.463]\tOW0\n",
      "[0.454]\tW\n",
      "[0.450]\tT\n",
      "[0.443]\tK\n",
      "[0.439]\tHH\n",
      "[0.331]\tB\n"
     ]
    }
   ],
   "source": [
    "def most_similar_phonemes(lm, phoneme, topn=10):\n",
    "    emb_one = lm.embedding_for(phoneme)\n",
    "\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(lm.embedding_for(phoneme), emb_one).item()\n",
    "        for phoneme in phoneme_to_idx\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        if other_phoneme != phoneme:\n",
    "            print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(lstm_lm, 'DH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {2: {'</W>',\n",
       "              '<PAD>',\n",
       "              'AA1',\n",
       "              'AE1',\n",
       "              'AH1',\n",
       "              'AW0',\n",
       "              'AW1',\n",
       "              'AY0',\n",
       "              'AY1',\n",
       "              'EH1',\n",
       "              'EH2',\n",
       "              'ER1',\n",
       "              'ER2',\n",
       "              'EY0',\n",
       "              'EY1',\n",
       "              'IY0',\n",
       "              'IY1',\n",
       "              'IY2',\n",
       "              'OW1',\n",
       "              'OW2',\n",
       "              'OY1',\n",
       "              'OY2',\n",
       "              'P',\n",
       "              'UH1',\n",
       "              'UW',\n",
       "              'UW0',\n",
       "              'UW2'},\n",
       "             1: {'<W>',\n",
       "              'AA0',\n",
       "              'AA2',\n",
       "              'AE0',\n",
       "              'AE2',\n",
       "              'AH0',\n",
       "              'AH2',\n",
       "              'AO0',\n",
       "              'AO1',\n",
       "              'AO2',\n",
       "              'AW2',\n",
       "              'AY2',\n",
       "              'EH0',\n",
       "              'EY2',\n",
       "              'IH0',\n",
       "              'IH1',\n",
       "              'IH2',\n",
       "              'UH0',\n",
       "              'UH2',\n",
       "              'UW1'},\n",
       "             0: {'B',\n",
       "              'CH',\n",
       "              'D',\n",
       "              'DH',\n",
       "              'ER0',\n",
       "              'F',\n",
       "              'G',\n",
       "              'HH',\n",
       "              'JH',\n",
       "              'K',\n",
       "              'L',\n",
       "              'M',\n",
       "              'N',\n",
       "              'NG',\n",
       "              'OW0',\n",
       "              'OY0',\n",
       "              'R',\n",
       "              'S',\n",
       "              'SH',\n",
       "              'T',\n",
       "              'TH',\n",
       "              'V',\n",
       "              'W',\n",
       "              'Y',\n",
       "              'Z',\n",
       "              'ZH'}})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = lstm_lm.embeddings\n",
    "normed_embeddings = normalize(embeddings)\n",
    "\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(normed_embeddings)\n",
    "\n",
    "grouped = defaultdict(set)\n",
    "for idx, label in enumerate(kmeans.labels_):\n",
    "    phoneme = lm.vocab[idx]\n",
    "    grouped[label].add(phoneme)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 0.7106951475143433),\n",
       " ('TH', 0.6230912804603577),\n",
       " ('V', 0.5945394039154053)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For consonants\n",
    "# - voicing\n",
    "# - place: bilabial, dental, alveolar, palatal, velar\n",
    "# - manner: stop, fricative, nasal\n",
    "\n",
    "# For vowels\n",
    "# - front/back\n",
    "# - closed/open\n",
    "# - rounding\n",
    "\n",
    "# General\n",
    "# - syllabic\n",
    "\n",
    "# TODO: combine multiple vectors together, e.g. {B, G, V, DH, D} for voiced\n",
    "lm = lstm_lm\n",
    "voicing = lm.embedding_for('B') - lm.embedding_for('P')\n",
    "forwarding = lm.embedding_for('P') - lm.embedding_for('K')\n",
    "frication = lm.embedding_for('F') - lm.embedding_for('P')\n",
    "\n",
    "new = lm.embedding_for('TH') + voicing\n",
    "# new = lm.embedding_for('K') + voicing\n",
    "# new = lm.embedding_for('T') + frication\n",
    "\n",
    "phoneme_to_sim = {}\n",
    "for phoneme in phoneme_to_idx:\n",
    "    this_embs = lm.embedding_for(phoneme)\n",
    "    sim = cosine_similarity(new, this_embs).item()\n",
    "    phoneme_to_sim[phoneme] = sim\n",
    "\n",
    "sorted(phoneme_to_sim.items(), key=lambda p: -p[1])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoneme_lm import START, END, PAD\n",
    "# TODO: finish this\n",
    "def analogy(lm, a, b, c):\n",
    "    emb_a = lm.embedding_for(a)\n",
    "    emb_b = lm.embedding_for(b)\n",
    "    emb_c = lm.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = set(lm.vocab) - {START, END, PAD}\n",
    "    \n",
    "    phoneme_to_diff = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb = lm.embedding_for(phoneme)\n",
    "        first = emb_a - emb_b\n",
    "        second = emb_c - emb\n",
    "        diff = abs(first - second)\n",
    "        phoneme_to_diff[phoneme] = diff\n",
    "    return phoneme_to_diff\n",
    "\n",
    "p2d = analogy(lstm_lm, 'P', 'B', 'K')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
