{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating English Phonotactics #\n",
    "In the notebook `Model Training.ipynb` I trained a language model over English pronunciations from [the CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict). CMU Dict contains phonetic representations of about 125,000 words, so the goal of the language model is to learn what sequences of sounds constitute good words.\n",
    "\n",
    "In this notebook I use the model to:\n",
    "1. **Identify which English pronunciations are most- and least-Englishlike**. For example, I would expect \"fun\" to sound normal and a borrowed word like \"clich√©\" to be less normal.\n",
    "2. **Generate novel words** that aren't English words but sound like they could be.\n",
    "\n",
    "I'll also dig into what the model has learned to see whether it has learned the [phonotactics rules](https://en.wikipedia.org/wiki/Phonotactics) that all English speakers subconsciously understand.\n",
    "\n",
    "Note that pronunciations are in [ARPABET](https://en.wikipedia.org/wiki/ARPABET), a set of symbols representing English sounds. It's a subset of the more popular [International Phonetic Alphabet](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet). If you know IPA you can pick up the equivalent ARPABET from looking at the Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sonorous.analysis_utils import plot_next_phoneme_distribution, plot_pronunciation_probability\n",
    "from sonorous.languagemodel import LanguageModel\n",
    "from sonorous.utils import perplexity\n",
    "from sonorous.pronunciationdata import augment_pronunciations_df, load_pronunciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_colwidth = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll load the model that I trained in `Model Training.ipynb`, as well as all of the pronunciations from CMU Dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (_encoder): Embedding(72, 100)\n",
       "  (_rnn): GRU(100, 3, batch_first=True)\n",
       "  (_decoder): Linear(in_features=3, out_features=72, bias=True)\n",
       "  (_dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('model_1_100_3.pt', 'rb') as fh:\n",
    "    language_model = LanguageModel.load(fh, device_name='cpu')\n",
    "\n",
    "language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 125,801 pronunciations.\n",
      "\n",
      "Sample of 5 pronunciations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freire</th>\n",
       "      <td>(F, R, IH1, R)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budin</th>\n",
       "      <td>(B, UW1, D, IH0, N)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underscoring</th>\n",
       "      <td>(AH2, N, D, ER0, S, K, AO1, R, IH0, NG)</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ehret</th>\n",
       "      <td>(EH1, R, IH0, T)</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skipping</th>\n",
       "      <td>(S, K, IH1, P, IH0, NG)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pronunciation  num_phonemes  \\\n",
       "word                                                                  \n",
       "freire                                 (F, R, IH1, R)             4   \n",
       "budin                             (B, UW1, D, IH0, N)             5   \n",
       "underscoring  (AH2, N, D, ER0, S, K, AO1, R, IH0, NG)            10   \n",
       "ehret                                (EH1, R, IH0, T)             4   \n",
       "skipping                      (S, K, IH1, P, IH0, NG)             6   \n",
       "\n",
       "              num_syllables  \n",
       "word                         \n",
       "freire                    1  \n",
       "budin                     2  \n",
       "underscoring              4  \n",
       "ehret                     2  \n",
       "skipping                  2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations = load_pronunciations()\n",
    "print(f\"There are {len(pronunciations):,} pronunciations.\")\n",
    "print()\n",
    "print(\"Sample of 5 pronunciations:\")\n",
    "\n",
    "pronunciations.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is in utils now, so delete\n",
    "pronunciations['num_primary_stressed_syllables'] = pronunciations.pronunciation.apply(lambda pronunciation: sum(1 for phoneme in pronunciation if phoneme.endswith('1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Words are the Most and Least Englishy? ##\n",
    "Since the model can assign a probability to any pronunciation, I can run it over the entire set of pronunciations in the Pronouncing Dictionary and identify the ones that have high and low likelihood of being English.\n",
    "\n",
    "I'll be using [perplexity](https://en.wikipedia.org/wiki/Perplexity) as a measurement of how likely the model thinks each pronunciation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations['perplexity'] = pronunciations.pronunciation.apply(language_model.perplexity_of_text)\n",
    "pronunciations.sort_values('perplexity', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the least perplexing words. These are the ones the model was totally unsurprised because they seem very normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>renton</th>\n",
       "      <td>(R, EH1, N, T, AH0, N)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.880087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catalan</th>\n",
       "      <td>(K, AE1, T, AH0, L, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.926647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melanin</th>\n",
       "      <td>(M, EH1, L, AH0, N, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8.020210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kenton</th>\n",
       "      <td>(K, EH1, N, T, AH0, N)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8.108158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>callanan</th>\n",
       "      <td>(K, AE1, L, AH0, N, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8.196656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lenton</th>\n",
       "      <td>(L, EH1, N, T, AH0, N)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8.205855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lanolin</th>\n",
       "      <td>(L, AE1, N, AH0, L, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8.299688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marilynn</th>\n",
       "      <td>(M, EH1, R, AH0, L, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8.300134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marilyn</th>\n",
       "      <td>(M, EH1, R, AH0, L, AH0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8.300134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>menton</th>\n",
       "      <td>(M, EH1, N, T, AH0, N)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8.349727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pronunciation  num_phonemes  num_syllables  \\\n",
       "word                                                                 \n",
       "renton         (R, EH1, N, T, AH0, N)             6              2   \n",
       "catalan   (K, AE1, T, AH0, L, AH0, N)             7              3   \n",
       "melanin   (M, EH1, L, AH0, N, AH0, N)             7              3   \n",
       "kenton         (K, EH1, N, T, AH0, N)             6              2   \n",
       "callanan  (K, AE1, L, AH0, N, AH0, N)             7              3   \n",
       "lenton         (L, EH1, N, T, AH0, N)             6              2   \n",
       "lanolin   (L, AE1, N, AH0, L, AH0, N)             7              3   \n",
       "marilynn  (M, EH1, R, AH0, L, AH0, N)             7              3   \n",
       "marilyn   (M, EH1, R, AH0, L, AH0, N)             7              3   \n",
       "menton         (M, EH1, N, T, AH0, N)             6              2   \n",
       "\n",
       "          perplexity  num_primary_stressed_syllables  \n",
       "word                                                  \n",
       "renton      7.880087                               1  \n",
       "catalan     7.926647                               1  \n",
       "melanin     8.020210                               1  \n",
       "kenton      8.108158                               1  \n",
       "callanan    8.196656                               1  \n",
       "lenton      8.205855                               1  \n",
       "lanolin     8.299688                               1  \n",
       "marilynn    8.300134                               1  \n",
       "marilyn     8.300134                               1  \n",
       "menton      8.349727                               1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_perplexing = pronunciations.head(10)\n",
    "least_perplexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>environmentalism</th>\n",
       "      <td>(EH0, N, V, AY1, R, AH0, N, M, EH2, N, AH0, L, IH2, Z, AH0, M)</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>24.217822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmentalism</th>\n",
       "      <td>(EH0, N, V, AY1, R, AH0, N, M, EH2, N, T, AH0, L, IH2, Z, AH0, M)</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>25.519437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      pronunciation  \\\n",
       "word                                                                                  \n",
       "environmentalism     (EH0, N, V, AY1, R, AH0, N, M, EH2, N, AH0, L, IH2, Z, AH0, M)   \n",
       "environmentalism  (EH0, N, V, AY1, R, AH0, N, M, EH2, N, T, AH0, L, IH2, Z, AH0, M)   \n",
       "\n",
       "                  num_phonemes  num_syllables  perplexity  \\\n",
       "word                                                        \n",
       "environmentalism            16              7   24.217822   \n",
       "environmentalism            17              7   25.519437   \n",
       "\n",
       "                  num_primary_stressed_syllables  \n",
       "word                                              \n",
       "environmentalism                               1  \n",
       "environmentalism                               1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.loc['environmentalism']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ten least perplexing words have very regular structure. In all of them the first syllable is stressed and the final syllable is /AH0 N/. There are lots of schwas (/AH0/), which is the most neutral vowel in English.\n",
    "\n",
    "I trained a number of different models and looked at their least perplexing words. The more complex models all had very long words as the least perplexing, which showed that the model had basically memorized actual English words. \"Environmentalism\", for example, had a very low perplexity because the once the model saw /EH0 N V AY1 R/ it seemed to know that there were only a few possible endings. The model we're looking at though seems to have struck a nice balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least perplexing long words (five or more syllables) also display a lot of regularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>concatenating</th>\n",
       "      <td>(K, AH0, N, K, AE1, T, AH0, N, EY2, T, IH0, NG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>12.114662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procrastinating</th>\n",
       "      <td>(P, R, AH0, K, R, AE1, S, T, AH0, N, EY2, T, IH0, NG)</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12.194682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procrastinator</th>\n",
       "      <td>(P, R, AH0, K, R, AE1, S, T, AH0, N, EY2, T, ER0)</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13.095788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contaminating</th>\n",
       "      <td>(K, AH0, N, T, AE1, M, AH0, N, EY2, T, IH0, NG)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13.140277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncollectable</th>\n",
       "      <td>(AH0, N, K, AH0, L, EH1, K, T, AH0, B, AH0, L)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13.271295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         pronunciation  \\\n",
       "word                                                                     \n",
       "concatenating          (K, AH0, N, K, AE1, T, AH0, N, EY2, T, IH0, NG)   \n",
       "procrastinating  (P, R, AH0, K, R, AE1, S, T, AH0, N, EY2, T, IH0, NG)   \n",
       "procrastinator       (P, R, AH0, K, R, AE1, S, T, AH0, N, EY2, T, ER0)   \n",
       "contaminating          (K, AH0, N, T, AE1, M, AH0, N, EY2, T, IH0, NG)   \n",
       "uncollectable           (AH0, N, K, AH0, L, EH1, K, T, AH0, B, AH0, L)   \n",
       "\n",
       "                 num_phonemes  num_syllables  perplexity  \\\n",
       "word                                                       \n",
       "concatenating              12              5   12.114662   \n",
       "procrastinating            14              5   12.194682   \n",
       "procrastinator             13              5   13.095788   \n",
       "contaminating              12              5   13.140277   \n",
       "uncollectable              12              5   13.271295   \n",
       "\n",
       "                 num_primary_stressed_syllables  \n",
       "word                                             \n",
       "concatenating                                 1  \n",
       "procrastinating                               1  \n",
       "procrastinator                                1  \n",
       "contaminating                                 1  \n",
       "uncollectable                                 1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[pronunciations.num_syllables>=5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the high perplexity words-- those that the model is surprised by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>(ER0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138859.122831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er</th>\n",
       "      <td>(ER0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138859.122831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>(ER0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138859.122831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ow</th>\n",
       "      <td>(AW1,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122324.888664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aue</th>\n",
       "      <td>(AW1,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122324.888664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uh</th>\n",
       "      <td>(AH1,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94183.291499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uhh</th>\n",
       "      <td>(AH1,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94183.291499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sh</th>\n",
       "      <td>(SH,)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91141.166429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shh</th>\n",
       "      <td>(SH,)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91141.166429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>(AH0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57648.611399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pronunciation  num_phonemes  num_syllables     perplexity  \\\n",
       "word                                                             \n",
       "are         (ER0,)             1              1  138859.122831   \n",
       "er          (ER0,)             1              1  138859.122831   \n",
       "or          (ER0,)             1              1  138859.122831   \n",
       "ow          (AW1,)             1              1  122324.888664   \n",
       "aue         (AW1,)             1              1  122324.888664   \n",
       "uh          (AH1,)             1              1   94183.291499   \n",
       "uhh         (AH1,)             1              1   94183.291499   \n",
       "sh           (SH,)             1              0   91141.166429   \n",
       "shh          (SH,)             1              0   91141.166429   \n",
       "a           (AH0,)             1              1   57648.611399   \n",
       "\n",
       "      num_primary_stressed_syllables  \n",
       "word                                  \n",
       "are                                0  \n",
       "er                                 0  \n",
       "or                                 0  \n",
       "ow                                 1  \n",
       "aue                                1  \n",
       "uh                                 1  \n",
       "uhh                                1  \n",
       "sh                                 0  \n",
       "shh                                0  \n",
       "a                                  0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations.sort_values('perplexity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these are one syllable words. As you can see in the histogram below, single phoneme words are incredibly rare in the CMU Dict so it makes sense the model would be surprised by these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pronunciations.num_phonemes.value_counts().sort_index().plot.bar()\n",
    "plt.xlabel('Number of Phonemes')\n",
    "plt.ylabel('Frequency')\n",
    "_ = plt.title('Distribution of Word Lengths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the most perplexing words that have at least two phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ainge</th>\n",
       "      <td>(EY1, NG)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10078.350085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>(EY1, AY1)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6758.279094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiaa</th>\n",
       "      <td>(EY1, CH, AY1, EY1, EY1)</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6711.688510</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmm</th>\n",
       "      <td>(HH, M)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5024.130742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hm</th>\n",
       "      <td>(HH, M)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5024.130742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmmm</th>\n",
       "      <td>(HH, M)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5024.130742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>(IH0, Z)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4876.104230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aoi</th>\n",
       "      <td>(AW1, IY0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4702.963188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aer</th>\n",
       "      <td>(EY1, IY1, AA1, R)</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4450.537587</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noaa</th>\n",
       "      <td>(EH1, N, OW1, EY1, EY1)</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4401.183334</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ths</th>\n",
       "      <td>(TH, S)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.262865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auer</th>\n",
       "      <td>(AW1, ER0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3974.001245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>(AW1, ER0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3974.001245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>(AW1, ER0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3974.001245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foia</th>\n",
       "      <td>(EH1, F, OW1, AY1, EY1)</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3510.319207</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hye</th>\n",
       "      <td>(HH, AY0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3389.022801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hors</th>\n",
       "      <td>(AO2, R)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3388.997813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyer</th>\n",
       "      <td>(OY1, ER0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3168.648967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aol</th>\n",
       "      <td>(EY1, OW1, EH1, L)</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2852.541426</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sai</th>\n",
       "      <td>(EH1, S, EY1, AY1)</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2840.777090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pronunciation  num_phonemes  num_syllables    perplexity  \\\n",
       "word                                                                         \n",
       "ainge                 (EY1, NG)             2              1  10078.350085   \n",
       "ai                   (EY1, AY1)             2              2   6758.279094   \n",
       "hiaa   (EY1, CH, AY1, EY1, EY1)             5              4   6711.688510   \n",
       "hmm                     (HH, M)             2              0   5024.130742   \n",
       "hm                      (HH, M)             2              0   5024.130742   \n",
       "hmmm                    (HH, M)             2              0   5024.130742   \n",
       "is                     (IH0, Z)             2              1   4876.104230   \n",
       "aoi                  (AW1, IY0)             2              2   4702.963188   \n",
       "aer          (EY1, IY1, AA1, R)             4              3   4450.537587   \n",
       "noaa    (EH1, N, OW1, EY1, EY1)             5              4   4401.183334   \n",
       "ths                     (TH, S)             2              0   4096.262865   \n",
       "auer                 (AW1, ER0)             2              2   3974.001245   \n",
       "hour                 (AW1, ER0)             2              2   3974.001245   \n",
       "our                  (AW1, ER0)             2              2   3974.001245   \n",
       "foia    (EH1, F, OW1, AY1, EY1)             5              4   3510.319207   \n",
       "hye                   (HH, AY0)             2              1   3389.022801   \n",
       "hors                   (AO2, R)             2              1   3388.997813   \n",
       "oyer                 (OY1, ER0)             2              2   3168.648967   \n",
       "aol          (EY1, OW1, EH1, L)             4              3   2852.541426   \n",
       "sai          (EH1, S, EY1, AY1)             4              3   2840.777090   \n",
       "\n",
       "       num_primary_stressed_syllables  \n",
       "word                                   \n",
       "ainge                               1  \n",
       "ai                                  2  \n",
       "hiaa                                4  \n",
       "hmm                                 0  \n",
       "hm                                  0  \n",
       "hmmm                                0  \n",
       "is                                  0  \n",
       "aoi                                 1  \n",
       "aer                                 3  \n",
       "noaa                                4  \n",
       "ths                                 0  \n",
       "auer                                1  \n",
       "hour                                1  \n",
       "our                                 1  \n",
       "foia                                4  \n",
       "hye                                 0  \n",
       "hors                                0  \n",
       "oyer                                1  \n",
       "aol                                 3  \n",
       "sai                                 3  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[pronunciations.num_phonemes > 1].sort_values('perplexity', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting patterns here. Many of these are actually pronunciations of acronyms. For example, \"ai\" . is /EY1 AY1/, where /EY1/ is \"a\" and /AY1/ is \"i\". You can identify acronyms and compound words by how many primary-stressed syllables they contain: a word will only have one primary stressed syllable.\n",
    "\n",
    "The words that do have just one primary-stressed syllable sound strange to me: /EY1 NG/, /AW1 IY0/, /OY1 ER0/. So I think the model has done a good job here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that for longer pronunciations (e.g. 5+ phonemes), the most perplexing words are almost all acronyms. Below I drop those by removing pronunciations with more than one syllable with primary stress, which works because normal words only have one primary stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_primary_stressed_syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kwangju</th>\n",
       "      <td>(K, W, AA0, NG, JH, UW1)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>390.133280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jambor</th>\n",
       "      <td>(Y, AA0, M, B, AO1, R)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>330.894242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>janthina</th>\n",
       "      <td>(Y, AA0, N, TH, IY1, N, AH0)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>328.836086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lagroceria</th>\n",
       "      <td>(L, AA0, G, R, OW2, S, ER0, IY1, AH2)</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>315.445837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agarwal</th>\n",
       "      <td>(AA1, G, AA0, R, W, AA0, L)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>314.874608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maharaja</th>\n",
       "      <td>(M, AA2, HH, ER0, AA1, ZH, AH2)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>313.583086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kwangju</th>\n",
       "      <td>(G, W, AA0, NG, JH, UW1)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>310.485710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hayenga</th>\n",
       "      <td>(HH, EY0, EY1, NG, G, AH0)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>297.175091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angermeier</th>\n",
       "      <td>(EY1, NG, G, ER0, M, AY0, ER0)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>274.171253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oecd</th>\n",
       "      <td>(OW2, IY2, S, IY2, D, IY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>273.135936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd</th>\n",
       "      <td>(EY2, D, IY2, EY2, CH, D, IY1)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>261.647246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theodorou</th>\n",
       "      <td>(TH, IY1, AH0, D, ER0, UW0)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>256.430630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaquez</th>\n",
       "      <td>(Y, AA0, K, W, EH1, Z)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>240.483388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jacquez</th>\n",
       "      <td>(Y, AA0, K, W, EH1, Z)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>240.483388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourgeois</th>\n",
       "      <td>(B, UH0, R, ZH, W, AA1)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>235.197724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourgeoisie</th>\n",
       "      <td>(B, UH2, R, ZH, W, AA2, Z, IY1)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>230.912821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angeloff</th>\n",
       "      <td>(EY1, NG, G, IH0, L, AO0, F)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>224.123674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angevine</th>\n",
       "      <td>(EY1, NG, G, IH0, V, AY0, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>219.259628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourgeois</th>\n",
       "      <td>(B, UH1, R, ZH, W, AA0)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>218.627598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yamanouchi</th>\n",
       "      <td>(Y, AA0, M, AA0, N, UW1, CH, IY0)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>216.348718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pronunciation  num_phonemes  \\\n",
       "word                                                               \n",
       "kwangju                   (K, W, AA0, NG, JH, UW1)             6   \n",
       "jambor                      (Y, AA0, M, B, AO1, R)             6   \n",
       "janthina              (Y, AA0, N, TH, IY1, N, AH0)             7   \n",
       "lagroceria   (L, AA0, G, R, OW2, S, ER0, IY1, AH2)             9   \n",
       "agarwal                (AA1, G, AA0, R, W, AA0, L)             7   \n",
       "maharaja           (M, AA2, HH, ER0, AA1, ZH, AH2)             7   \n",
       "kwangju                   (G, W, AA0, NG, JH, UW1)             6   \n",
       "hayenga                 (HH, EY0, EY1, NG, G, AH0)             6   \n",
       "angermeier          (EY1, NG, G, ER0, M, AY0, ER0)             7   \n",
       "oecd                    (OW2, IY2, S, IY2, D, IY1)             6   \n",
       "adhd                (EY2, D, IY2, EY2, CH, D, IY1)             7   \n",
       "theodorou              (TH, IY1, AH0, D, ER0, UW0)             6   \n",
       "jaquez                      (Y, AA0, K, W, EH1, Z)             6   \n",
       "jacquez                     (Y, AA0, K, W, EH1, Z)             6   \n",
       "bourgeois                  (B, UH0, R, ZH, W, AA1)             6   \n",
       "bourgeoisie        (B, UH2, R, ZH, W, AA2, Z, IY1)             8   \n",
       "angeloff              (EY1, NG, G, IH0, L, AO0, F)             7   \n",
       "angevine              (EY1, NG, G, IH0, V, AY0, N)             7   \n",
       "bourgeois                  (B, UH1, R, ZH, W, AA0)             6   \n",
       "yamanouchi       (Y, AA0, M, AA0, N, UW1, CH, IY0)             8   \n",
       "\n",
       "             num_syllables  perplexity  num_primary_stressed_syllables  \n",
       "word                                                                    \n",
       "kwangju                  2  390.133280                               1  \n",
       "jambor                   2  330.894242                               1  \n",
       "janthina                 3  328.836086                               1  \n",
       "lagroceria               5  315.445837                               1  \n",
       "agarwal                  3  314.874608                               1  \n",
       "maharaja                 4  313.583086                               1  \n",
       "kwangju                  2  310.485710                               1  \n",
       "hayenga                  3  297.175091                               1  \n",
       "angermeier               4  274.171253                               1  \n",
       "oecd                     4  273.135936                               1  \n",
       "adhd                     4  261.647246                               1  \n",
       "theodorou                4  256.430630                               1  \n",
       "jaquez                   2  240.483388                               1  \n",
       "jacquez                  2  240.483388                               1  \n",
       "bourgeois                2  235.197724                               1  \n",
       "bourgeoisie              3  230.912821                               1  \n",
       "angeloff                 3  224.123674                               1  \n",
       "angevine                 3  219.259628                               1  \n",
       "bourgeois                2  218.627598                               1  \n",
       "yamanouchi               4  216.348718                               1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[(pronunciations.num_phonemes > 5) & (pronunciations.num_primary_stressed_syllables == 1)].sort_values('perplexity', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asean</th>\n",
       "      <td>(EY1, EH1, S, IY1, EY1, EH1, N)</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1513.816329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgh</th>\n",
       "      <td>(EY1, CH, JH, IY1, EY1, CH)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1149.955619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cama</th>\n",
       "      <td>(S, IY1, EY1, EH1, M, EY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1125.057360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kjar</th>\n",
       "      <td>(K, EY1, JH, EY1, EY1, AA1, R)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>884.991168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anfal</th>\n",
       "      <td>(EY1, EH1, N, EH1, F, EY1, EH1, L)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>875.562572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hces</th>\n",
       "      <td>(EY1, CH, S, IY1, IY1, EH1, S)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>763.385405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziad</th>\n",
       "      <td>(Z, IY1, AY1, EY1, D, IY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>755.856467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genego</th>\n",
       "      <td>(JH, IY1, IY1, EH1, N, IY1, JH, IY1, OW1)</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>693.683629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zepa</th>\n",
       "      <td>(Z, IY1, IY1, P, IY1, EY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>666.577943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hfdf</th>\n",
       "      <td>(EY1, CH, EH1, F, D, IY1, EH1, F)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>639.946869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kpmg</th>\n",
       "      <td>(K, EY1, P, IY1, EH1, M, JH, IH1)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>632.027737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmos</th>\n",
       "      <td>(S, IY1, EH1, M, OW1, EH1, S)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>631.471351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wor</th>\n",
       "      <td>(D, AH1, B, AH0, Y, UW1, OW1, AA1, R)</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>583.342915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asap</th>\n",
       "      <td>(EY1, EH1, S, EY1, P, IY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>548.774905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surveyors</th>\n",
       "      <td>(S, ER2, V, EY2, ER0, Z)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>511.866964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adss</th>\n",
       "      <td>(EY1, D, IY1, EH1, S, EH1, S)</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>501.848953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irve</th>\n",
       "      <td>(AY1, AA1, R, V, IY1, IY1)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>457.362539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xudong</th>\n",
       "      <td>(ZH, W, EY1, D, AO1, NG)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>454.192225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silwan</th>\n",
       "      <td>(S, IH2, L, W, AA0, N)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>428.392866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cacld</th>\n",
       "      <td>(S, IY1, EY1, S, IY1, EH1, L, D, IY1)</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>425.572817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pronunciation  num_phonemes  \\\n",
       "word                                                                 \n",
       "asean                (EY1, EH1, S, IY1, EY1, EH1, N)             7   \n",
       "hgh                      (EY1, CH, JH, IY1, EY1, CH)             6   \n",
       "cama                      (S, IY1, EY1, EH1, M, EY1)             6   \n",
       "kjar                  (K, EY1, JH, EY1, EY1, AA1, R)             7   \n",
       "anfal             (EY1, EH1, N, EH1, F, EY1, EH1, L)             8   \n",
       "hces                  (EY1, CH, S, IY1, IY1, EH1, S)             7   \n",
       "ziad                      (Z, IY1, AY1, EY1, D, IY1)             6   \n",
       "genego     (JH, IY1, IY1, EH1, N, IY1, JH, IY1, OW1)             9   \n",
       "zepa                      (Z, IY1, IY1, P, IY1, EY1)             6   \n",
       "hfdf               (EY1, CH, EH1, F, D, IY1, EH1, F)             8   \n",
       "kpmg               (K, EY1, P, IY1, EH1, M, JH, IH1)             8   \n",
       "cmos                   (S, IY1, EH1, M, OW1, EH1, S)             7   \n",
       "wor            (D, AH1, B, AH0, Y, UW1, OW1, AA1, R)             9   \n",
       "asap                      (EY1, EH1, S, EY1, P, IY1)             6   \n",
       "surveyors                   (S, ER2, V, EY2, ER0, Z)             6   \n",
       "adss                   (EY1, D, IY1, EH1, S, EH1, S)             7   \n",
       "irve                      (AY1, AA1, R, V, IY1, IY1)             6   \n",
       "xudong                      (ZH, W, EY1, D, AO1, NG)             6   \n",
       "silwan                        (S, IH2, L, W, AA0, N)             6   \n",
       "cacld          (S, IY1, EY1, S, IY1, EH1, L, D, IY1)             9   \n",
       "\n",
       "           num_syllables   perplexity  \n",
       "word                                   \n",
       "asean                  5  1513.816329  \n",
       "hgh                    3  1149.955619  \n",
       "cama                   4  1125.057360  \n",
       "kjar                   4   884.991168  \n",
       "anfal                  5   875.562572  \n",
       "hces                   4   763.385405  \n",
       "ziad                   4   755.856467  \n",
       "genego                 6   693.683629  \n",
       "zepa                   4   666.577943  \n",
       "hfdf                   4   639.946869  \n",
       "kpmg                   4   632.027737  \n",
       "cmos                   4   631.471351  \n",
       "wor                    5   583.342915  \n",
       "asap                   4   548.774905  \n",
       "surveyors              3   511.866964  \n",
       "adss                   4   501.848953  \n",
       "irve                   4   457.362539  \n",
       "xudong                 2   454.192225  \n",
       "silwan                 2   428.392866  \n",
       "cacld                  5   425.572817  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations[(pronunciations.num_stressed_vowels == 1) & (pronunciations.num_syllables > 3)].drop_duplicates('pronunciation').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these words have three syllables with the stress on the second syllable. These all feel like good English words. They have many phonemes though, so I'm concerned that the model is recognizing the very specific patterns and giving all the later phonemes very high probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations[pronunciations.num_phonemes == 2].sort_values('perplexity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly these words do all feel very weird to me as an English speaker. \"ai\" is an acronym, pronounced as the letter 'A' followed by the letter 'I', so isn't held to normal word formation properties and would be a really strange word.\n",
    "\n",
    "\"zungu\" also doesn't sound like English. Since English prefers syllables with onsets, when saying the word I feel like I want /NG/ to be the onset of the second syllable /NG UW1/. But /NG/ isn't normally allowed as the onset of a syllable.\n",
    "\n",
    "The stress pattern is also weird on this word. Normally in a two syllable word there will be one stressed syllable and one unstressed. This word has primary stress on the second syllabie (/UW1/) and secondary stressed on the first syllable (/AH2/). Interestingly, the perplexity of the word drops considerably (to 450) when I replace /AH2/ with /AH1/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('Z', 'AH2', 'NG', 'UW1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that the lowest perplexity words are very long and the highest perplexity words are short. Let's look at the two other options. First let's look at the low perplexity short words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations[pronunciations.num_phonemes == 2].drop_duplicates('pronunciation').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation(lm, ('K', 'R', 'IH1', 'S', 'T', 'AH0', 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite being only two syllables, these words are packed with phonemes, with lots complex onsets and codas. Let's look at words that are three or fewer phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations[pronunciations.num_phonemes <= 3].drop_duplicates('pronunciation').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('B', 'ER1', 'K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words are all of the form ONSET VOWEL CODA. Overall they all sound like standard words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at long and perplexing words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the words the model thinks are most perplexing (i.e. least likely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations[pronunciations.num_syllables > 4].sort_values('perplexity', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from \"gunatilake\", all of these words are acronyms. For example, \"wor\" is each letter in the word pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Pronunciation Wins for Words with Multiple Pronunciations? ##\n",
    "Another interesting thing we can look at is which pronunciation the model prefers when a word has multiple standard ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations.loc['tomato']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the model's preferred pronunciations for three words commonly argued over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pronunciations.loc['tomato'])\n",
    "display(pronunciations.loc['aunt'])\n",
    "display(pronunciations.loc['nevada'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model agrees with (what I take to be) the more common pronunciation of the first two words but thinks \"Nevada\" is different than how I say it.\n",
    "\n",
    "Let's look at \"coupon\" now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations.loc['coupon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_next_phoneme_distribution(language_model, ('K', 'Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, tuple('K Y UW1 P AO2 N'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, tuple('K UW1 P AO2 N'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prefers the \"YU\" less version of \"coupon\". Interestingly, in this case the relatively low perplexity seems to be due to the model being very certain that /UW1/ will follow /K Y/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"with\" has four possible pronunciations listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations.loc['with']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far the least perplexing one is the one I personally would use. The Pronouncing Dictionary includes two pronunciatinos with an unstressed vowel. When actually spoken in a sentence it'd be common to not stress that vowel, but when just saying the word on its own I would think it should have stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('W', 'IH1', 'TH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('W', 'IH1', 'DH'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also strongly believes \"with\" should end with the voiceless /TH/ instead of the voiced /DH/. It looks like this is due to the model not wanting to end the word at /W IH1 DH/, probably because ending any word with /IH1 DH/ is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the Model Generate Novel Words? ##\n",
    "\n",
    "* proportion of words that are novel\n",
    "* proportion of words (from a sample) that look good to me\n",
    "* 10 randomly sampled words. show them and play the word. ARPABET | IPA | my best spelling guess | play button¬†\n",
    "\n",
    "\n",
    "compare with overgenerated model. probably way more that aren't novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.generate(max_length=1000, temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_pronunciations = pd.DataFrame({\n",
    "    'pronunciation': [\n",
    "        language_model.generate(max_length=1000, temperature=.5)\n",
    "        for _ in range(100)\n",
    "    ]\n",
    "})\n",
    "\n",
    "generated_pronunciations['is_novel_word'] = ~generated_pronunciations.pronunciation.isin(pronunciations.pronunciation)\n",
    "augment_pronunciations_df(generated_pronunciations)\n",
    "\n",
    "# Occasionally the model generates empty pronunciations.\n",
    "generated_pronunciations = generated_pronunciations[generated_pronunciations.num_phonemes > 0]\n",
    "\n",
    "generated_pronunciations.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.next_probabilities(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generated 10,000 new pronunciations. Of those, 75% are novel pronunciations and 25% were in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proportion_novel(generated_pronunciations):\n",
    "    counts = generated_pronunciations.is_novel_word.value_counts()\n",
    "    percentages = counts / counts.sum() * 100\n",
    "    \n",
    "    percentages.index = percentages.index.map({True: 'Novel Word', False: 'Existing Word'})\n",
    "    percentages.plot.bar()\n",
    "    plt.title('Percentage of Generated Words that are Novel')\n",
    "\n",
    "show_proportion_novel(generated_pronunciations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some randomly generated proununciations. I'm printing five pronunciations for each syllable count. Note that these are all novel words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_pronunciations[:0].empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_generated_pronunciations = generated_pronunciations[generated_pronunciations.is_novel_word]\n",
    "\n",
    "for num_syllables in range(1, 5):\n",
    "    \n",
    "    novel_with_syllable_count = novel_generated_pronunciations[novel_generated_pronunciations.num_syllables==num_syllables]\n",
    "    if novel_with_syllable_count.empty:\n",
    "        break\n",
    "    \n",
    "    print(f'These have {num_syllables} syllables')\n",
    "\n",
    "    for pronunciation in novel_with_syllable_count.sample(min(5, len(novel_with_syllable_count))).pronunciation:\n",
    "        print(f'\\t{pronunciation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing that jumps out at me is that these all sound like conceivable English words. There are a few sort of awkward words, like /G OW1 JH D/, but there's nothing unpronouncable. And the stress patterns feel natural to me.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the words the model generates (both in terms of phonemes and syllables) is fairly similar to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations.num_phonemes.hist(density=True, figsize=(10, 5), label='English')\n",
    "generated_pronunciations.num_phonemes.hist(density=True, alpha=.75, label='Generated')\n",
    "plt.xlabel('Number of Phonemes')\n",
    "plt.ylabel('Proportion of Words')\n",
    "plt.title('Phoneme Count Comparison')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations.num_syllables.hist(density=True, figsize=(10, 5), label='English')\n",
    "generated_pronunciations.num_syllables.hist(density=True, alpha=.75, label='Generated')\n",
    "plt.xlabel('Number of Syllables')\n",
    "plt.ylabel('Proportion of Words')\n",
    "plt.title('Syllable Count Comparison')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section I'll probe the model to figure out whether it's just getting lucky or has learned something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Rules is the Model Actually Learning? ##\n",
    "\n",
    "Given the overfitting examples we saw earlier where the model had memorized \"constitutional\" and similar words, I wanted to probe the model to make sure it's learning some more general properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting place to start is at the start of each generated pronunciation. Here are the probabilities for the first phoneme in a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_next_phoneme_distribution(language_model, (), min_probability=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_phoneme_counts = pronunciations.pronunciation.apply(itemgetter(0)).value_counts()\n",
    "(first_phoneme_counts / first_phoneme_counts.sum())[:20].plot.bar()\n",
    "plt.xlabel('Phoneme')\n",
    "_ = plt.title('Distribution of First Phoneme in English WOrds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's probabilities almost exactly match the actual distribution of first phonemes in the training set. I was hoping that the model might learn some more general properties, like that obstruents (e.g. /K/, /P/, /D/) are equally likely to occur at the beginning of the word, but I appear to have given the model enough capacity to learn more specific sound transition probabilities. This is arguably better since the model can differentiate between very likely English pronunciations instead of just valid ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick background on English word structure first. Words are composed of syllables. A syllable consists of an onset, a nucleus, and a coda. The nucleus is usually a vowel (or syllablic consonant like /ER/). The syllable /K R EH1 P T/ has /K R/ in the onset, /EH1/ in the nucleus, and /P T/ in the coda.\n",
    "\n",
    "English prefers that syllables at the end of a word have a coda. Consonants can serve as the codas of syllables. Diphthongs (/EY/, /OW/, /AW/, /OY/, /IY/) also have coda.\n",
    "\n",
    "Compare the two pronunciations below, /K EY1/ and /KEH1/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, (\"S\", \"EY1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, (\"S\", \"EH1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After /S EY1/ the model assigns a 3% probability of the word ending. But /S EH1/ doesn't have a coda, so the model assigns a 0% probability of the word ending.\n",
    "\n",
    "By closing /S EH1/ with /D/ below, we create a complete word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, (\"S\", \"EH1\", \"D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also seems to have learned some intersting stress patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('AH0', 'D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pronunciation_probability(language_model, ('AH1', 'D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It knows that the word /AH0 D/ is very unlikely (it assigns a 0 probability to the word ending there) because a word has to have some stress in it. /AH1 D/ is fine though because it's stressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also learned patterns about stress over multiple syllables. A *foot* is a pair of syllables. A *trochee* contains a stressed syllable followed by an unstressed one. And an *iamb* is an unstressed syllable followed by a stressed one.\n",
    "\n",
    "English, in general, prefers trochees. This implies that the model should assign a lower perplexity to trochees than iambs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trochee: {:.2f}'.format(language_model.perplexity_of_text((\"T\", \"R\", \"OW1\", \"K\", \"IY0\"))))\n",
    "print('Iamb:    {:.2f}'.format(language_model.perplexity_of_text((\"T\", \"R\", \"OW0\", \"K\", \"IY1\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does in fact prefer the trochee versions in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another English phonotactic rule, from Wikipedia, is: \"Two obstruents in the same coda must share voicing (compare kids /K IH1 D Z/ with kits /K IH1 T S/)\". Hopefully the model will assign a higher perplexity when this rule is violated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perplexity for /T EH1 B Z/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'B', 'Z'))))\n",
    "print('Perplexity for /T EH1 B S/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'B', 'S'))))\n",
    "print()\n",
    "print('Perplexity for /T EH1 P S/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'P', 'S'))))\n",
    "print('Perplexity for /T EH1 P Z/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'P', 'Z'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is higher when the two phonemes in the coda do not match in voicing. The model could just be learning that adjacent phonemes should ideally share voicing though. To test whether it's actually learned the rule about voicing in codas I'll change the syllable structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perplexity for /T EH1 B Z AH0/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'B', 'Z', 'AH0'))))\n",
    "print('Perplexity for /T EH1 B S AH0/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'B', 'S', 'AH0'))))\n",
    "print()\n",
    "print('Perplexity for /T EH1 P Z AH0/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'P', 'Z', 'AH0'))))\n",
    "print('Perplexity for /T EH1 P S AH0/: {:.0f}'.format(language_model.perplexity_of_text(('T', 'EH1', 'P', 'S', 'AH0'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four words are identical to the first except that I've inserted /AH0/ to the end of the word, which allows the /S/ and /Z/ to form a second syllable with it. Since /S/ and /Z/ become onsets of the next syllable they're not subject to the constraint on the previous syllable's coda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing the Embeddings (WIP) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_phonemes(language_model, embedding, topn=10):\n",
    "    other_to_sim = {\n",
    "        phoneme: cosine_similarity(language_model.embedding_for(phoneme), embedding).item()\n",
    "        for phoneme in language_model.vocab.tokens\n",
    "\n",
    "    }\n",
    "\n",
    "    for other_phoneme, similarity in sorted(other_to_sim.items(), key=lambda p: -p[1])[:topn]:\n",
    "        print(f'[{similarity:.3f}]\\t{other_phoneme}')\n",
    "        \n",
    "most_similar_phonemes(language_model, language_model.embedding_for('DH'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See whether I can make an embedding for different features.\n",
    "\n",
    "For consonants:\n",
    "- voicing\n",
    "- place: bilabial, dental, alveolar, palatal, velar\n",
    "- manner: stop, fricative, nasal\n",
    "\n",
    "For vowels:\n",
    "- front/back\n",
    "- closed/open\n",
    "- rounding\n",
    "\n",
    "General:\n",
    "- syllabic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector(language_model, class1_phonemes, class2_phonemes):\n",
    "    class1_embeddings = [language_model.embedding_for(phoneme) for phoneme in class1_phonemes]\n",
    "    class2_embeddings = [language_model.embedding_for(phoneme) for phoneme in class2_phonemes]\n",
    "    class1_mean = np.mean(class1_embeddings, axis=0)\n",
    "    class2_mean = np.mean(class2_embeddings, axis=0)\n",
    "    return class1_mean - class2_mean\n",
    "\n",
    "voicing = build_vector(language_model, {'B', 'V', 'DH', 'JH', 'G'}, {'P', 'F', 'TH', 'CH', 'K'})\n",
    "most_similar_phonemes(language_model, voicing + language_model.embedding_for('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(language_model, a, b, c):\n",
    "    \"\"\"\n",
    "    a - b = c - w\n",
    "    argmax(w) over sim(w, c - a + b)\n",
    "    \"\"\"\n",
    "    emb_a = language_model.embedding_for(a)\n",
    "    emb_b = language_model.embedding_for(b)\n",
    "    emb_c = language_model.embedding_for(c)\n",
    "    \n",
    "    all_phonemes = language_model.vocab.tokens - set(language_model.vocab.DUMMY_TOKENS)\n",
    "    \n",
    "    phoneme_to_sim = {}\n",
    "    for phoneme in all_phonemes:\n",
    "        if phoneme in {a, b, c}:\n",
    "            continue\n",
    "        \n",
    "        emb_p = language_model.embedding_for(phoneme)\n",
    "        sim = cosine_similarity(emb_p, emb_c - emb_a + emb_b)\n",
    "        phoneme_to_sim[phoneme] = sim.item()\n",
    "    return phoneme_to_sim\n",
    "\n",
    "analogies = analogy(language_model, 'P', 'K', 'D')\n",
    "for phoneme, sim in sorted(analogies.items(), key=lambda p: -p[1])[:10]:\n",
    "    print(f'[{sim:.4f}] {phoneme}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
